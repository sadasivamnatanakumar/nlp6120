<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="editorial"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Neuroscience</journal-title></journal-title-group><issn pub-type="ppub">1662-4548</issn><issn pub-type="epub">1662-453X</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38125400</article-id><article-id pub-id-type="pmc">PMC10731354</article-id><article-id pub-id-type="doi">10.3389/fnins.2023.1332749</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Editorial</subject></subj-group></subj-group></article-categories><title-group><article-title>Editorial: Unraveling sleep and its disorders using novel analytical approaches, volume II</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Guti&#x000e9;rrez-Tobal</surname><given-names>Gonzalo C.</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref><uri xlink:href="http://loop.frontiersin.org/people/1096559/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Kheirandish-Gozal</surname><given-names>Leila</given-names></name><xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref><uri xlink:href="http://loop.frontiersin.org/people/2328243/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Gozal</surname><given-names>David</given-names></name><xref rid="aff4" ref-type="aff">
<sup>4</sup>
</xref><uri xlink:href="http://loop.frontiersin.org/people/8633/overview"/><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib><contrib contrib-type="author"><name><surname>Hornero</surname><given-names>Roberto</given-names></name><xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref><role content-type="https://credit.niso.org/contributor-roles/conceptualization/"/><role content-type="https://credit.niso.org/contributor-roles/funding-acquisition/"/><role content-type="https://credit.niso.org/contributor-roles/supervision/"/><role content-type="https://credit.niso.org/contributor-roles/writing-original-draft/"/><role content-type="https://credit.niso.org/contributor-roles/writing-review-editing/"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Biomedical Engineering Group, University of Valladolid</institution>, <addr-line>Valladolid</addr-line>, <country>Spain</country></aff><aff id="aff2"><sup>2</sup><institution>Centro de Investigaci&#x000f3;n Biomedica en Red en Bioingenier&#x000ed;a, Biomateriales y Nanomedicina</institution>, <addr-line>Valladolid</addr-line>, <country>Spain</country></aff><aff id="aff3"><sup>3</sup><institution>Department of Neurology, The University of Missouri School of Medicine</institution>, <addr-line>Columbia, MO</addr-line>, <country>United States</country></aff><aff id="aff4"><sup>4</sup><institution>Joan C. Edwards School of Medicine, Marshall University</institution>, <addr-line>Huntington, WV</addr-line>, <country>United States</country></aff><author-notes><fn fn-type="edited-by"><p>Edited and reviewed by: Luis de Lecea, Stanford University, United States</p></fn><corresp id="c001">*Correspondence: Gonzalo C. Guti&#x000e9;rrez-Tobal <email>gonzalo.gutierrez@ciber-bbn.es</email></corresp></author-notes><pub-date pub-type="epub"><day>06</day><month>12</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>17</volume><elocation-id>1332749</elocation-id><history><date date-type="received"><day>03</day><month>11</month><year>2023</year></date><date date-type="accepted"><day>22</day><month>11</month><year>2023</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2023 Guti&#x000e9;rrez-Tobal, Kheirandish-Gozal, Gozal and Hornero.</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Guti&#x000e9;rrez-Tobal, Kheirandish-Gozal, Gozal and Hornero</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><related-article related-article-type="commentary-article" id="RA1" xlink:href="https://www.frontiersin.org/research-topics/38431/unraveling-sleep-and-its-disorders-using-novel-analytical-approaches-volume-ii" ext-link-type="uri">Editorial on the Research Topic <article-title>Unraveling sleep and its disorders using novel analytical approaches, volume II</article-title></related-article><kwd-group><kwd>sleep apnea</kwd><kwd>automated sleep stages</kwd><kwd>insomnia</kwd><kwd>depression</kwd><kwd>explainable artificial intelligence</kwd><kwd>GOAL questionnaire</kwd></kwd-group><funding-group><funding-statement>The author(s) declare financial support was received for the research, authorship, and/or publication of this article. This research was supported by &#x0201c;Ministerio de Ciencia, Innovaci&#x000f3;n y Universidades&#x02014;Agencia Estatal de Investigaci&#x000f3;n/10.13039/501100011033/,&#x0201d; &#x0201c;ERDF A way of making Europe,&#x0201d; and &#x0201c;European Union NextGenerationEU/PRTR&#x0201d; under projects PID2020-115468RB-I00 and PDC2021-120775-I00, and by &#x0201c;CIBER&#x02014;Consorcio Centro de Investigaci&#x000f3;n Biom&#x000e9;dica en Red-(CB19/01/00012)&#x0201d; through &#x0201c;Instituto de Salud Carlos III&#x0201d;. GG-T was supported by a post-doctoral grant from the University of Valladolid. DG was supported by &#x0201c;National Institutes of Health (NIH)&#x0201d; AG061824.</funding-statement></funding-group><counts><fig-count count="1"/><table-count count="0"/><equation-count count="0"/><ref-count count="10"/><page-count count="3"/><word-count count="1847"/></counts><custom-meta-group><custom-meta><meta-name>section-at-acceptance</meta-name><meta-value>Sleep and Circadian Rhythms</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>After completion of this second volume, two important aspects have emerged: (i) the manuscripts submitted have met with the highest scientific standards and (ii) a quick comparison with the first Research Topic (Guti&#x000e9;rrez-Tobal et al., <xref rid="B5" ref-type="bibr">2022</xref>) reveals new trends in the application of analytical tools, yet still being applied to unresolved problems in sleep research (see <xref rid="F1" ref-type="fig">Figure 1</xref>). Accordingly, sleep apnea is the subject of investigation in three out of the five studies of this second collection. Novel artificial intelligence approaches focusing on explainability (Adadi and Berrada, <xref rid="B1" ref-type="bibr">2018</xref>), as well as simplified screening procedures based on questionnaires are the topics covered by the authors of these studies. Automatizing sleep stage detection is also a recurrent topic and is present in another paper. Artificial intelligence, and in particular deep learning (Goodfellow et al., <xref rid="B4" ref-type="bibr">2016</xref>), is again the analytical framework selected by the investigators. The fifth article focuses on relationships between insomnia and depression, with analysis of cerebral blood perfusion, as well as the connectivity between brain regions, representing the specific emphasis explored by this investigation.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p>Number of papers published for each topic in Volume I (orange), Volume II (yellow), and the both of them together (blue).</p></caption><graphic xlink:href="fnins-17-1332749-g0001" position="float"/></fig><p>Consistent with the above-mentioned methods used in the articles, we have organized this editorial in the following sub-sections.</p><sec><title> Deep learning and explainable artificial intelligence</title><p>Deep learning have led to impressive performances in a wide range of problems, including those within healthcare (Miotto et al., <xref rid="B7" ref-type="bibr">2018</xref>) and in the processing of physiological signals (Faust et al., <xref rid="B3" ref-type="bibr">2018</xref>) contexts. Often blamed for being essentially a &#x0201c;black box&#x0201d; methodology, substantial effort is now being made to provide explainable deep-learning models (Adadi and Berrada, <xref rid="B1" ref-type="bibr">2018</xref>). In this Research Topic collection, the study by <ext-link xlink:href="https://doi.org/10.3389/fnins.2022.974192" ext-link-type="uri">Pini et al.</ext-link> used the cardio-respiratory signals derived from a wearable chest belt to train a deep learning model with the ability to automatically detect sleep stages. A particular strength of the study is that the investigators included more than 1,000 subjects and evaluated a combination of temporal convolutional (Lea et al., <xref rid="B6" ref-type="bibr">2017</xref>) and inception residual networks (Szegedy et al., <xref rid="B9" ref-type="bibr">2017</xref>) to detect two (wake/sleep), three (wake/NREM/REM), or four (wake/light/deep/REM) sleep stages. Such, sophisticated methodologies clearly open the way for expanded generalizability studies that reconcile different sensors and signals to enable extraction of valid sleep staging irrespective of the specific physiological signal or signals being acquired by the wearable device.</p><p>A second study by <ext-link xlink:href="https://doi.org/10.3389/fnins.2023.1155900" ext-link-type="uri">Serrano Alarc&#x000f3;n et al.</ext-link> focused on detecting apneic events during sleep by means of a convolutional neural network (CNN) architecture. In this instance, they used overnight blood oxygen saturation, heart rate, and thoracic and abdominal respiration from more than 4,000 adult subjects from Sleep Health Heart Study (SHHS) and Multi-Ethnic Study of Atherosclerosis (MESA) databases. In their study, the authors also applied explainable artificial intelligence (XAI) techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM) (Selvaraju et al., <xref rid="B8" ref-type="bibr">2017</xref>), which allowed them to visually identify those regions of the signals in which the CNN was focusing to derive its accurate predictions.</p></sec><sec><title> Brain connectivity and cerebral blood floor</title><p>Other issues that remain persistently under exploration in sleep research are insomnia and depression. In this Research Topic, both are addressed at the same time by <ext-link xlink:href="https://doi.org/10.3389/fnins.2023.1202514" ext-link-type="uri">Xu et al.</ext-link>. The authors presented a very interesting study with 44 patients and 43 healthy controls to pave the way toward finding the mechanisms driving comorbidity of chronic insomnia and major depressive disorders. They showed new connections and associations between cerebral blood flow, brain function, and sleep and emotion regulation abnormalities, which may be behind of the pathogenesis of comorbidity in these diseases.</p></sec><sec><title> GOAL questionnaire assessment</title><p>A new tool in the form of a simple yes/no questionnaire has been recently proposed for sleep apnea screening in adults (Duarte et al., <xref rid="B2" ref-type="bibr">2020</xref>). The GOAL questionnaire (the initials standing for Gender, Obesity, Age, and Loud snoring) showed interesting screening performance when first proposed using a large Brazilian population (<italic>N</italic> = 7,377). In this Research Topic, a first study by <ext-link xlink:href="https://doi.org/10.3389/fnins.2022.1046603" ext-link-type="uri">Zheng et al.</ext-link> validated the GOAL instrument in a relatively large Asian population from China (<italic>N</italic> = 2,171). The authors reported similar results to those of the original study, as well as comparable screening ability than other well-known questionnaires, thus evidencing its robustness. Furthermore, a second study by <ext-link xlink:href="https://doi.org/10.3389/fnins.2022.1014948" ext-link-type="uri">Zhao et al.</ext-link> assessed the screening ability of GOAL questionnaire when combined with neck circumference or neck-to-height ratio by the use of logistic regression models. In their study, the authors enrolled 288 subjects and showed improved performance when compared with the original GOAL instrument alone.</p></sec></sec><sec sec-type="conclusions" id="s2"><title>Conclusions</title><p>Several conclusions can be derived from the review of the literature that is also reflected in this Research Topic. First, sleep science is a natural multidisciplinary research area. Psychiatrists, electronic engineers, pediatricians, nurses, pulmonologists, radiologists, and computer scientists are among the authors of the published works. Second, studies involving sleep are increasing in the number and magnitude of the participants enrolled in such studies. This was a common drawback in the past due to the low availability of sleep labs. However, social awareness and technical improvements have allowed for the ability to enroll more subjects in these studies, and such enhanced representation has and will continue to improve the quality and significance of the studies being published in these pages. In this Research Topic, three out of the five published works used recordings from more than 1,000 subjects. Finally, artificial intelligence and XAI are gaining importance in the evolution of sleep research, as depicted in two of the published studies. Favored by the above-mentioned increasing in data collection, which is mandatorily required for training successful models, the combination of deep learning and XAI is now providing very accurate methods for the purpose they are designed, while also uncovering new sleep-related knowledge based on the explanations of the decisions automatically made by these models (Vaquerizo-Villar et al., <xref rid="B10" ref-type="bibr">2023</xref>).</p></sec><sec sec-type="author-contributions" id="s3"><title>Author contributions</title><p>GG-T: Conceptualization, Funding acquisition, Supervision, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. LK-G: Conceptualization, Funding acquisition, Supervision, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. DG: Conceptualization, Funding acquisition, Supervision, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. RH: Conceptualization, Funding acquisition, Supervision, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing.</p></sec></body><back><ack><p>The Editors want to thank the excellent work of authors and reviewers of the submitted manuscripts.</p></ack><sec sec-type="COI-statement" id="conf1"><title>Conflict of interest</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. The author(s) declared that they were an editorial board member of Frontiers, at the time of submission. This had no impact on the peer review process and the final decision.</p></sec><sec sec-type="disclaimer" id="s5"><title>Publisher's note</title><p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p></sec><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adadi</surname><given-names>A.</given-names></name><name><surname>Berrada</surname><given-names>M.</given-names></name></person-group> (<year>2018</year>). <article-title>Peeking inside the black-box: a survey on explainable artificial intelligence (XAI)</article-title>. <source>IEEE Access</source>
<volume>6</volume>, <fpage>52138</fpage>&#x02013;<lpage>52160</lpage>. <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2870052</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duarte</surname><given-names>R. L.</given-names></name><name><surname>Magalh&#x000e3;es-da Silveira</surname><given-names>F. J.</given-names></name><name><surname>Oliveira-e S&#x000e1;</surname><given-names>T. S.</given-names></name><name><surname>Silva</surname><given-names>J. A.</given-names></name><name><surname>Mello</surname><given-names>F. C.</given-names></name><name><surname>Gozal</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Obstructive sleep apnea screening with a 4-item instrument, named goal questionnaire: development, validation and comparative study with no-apnea, stop-bang, and nosas</article-title>. <source>Nat. Sci. Sleep</source>
<volume>12</volume>, <fpage>57</fpage>&#x02013;<lpage>67</lpage>. <pub-id pub-id-type="doi">10.2147/NSS.S238255</pub-id><pub-id pub-id-type="pmid">32158294</pub-id>
</mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faust</surname><given-names>O.</given-names></name><name><surname>Hagiwara</surname><given-names>Y.</given-names></name><name><surname>Hong</surname><given-names>T. J.</given-names></name><name><surname>Lih</surname><given-names>O. S.</given-names></name><name><surname>Acharya</surname><given-names>U. R.</given-names></name></person-group> (<year>2018</year>). <article-title>Deep learning for healthcare applications based on physiological signals: a review</article-title>. <source>Comp. Methods Progr. Biomed</source>. <volume>161</volume>, <fpage>1</fpage>&#x02013;<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1016/j.cmpb.2018.04.005</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Courville</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <source>Deep Learning</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guti&#x000e9;rrez-Tobal</surname><given-names>G. C.</given-names></name><name><surname>Kheirandish-Gozal</surname><given-names>L.</given-names></name><name><surname>Gozal</surname><given-names>D.</given-names></name><name><surname>Hornero</surname><given-names>R.</given-names></name></person-group> (<year>2022</year>). <article-title>Unraveling sleep and its disorders using novel analytical approaches</article-title>. <source>Front. Neurosci</source>. 16, 924359. <pub-id pub-id-type="doi">10.3389/fnins.2022.924359</pub-id><pub-id pub-id-type="pmid">35663551</pub-id>
</mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lea</surname><given-names>C.</given-names></name><name><surname>Flynn</surname><given-names>M. D.</given-names></name><name><surname>Vidal</surname><given-names>R.</given-names></name><name><surname>Reiter</surname><given-names>A.</given-names></name><name><surname>Hager</surname><given-names>G. D.</given-names></name></person-group> (<year>2017</year>). <article-title>&#x0201c;Temporal convolutional networks for action segmentation and detection,&#x0201d;</article-title> in <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>, <fpage>156</fpage>&#x02013;<lpage>165</lpage>.</mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miotto</surname><given-names>R.</given-names></name><name><surname>Wang</surname><given-names>F.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Jiang</surname><given-names>X.</given-names></name><name><surname>Dudley</surname><given-names>J. T.</given-names></name></person-group> (<year>2018</year>). <article-title>Deep learning for healthcare: review, opportunities and challenges</article-title>. <source>Brief. Bioinformat</source>. <volume>19</volume>, <fpage>1236</fpage>&#x02013;<lpage>1246</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbx044</pub-id><pub-id pub-id-type="pmid">28481991</pub-id>
</mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Selvaraju</surname><given-names>R. R.</given-names></name><name><surname>Cogswell</surname><given-names>M.</given-names></name><name><surname>Das</surname><given-names>A.</given-names></name><name><surname>Vedantam</surname><given-names>R.</given-names></name><name><surname>Parikh</surname><given-names>D.</given-names></name><name><surname>Batra</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>&#x0201c;Grad-cam: visual explanations from deep networks via gradient-based localization,&#x0201d;</article-title> in <source>Proceedings of the IEEE International Conference on Computer Vision</source>, <fpage>618</fpage>&#x02013;<lpage>626</lpage>.</mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szegedy</surname><given-names>C.</given-names></name><name><surname>Ioffe</surname><given-names>S.</given-names></name><name><surname>Vanhoucke</surname><given-names>V.</given-names></name><name><surname>Alemi</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>&#x0201c;Inception-v4, inception-resnet and the impact of residual connections on learning,&#x0201d;</article-title> in <source>Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 31</source>.</mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaquerizo-Villar</surname><given-names>F.</given-names></name><name><surname>Guti&#x000e9;rrez-Tobal</surname><given-names>G. C.</given-names></name><name><surname>Calvo</surname><given-names>E.</given-names></name><name><surname>&#x000c1;lvarez</surname><given-names>D.</given-names></name><name><surname>Kheirandish-Gozal</surname><given-names>L.</given-names></name><name><surname>Del Campo</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2023</year>). <article-title>An explainable deep-learning model to stage sleep states in children and propose novel eeg-related patterns in sleep apnea</article-title>. <source>Comp. Biol. Med</source>. 165, 107419. <pub-id pub-id-type="doi">10.1016/j.compbiomed.2023.107419</pub-id><pub-id pub-id-type="pmid">37703716</pub-id>
</mixed-citation></ref></ref-list></back></article>
