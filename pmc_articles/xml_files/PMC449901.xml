<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="iso-abbrev">PLoS Biol</journal-id><journal-id journal-id-type="publisher-id">pbio</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15252459</article-id><article-id pub-id-type="pmc">PMC449901</article-id><article-id pub-id-type="doi">10.1371/journal.pbio.0020216</article-id><article-categories><subj-group subj-group-type="heading"><subject>Primer</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Animal Behavior</subject></subj-group><subj-group subj-group-type="System Taxonomy"><subject>Insects</subject></subj-group></article-categories><title-group><article-title>Dances as Windows into Insect Perception</article-title><alt-title alt-title-type="running-head">Primer</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Chittka</surname><given-names>Lars</given-names></name></contrib></contrib-group><pub-date pub-type="ppub"><month>7</month><year>2004</year></pub-date><pub-date pub-type="epub"><day>13</day><month>7</month><year>2004</year></pub-date><pub-date pub-type="pmc-release"><day>13</day><month>7</month><year>2004</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. --><volume>2</volume><issue>7</issue><elocation-id>e216</elocation-id><permissions><copyright-statement>Copyright: &#x000a9; 2004 Lars Chittka.</copyright-statement><copyright-year>2004</copyright-year><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><related-article id="d35e70" related-article-type="companion" ext-link-type="doi" xlink:href="10.1371/journal.pbio.0020211" xlink:title="research article" vol="2" page="e211">
<article-title>Honeybee Odometry: Performance in Varying Natural Terrain</article-title>
</related-article><abstract abstract-type="toc"><p>Honeybees signal the location of food sources to their hive- mates using a "dancing" flight pattern. Translating these patterns, scientists learn what bees perceive</p></abstract></article-meta></front><body><p>Experimental psychologists working with humans have a fundamental advantage over scientists studying the behaviour of other animals. This is because human subjects can give a verbal account of their experience. For example, they can report: &#x02018;These two lights of different colour look equally bright&#x02019; or &#x02018;This object looks further away than that one&#x02019;. Such direct reports facilitate studying how information from the sensory periphery, that is, the sense organs that actually interface with the environment, is processed in the brain.</p><p>The perceptual world of animals is often very different from that of humans. Many animals have sensory facilities that we humans lack; for example, insects can see ultraviolet and polarised light. But how they actually perceive the world, based on information from their sensory periphery, is often beyond our grasp. Because animals cannot describe their sensations, our access to them is often based on indirect psychophysical tests, where animal performance depends fundamentally on motivation and training method (<xref rid="pbio-0020216-Chittka3" ref-type="bibr">Chittka et al. 2003</xref>). However, some animals do in fact describe the world around them, but not necessarily in ways that we might intuitively understand. Perhaps the best example of this are the honeybees (genus <named-content content-type="genus-species">Apis</named-content>), which have a symbolic &#x02018;language&#x02019; that nestmates use to communicate with each other about profitable food sources. By eavesdropping on this communication, scientists have recently obtained a unique perspective into the perceptual world of insects.</p><p>How does the dance language work? A triumphant scout bee returns from the field, and advertises the location of a newly discovered food source to nestmates. To do this, the forager performs a repetitive sequence of movements, the so-called waggle dance, which is one of the most intriguing examples of complex animal behaviour. The successful forager wiggles her abdomen provocatively from side to side, moving forward in a straight line. Then she runs in a half circle to the left, back to her starting point, performs another straight wiggle run along the path of her first, and then circles to the right (<xref ref-type="fig" rid="pbio-0020216-g001">Figure 1</xref>). This pattern is repeated multiple times, and is eagerly attended by unemployed bees in the hive. Shortly after such dances commence, dozens of newly recruited foragers arrive at the food source being advertised.</p><fig id="pbio-0020216-g001" position="float"><label>Figure 1</label><caption><title>Figure-Eight-Shaped Waggle Dance of the Honeybee (<named-content content-type="genus-species">Apis mellifera</named-content>)</title><p>A waggle run oriented 45&#x000b0; to the right of &#x02018;up&#x02019; on the vertical comb (A) indicates a food source 45&#x000b0; to the right of the direction of the sun outside the hive (B). The abdomen of the dancer appears blurred because of the rapid motion from side to side. (Figure design: J. Tautz and M. Kleinhenz, Beegroup W&#x000fc;rzburg.)</p></caption><graphic xlink:href="pbio.0020216.g001"/></fig><p>In the 1940s, Nobel laureate Karl von Frisch deciphered the code hidden in this seemingly senseless choreography performed on vertical honeycombs in the darkness of the hive (reviewed in <xref rid="pbio-0020216-vonFrisch1" ref-type="bibr">von Frisch 1967</xref>). He found that the angle of the waggle run from the vertical is equal to the angle between the sun's azimuth and the indicated food source outside the hive. For example, if a food source is found in the direction of the sun, the dancer will waggle &#x02018;straight up&#x02019; the vertical comb. If food is found 45&#x000b0; to the right of the sun's direction, the waggle run will be oriented 45&#x000b0; to the right of vertical on the comb (<xref ref-type="fig" rid="pbio-0020216-g001">Figure 1</xref>). The distance to the target, a flower patch with abundant nectar or pollen, is encoded in the duration of the waggle run: the longer the bee waggles, the larger the distance of the food from the hive. No other species (besides humans) uses a similarly symbolic representation to communicate information from the real world.</p><p>But how do bees measure the flight distance that they communicate so precisely? It was previously thought they do this by measuring the energy used as they fly (<xref rid="pbio-0020216-Heran1" ref-type="bibr">Heran 1956</xref>). However, doubts emerged when it was found that distance estimation by bees could be manipulated by altering the number of landmarks between the hive and a food source, suggesting bees were counting landmarks encountered en route (<xref rid="pbio-0020216-Chittka2" ref-type="bibr">Chittka and Geiger 1995</xref>). In an elegant experiment, <xref rid="pbio-0020216-Esch1" ref-type="bibr">Esch and Burns (1995)</xref> tapped into the bees' dance language to access their subjective assessment of flight distance. They let bees forage from a food source 70 m from the hive and recorded the dance distance code of the returning foragers. Subsequently, the feeder was attached to a weather balloon, and slowly lifted to an altitude of 90 m&#x02014;so that the distance between the hive and the food now increased from 70 m to 114 m. Correspondingly, foragers should have indicated a longer distance, by stretching their waggle run duration. But, in fact, the perceived distance (as indicated in the dance) <italic>decreased</italic> by more than 50%! This clearly shows that bee perception of distance cannot solely be based on energy expenditure, since a longer flight that cost more energy was danced as a shorter &#x02018;distance&#x02019; in the waggle run.</p><p>So what actually drives the bee odometer? Because the landscape bees pass in flight moves more slowly when bees fly at higher altitudes, <xref rid="pbio-0020216-Esch1" ref-type="bibr">Esch and Burns (1995)</xref> conjectured that foragers process the speed with which visual contours move across the eye (optic flow), and integrate this with travel time. To confirm this hypothesis, <xref rid="pbio-0020216-Srinivasan1" ref-type="bibr">Srinivasan et al. (2000)</xref> further exaggerated the experienced image flow, by training bees to fly through narrow chequered tunnels. These bees grossly overestimated actual travel distance, bragging to their nestmates that they had flown 195 m when in fact they had flown 6 m. Attendees of these dances promptly believed the high-class swindle, and searched for food at remote locations that the dancers had never even visited (<xref rid="pbio-0020216-Esch2" ref-type="bibr">Esch et al. 2001</xref>).</p><p>The quality of information available about the velocity of the passing landscape will depend, of course, on the sensitivity of the eyes. The eyes of bees contain three types of colour receptors, with maximum sensitivity in the ultraviolet, blue, and green domains of the spectrum (<xref rid="pbio-0020216-Autrum1" ref-type="bibr">Autrum and von Zwehl 1964</xref>). Their excellent colour vision is optimal for flower identification (<xref rid="pbio-0020216-Chittka1" ref-type="bibr">Chittka 1996</xref>), but do they also use it to measure the image velocity of the passing landscape? Surprisingly, the answer is no&#x02014;bee odometry is in fact totally colour blind. <xref rid="pbio-0020216-Chittka3" ref-type="bibr">Chittka and Tautz (2003)</xref> found that bees use exclusively the signal from their green receptors for measuring image velocity (<xref ref-type="fig" rid="pbio-0020216-g002">Figure 2</xref>), confirming earlier reports that motion vision in bees is mediated only by this receptor type (<xref rid="pbio-0020216-Giurfa1" ref-type="bibr">Giurfa and Lehrer 2001</xref>; <xref rid="pbio-0020216-Spaethe1" ref-type="bibr">Spaethe et al. 2001</xref>). Thus, the level of intensity contrast present in the scene strongly influences the bees' subjective experience of flight distance (<xref rid="pbio-0020216-Chittka3" ref-type="bibr">Chittka and Tautz 2003</xref>; <xref rid="pbio-0020216-Si1" ref-type="bibr">Si et al. 2003</xref>).</p><fig id="pbio-0020216-g002" position="float"><label>Figure 2</label><caption><title>Bees Use Different Visual Cues When Viewing Flowers and Landscape Image Motion</title><p>Although bees see flowers in colour, they do not analyse the colours of the landscape image that moves across the eye as they fly. Their perception of landscape motion is colour-blind; motion vision is driven solely by a single spectral receptor type, the bees' green receptor. This is reflected in the distance code of the dance: the more green contrast is present in the scene, the further bees &#x02018;think&#x02019; they have flown. (Figure design: F. Bock, Beegroup W&#x000fc;rzburg.)</p></caption><graphic xlink:href="pbio.0020216.g002"/></fig><p>With so many external variables influencing distance estimation, it seems unlikely that the honeybee odometer would be very robust in natural conditions. Now, as reported in this issue of <italic>PLoS Biology</italic>, <xref rid="pbio-0020216-Tautz1" ref-type="bibr">Tautz et al. (2004)</xref> have quantified the bees' subjective experience of distance travelled when they fly over natural terrain with varying levels of contrast. Specifically, they compared the dances of bees flying over water (scenery with low visual contrast) with those of bees flying over land (scenery with relatively high contrast). They trained bees to forage at a feeder on a boat, which was paddled increasing distances from the hive, until it reached an island. All the while, observers at the hive deciphered the dances of the bees returning from the feeder. Interestingly, bees flying 200 m over water hardly appeared to register an increase in travel distance, whereas the same increase in distance flown over land resulted in a substantial increase in perceived flight distance. This is consistent with the hypothesis that the bees' odometer is largely based on visual, external cues and demonstrates that this system is sensitive to visual contrast.</p><p>But there must be something else beside visual cues. Navigation over water, in the near absence of visible ground features, is extremely difficult without a reliable internal instrument measuring travel speed. This is the case even for us humans with sophisticated measuring devices: malfunctioning air speed indicators have been responsible for several airplane crashes into water, for example Birgenair Flight 301 and AeroPeru Flight 603 in 1996. <xref rid="pbio-0020216-Heran2" ref-type="bibr">Heran and Lindauer (1963)</xref> likewise observed that honeybees flying over lakes sometimes lost altitude and plunged into the water. However, the new study by <xref rid="pbio-0020216-Tautz1" ref-type="bibr">Tautz et al. (2004)</xref> also shows that most bees will reliably fly over prolonged stretches of water without accident. Furthermore, even though bees experience only a small increase in subjective travel distance when flying over water, it is not zero. This indicates that bees do perhaps resort to an internal measure of flight distance when other cues fail. For example, bumblebees walking to a food source in absolute darkness, that is, in the complete absence of visual cues, are able to correctly gauge travel distance (<xref rid="pbio-0020216-Chittka4" ref-type="bibr">Chittka et al. 1999</xref>), indicating that an internal odometer, possibly based on energy consumption, also exists. It appears that animal navigation, just like aviation, relies on multiple backup systems that support each other and can compensate if one system fails in a certain context.</p><p>Spying on honeybee dances can not only tell us about the cues they use for navigation, but also allows insights into the cognitive architecture that governs other aspects of bee behaviour, such as the assessment of flower quality. We've learned that bees prefer high over low nectar concentrations because this is reflected in their dances. When bees find better nectar, they dance more enthusiastically, that is, the number of dance circuits per minute increases (<xref rid="pbio-0020216-Seeley1" ref-type="bibr">Seeley et al. 2000</xref>; <xref rid="pbio-0020216-Waddington1" ref-type="bibr">Waddington 2001</xref>). However, <xref rid="pbio-0020216-Waddington1" ref-type="bibr">Waddington (2001)</xref> found that the relationship between actual and perceived nectar quality is nonlinear. In fact, it is a positive but decelerating relationship, so that an increase in sucrose concentration from 10% to 20% results in twice the difference in dance rate that an increase from 50% to 60% does. Interestingly, the perceived change in quality is stronger when there is a <italic>decrease</italic> than when there is an <italic>increase</italic> in nectar quality of the same magnitude. Such asymmetric perception of gains and losses is well known in humans, where it has been linked to risk-aversive behaviour (<xref rid="pbio-0020216-Tversky1" ref-type="bibr">Tversky and Kahnemann 1981</xref>). Unfortunately, animal subjects often do not yield this type of information very readily. Only in their own language do they reveal many of their perceptual peculiarities. Using the bee language as a window into insect visual perception has been a wonderful tool and is a promising avenue for further research into the question of how miniature brains encode the world around them.</p></body><back><fn-group><fn id="n1" fn-type="current-aff"><p>Lars Chittka is at the School of Biological Sciences, Queen Mary College, University of London, London, United Kingdom. E-mail: <email>l.chittka@qmul.ac.uk</email>
</p></fn></fn-group><ref-list><title>References</title><ref id="pbio-0020216-Autrum1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Autrum</surname><given-names>HJ</given-names></name><name><surname>von Zwehl</surname><given-names>V</given-names></name></person-group><article-title>Die spektrale Empfindlichkeit einzelner Sehzellen des Bienenauges</article-title><source>Z Vergl Physiol</source><year>1964</year><volume>48</volume><fpage>357</fpage><lpage>384</lpage></element-citation></ref><ref id="pbio-0020216-Chittka1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Optimal sets of colour receptors and opponent processes for coding of natural objects in insect vision</article-title><source>J Theor Biol</source><year>1996</year><volume>181</volume><fpage>179</fpage><lpage>196</lpage></element-citation></ref><ref id="pbio-0020216-Chittka2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Geiger</surname><given-names>K</given-names></name></person-group><article-title>Can honeybees count landmarks?</article-title><source>Anim Behav</source><year>1995</year><volume>49</volume><fpage>159</fpage><lpage>164</lpage></element-citation></ref><ref id="pbio-0020216-Chittka3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Tautz</surname><given-names>J</given-names></name></person-group><article-title>The spectral input to honeybee visual odometry</article-title><source>J Exp Biol</source><year>2003</year><volume>206</volume><fpage>2393</fpage><lpage>2397</lpage><pub-id pub-id-type="pmid">12796456</pub-id></element-citation></ref><ref id="pbio-0020216-Chittka4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Williams</surname><given-names>NM</given-names></name><name><surname>Rasmussen</surname><given-names>H</given-names></name><name><surname>Thomson</surname><given-names>JD</given-names></name></person-group><article-title>Navigation without vision: Bumblebee orientation in complete darkness</article-title><source>Proc R Soc Lond B Biol Sci</source><year>1999</year><volume>266</volume><fpage>45</fpage><lpage>50</lpage></element-citation></ref><ref id="pbio-0020216-Chittka5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Dyer</surname><given-names>AG</given-names></name><name><surname>Bock</surname><given-names>F</given-names></name><name><surname>Dornhaus</surname><given-names>A</given-names></name></person-group><article-title>Bees trade off foraging speed for accuracy</article-title><source>Nature</source><year>2003</year><volume>424</volume><fpage>388</fpage><lpage>388</lpage><pub-id pub-id-type="pmid">12879057</pub-id></element-citation></ref><ref id="pbio-0020216-Esch1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esch</surname><given-names>HE</given-names></name><name><surname>Burns</surname><given-names>JE</given-names></name></person-group><article-title>Honeybees use optic flow to measure the distance of a food source</article-title><source>Naturwissenschaften</source><year>1995</year><volume>82</volume><fpage>38</fpage><lpage>40</lpage></element-citation></ref><ref id="pbio-0020216-Esch2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esch</surname><given-names>HE</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Srinivasan</surname><given-names>MV</given-names></name><name><surname>Tautz</surname><given-names>J</given-names></name></person-group><article-title>Honeybee dances communicate distances measured by optic flow</article-title><source>Nature</source><year>2001</year><volume>411</volume><fpage>581</fpage><lpage>583</lpage><pub-id pub-id-type="pmid">11385571</pub-id></element-citation></ref><ref id="pbio-0020216-Giurfa1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Giurfa</surname><given-names>M</given-names></name><name><surname>Lehrer</surname><given-names>M</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Thomson</surname><given-names>JD</given-names></name></person-group><article-title>Honeybee vision and floral displays: From detection to close-up recognition</article-title><source>Cognitive ecology of pollination</source><year>2001</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>61</fpage><lpage>82</lpage></element-citation></ref><ref id="pbio-0020216-Heran1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heran</surname><given-names>H</given-names></name></person-group><article-title>Ein Beitrag zur Frage nach der Wahrnehmungsgrundlage der Entfernungsweisung der Bienen</article-title><source>Z Vergl Physiol</source><year>1956</year><volume>42</volume><fpage>103</fpage><lpage>163</lpage></element-citation></ref><ref id="pbio-0020216-Heran2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heran</surname><given-names>H</given-names></name><name><surname>Lindauer</surname><given-names>M</given-names></name></person-group><article-title>Windkompensation und Seitenwindkorrektur der Bienen beim Flug ueber Wasser</article-title><source>Z Vergl Physiol</source><year>1963</year><volume>47</volume><fpage>39</fpage><lpage>55</lpage></element-citation></ref><ref id="pbio-0020216-Seeley1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeley</surname><given-names>TD</given-names></name><name><surname>Mikheyev</surname><given-names>AS</given-names></name><name><surname>Pagano</surname><given-names>GJ</given-names></name></person-group><article-title>Dancing bees tune both duration and rate of waggle-run production in relation to nectar-source profitability</article-title><source>J Comp Physiol A Neuroethol Sens Neural Behav Physiol</source><year>2000</year><volume>186</volume><fpage>813</fpage><lpage>819</lpage></element-citation></ref><ref id="pbio-0020216-Si1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Si</surname><given-names>A</given-names></name><name><surname>Srinivasan</surname><given-names>MV</given-names></name><name><surname>Zhang</surname><given-names>SW</given-names></name></person-group><article-title>Honeybee navigation: Properties of the visually driven &#x02018;odometer&#x02019;</article-title><source>J Exp Biol</source><year>2003</year><volume>206</volume><fpage>1265</fpage><lpage>1273</lpage><pub-id pub-id-type="pmid">12624162</pub-id></element-citation></ref><ref id="pbio-0020216-Spaethe1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaethe</surname><given-names>J</given-names></name><name><surname>Tautz</surname><given-names>J</given-names></name><name><surname>Chittka</surname><given-names>L</given-names></name></person-group><article-title>Visual constraints in foraging bumblebees: Flower size and color affect search time and flight behavior</article-title><source>Proc Nat Acad Sci U S A</source><year>2001</year><volume>98</volume><fpage>3898</fpage><lpage>3903</lpage></element-citation></ref><ref id="pbio-0020216-Srinivasan1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>MV</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Altwein</surname><given-names>M</given-names></name><name><surname>Tautz</surname><given-names>J</given-names></name></person-group><article-title>Honeybee navigation: Nature and calibration of the &#x02018;odometer&#x02019;</article-title><source>Science</source><year>2000</year><volume>287</volume><fpage>851</fpage><lpage>853</lpage><pub-id pub-id-type="pmid">10657298</pub-id></element-citation></ref><ref id="pbio-0020216-Tautz1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tautz</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Spaethe</surname><given-names>J</given-names></name><name><surname>Brockmann</surname><given-names>A</given-names></name><name><surname>Si</surname><given-names>A</given-names></name><etal/></person-group><article-title>Honeybee odometry: Performance in varying natural terrain</article-title><source>PLoS Biol</source><year>2004</year><volume>2</volume><fpage>e211</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0020211</pub-id><pub-id pub-id-type="pmid">15252454</pub-id></element-citation></ref><ref id="pbio-0020216-Tversky1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>A</given-names></name><name><surname>Kahnemann</surname><given-names>D</given-names></name></person-group><article-title>The framing of decisions and psychology of choice</article-title><source>Science</source><year>1981</year><volume>211</volume><fpage>453</fpage><lpage>458</lpage><pub-id pub-id-type="pmid">7455683</pub-id></element-citation></ref><ref id="pbio-0020216-vonFrisch1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>von Frisch</surname><given-names>K</given-names></name></person-group><article-title>The dance language and orientation of bees</article-title><year>1967</year><publisher-loc>Cambridge (Massachusetts)</publisher-loc><publisher-name>Harvard University Press</publisher-name><lpage>566</lpage></element-citation></ref><ref id="pbio-0020216-Waddington1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Waddington</surname><given-names>KD</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Chittka</surname><given-names>L</given-names></name><name><surname>Thomson</surname><given-names>JD</given-names></name></person-group><article-title>Subjective evaluation and choice behavior by nectar- and pollencollecting bees</article-title><source>Cognitive ecology of pollination</source><year>2001</year><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>41</fpage><lpage>60</lpage></element-citation></ref></ref-list></back></article>
