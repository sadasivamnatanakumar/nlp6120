<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Med Educ</journal-id><journal-title>BMC Medical Education</journal-title><issn pub-type="epub">1472-6920</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15488152</article-id><article-id pub-id-type="pmc">PMC526209</article-id><article-id pub-id-type="publisher-id">1472-6920-4-22</article-id><article-id pub-id-type="doi">10.1186/1472-6920-4-22</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Student evaluation of an OSCE in paediatrics at the University of the West Indies, Jamaica</article-title></title-group><contrib-group><contrib id="A1" equal-contrib="yes" corresp="yes" contrib-type="author"><name><surname>Pierre</surname><given-names>Russell B</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>rptrin@cwjamaica.com</email></contrib><contrib id="A2" equal-contrib="yes" contrib-type="author"><name><surname>Wierenga</surname><given-names>Andrea</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>andreawierenga@bellsouth.net</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Barton</surname><given-names>Michelle</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>mbarforbes@hotmail.com</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Branday</surname><given-names>J Michael</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>joseph.branday@uwimona.edu.jm</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Christie</surname><given-names>Celia DC</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>celia.christiesamuels@uwimona.edu.jm</email></contrib></contrib-group><aff id="I1"><label>1</label>Department of Obstetrics, Gynaecology and Child Health, University of the West Indies, Jamaica</aff><aff id="I2"><label>2</label>Undergraduate Affairs, Dean's Office, Faculty of Medical Sciences, Jamaica</aff><pub-date pub-type="collection"><year>2004</year></pub-date><pub-date pub-type="epub"><day>16</day><month>10</month><year>2004</year></pub-date><volume>4</volume><fpage>22</fpage><lpage>22</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1472-6920/4/22"/><history><date date-type="received"><day>8</day><month>4</month><year>2004</year></date><date date-type="accepted"><day>16</day><month>10</month><year>2004</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2004 Pierre et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2004</copyright-year><copyright-holder>Pierre et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Pierre
               B
               Russell
               
               rptrin@cwjamaica.com
            </dc:author><dc:title>
            Student evaluation of an OSCE in paediatrics at the University of the West Indies, Jamaica
         </dc:title><dc:date>2004</dc:date><dcterms:bibliographicCitation>BMC Medical Education 4(1): 22-. (2004)</dcterms:bibliographicCitation><dc:identifier type="sici">1472-6920(2004)4:1&#x0003c;22&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1472-6920</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>The Faculty of Medical Sciences, University of the West Indies first implemented the Objective Structured Clinical Examination (OSCE) in the final MB Examination in Medicine and Therapeutics during the 2000&#x02013;2001 academic year. Simultaneously, the Child Health Department initiated faculty and student training, and instituted the OSCE as an assessment instrument during the Child Health (Paediatric) clerkship in year 5. The study set out to explore student acceptance of the OSCE as part of an evaluation of the Child Health clerkship.</p></sec><sec sec-type="methods"><title>Methods</title><p>A self-administered questionnaire was completed by successive groups of students immediately after the OSCE at the end of each clerkship rotation. Main outcome measures were student perception of examination attributes, which included the quality of instructions and organisation, the quality of performance, authenticity and transparency of the process, and usefulness of the OSCE as an assessment instrument compared to other formats.</p></sec><sec><title>Results</title><p>There was overwhelming acceptance of the OSCE in Child Health with respect to the comprehensiveness (90%), transparency (87%), fairness (70%) and authenticity of the required tasks (58&#x02013;78%). However, students felt that it was a strong anxiety-producing experience. And concerns were expressed regarding the ambiguity of some questions and inadequacy of time for expected tasks.</p></sec><sec><title>Conclusion</title><p>Student feedback was invaluable in influencing faculty teaching, curriculum direction and appreciation of student opinion. Further psychometric evaluation will strengthen the development of the OSCE.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>The assessment of student's clinical competence is of paramount importance, and there are several means of evaluating student performance in medical examinations [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>]. The Objective Structured Clinical Examination (OSCE) is an approach to student assessment in which aspects of clinical competence are evaluated in a comprehensive, consistent and structured manner, with close attention to the objectivity of the process [<xref ref-type="bibr" rid="B3">3</xref>]. The OSCE was introduced by Harden in 1975 [<xref ref-type="bibr" rid="B4">4</xref>], and first described as an assessment format in Paediatrics (Child Health) by Waterson and colleagues [<xref ref-type="bibr" rid="B5">5</xref>]. Since its inception, the OSCE has been increasingly used to provide formative and summative assessment in various medical disciplines worldwide [<xref ref-type="bibr" rid="B6">6</xref>], including non-clinical disciplines [<xref ref-type="bibr" rid="B7">7</xref>].</p><p>The University of the West Indies was established in 1948 as a medical college of the University of London, which granted external degrees to those who successfully completed the course [<xref ref-type="bibr" rid="B8">8</xref>]. The Faculty of Medical Sciences located on four campuses, on the islands of Jamaica, Bahamas, Barbados and Trinidad and Tobago, conducts bi-annual final examinations at the end of year 5. The 'traditional' format of examination that included long case, short cases and oral examination, was preserved until recent changes in the curriculum. In response to recommendations to improve the validity and fairness of the examination through adoption of proven methods and approaches in assessment and evaluation in medical education, the Faculty of Medical Sciences (FMS), University of the West Indies (UWI) initiated the OSCE as a formal method of assessment for the final examination in Medicine and Therapeutics, Child Health, Community Health and Psychiatry, in November 2000. Students and faculty were exposed for the first time to a relatively new assessment instrument in which aspects of competence (communication, history-taking and technical skills) were assessed in a structured, formal manner.</p><p>The Section of Child Health, Mona, Jamaica, implemented the OSCE examination as an end-of clerkship assessment for students in their 5<sup>th </sup>year, during the 1999&#x02013;2000 academic year. It was felt timely in order to (a) direct and motivate student learning in areas not previously assessed in the 'traditional' curriculum, (b) verify students' competence in fundamental paediatric clinical skills, and (c) provide a forum for feedback to students on their strengths and weaknesses in clinical skills. It was thought that it would enhance faculty and student acceptance of this new assessment tool and promote faculty training for the newly introduced final OSCE examination.</p><p>In the absence of any previous information from this institution, the study was designed to evaluate student overall perception of the end-of-clerkship OSCE, determine student acceptability of the process and provide feedback to enhance further development of the assessment.</p></sec><sec sec-type="methods"><title>Methods</title><p>The OSCE comprised a circuit of thirteen stations, which involved completion of a number of tasks such as examination of a system, eliciting a focussed history, counselling or communicating a problem, performing a procedure and problem-solving oriented around patient and laboratory data, and photographic material (Figure <xref ref-type="fig" rid="F1">1</xref>). The areas assessed included cardiovascular, respiratory, abdomen, neurological, developmental, dysmorphism and nutrition. This assessment format allowed the controlled exposure of students to a wide variety of paediatric clinical skills within a relatively short time period. Each station was 7 minutes duration with the exception of the 14-minute history-taking station. One minute was given between stations to facilitate change and the reading of instructions. With the inclusion of strategically placed rest stations, to reduce student and patient fatigue, all students completed the circuit over a 2-hour period.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p>Plan of OSCE circuit</p></caption><graphic xlink:href="1472-6920-4-22-1"/></fig><p>A standardised technique of marking was used and student performance was assessed by criterion reference for each station. Criterion-based scoring was used, with each checklist item scored as 0 (omitted, incorrect or inadequate), or 1&#x02013;2 (correct or adequate).</p><p>Face and content validity of each checklist was established by review and consensus by a core group of senior paediatricians. Stations were first selected to represent the curricular goals and objectives and to reflect authentic clinical situations. Checklists were designed to include the features thought to be most important by the development committee. Through discussions, consensus was achieved on the checklist items and structure.</p><p>The study was conducted during the period July 2001 to December 2002. Five groups of students participated in the process, during their respective clerkship rotations. Student groups had at least two briefing sessions before the OSCE, and included an orientation about the examination process (both end-of-clerkship and final MB) and a review of commonly assessed competences. They were also apprised of the valuable contribution they could make towards improving the assessment and encouraged to participate in the evaluation.</p><p>A cross-sectional survey using a 32-item self-administered questionnaire was completed at the end of each OSCE [<xref ref-type="bibr" rid="B9">9</xref>]. Students were asked to evaluate the content, structure, and organization of the OSCE, rate the quality of performance and objectivity of the OSCE process, and to give their opinion about the usefulness of the OSCE as an assessment instrument compared to other forms which they had experienced (essays, multiple choice questions, long and short cases, general clerkship rating).</p><p>Participation was on a voluntary basis and students were assured that those who declined involvement in the survey would not be penalised. The Curricular Affairs Section handled the administration and analysis of the questionnaires. Ethical approval was received from the University Hospital of the West Indies/University of the West Indies Faculty of Medical Sciences Ethics Committee. Following completion of the questionnaire, an OSCE review session was conducted with the students for feedback and teaching purposes, at the end of the clerkship. Students were given the opportunity to review their individual performances at the respective stations. Examiner evaluations were also used in the feedback process.</p><p>Data were collated and descriptive and non-parametric tests applied using Stata version7 [<xref ref-type="bibr" rid="B10">10</xref>]. Basic statistical analysis of the Likert items was conducted by calculating frequencies, means and standard deviations. Qualitative analysis was done through a form of content analysis by identifying themes in student responses and grouping responses according to thematic content. Two of the authors individually conducted this content analysis and identified themes and final grouping of responses were developed by consensus.</p></sec><sec><title>Results</title><sec><title>OSCE evaluation</title><p>Eighty-one students responded to the questionnaire, representing 92 % (81/88) of those who completed the Clerkship.</p><p>The majority of students agreed that the OSCE was comprehensive and covered a wide range of knowledge (95%) and clinical competencies (86%) in Child Health. Three quarters (78%) also agreed that the assessment process helped to identify weaknesses and gaps in their competencies (Table <xref ref-type="table" rid="T1">1</xref>).</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>OSCE evaluation</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Question</td><td align="center">Agree %</td><td align="center">Neutral %</td><td align="center">Disagree %</td><td align="center">No comment %</td></tr></thead><tbody><tr><td align="left">Exam was fair</td><td align="center">68</td><td align="center">19</td><td align="center">12</td><td align="center">1</td></tr><tr><td align="left">Wide knowledge area covered</td><td align="center">95</td><td align="center">5</td><td></td><td></td></tr><tr><td align="left">Needed more time at stations</td><td align="center">70</td><td align="center">22.5</td><td align="center">7.5</td><td></td></tr><tr><td align="left">Exams well administered</td><td align="center">73</td><td align="center">16</td><td align="center">11</td><td></td></tr><tr><td align="left">Exams very stressful</td><td align="center">67</td><td align="center">20</td><td align="center">13</td><td></td></tr><tr><td align="left">Exams well structured &#x00026; sequenced</td><td align="center">81.5</td><td align="center">17</td><td align="center">2.5</td><td></td></tr><tr><td align="left">Exam minimized chance of failing</td><td align="center">28</td><td align="center">40.5</td><td align="center">30</td><td align="center">1.5</td></tr><tr><td align="left">OSCE less stressful than other exams</td><td align="center">15</td><td align="center">40</td><td align="center">35</td><td align="center">10</td></tr><tr><td align="left">Allowed student to compensate in some areas</td><td align="center">67</td><td align="center">21</td><td align="center">12</td><td></td></tr><tr><td align="left">Highlighted areas of weakness</td><td align="center">78</td><td align="center">13</td><td align="center">9</td><td></td></tr><tr><td align="left">Exam intimidating</td><td align="center">48</td><td align="center">32</td><td align="center">20</td><td></td></tr><tr><td align="left">Student aware of level of information needed</td><td align="center">53</td><td align="center">26</td><td align="center">21</td><td></td></tr><tr><td align="left">Wide range of clinical skills covered</td><td align="center">86</td><td align="center">6</td><td align="center">8</td><td></td></tr></tbody></table></table-wrap><p>Most (73&#x02013;82%) felt that the exam was well administered, and that the stations were arranged in an organised and well-sequenced order.</p><p>Students believed that the assessment was fair (68%). Fifty-three percent were aware of the level of information required at each station, yet 28% felt that the examination process minimized their chances of failing.</p><p>Students found the OSCE to be intimidating (48%) and more stressful (35%) than other assessment formats to which they were previously exposed. And most (70%) felt that they needed more time to complete the stations.</p></sec><sec><title>Performance testing</title><p>The majority of students felt they were well oriented about the exam and that the required tasks were consistent with the actual curriculum that they were taught. They also felt that the process was fair but were not as satisfied with the time allocation for each station (Table <xref ref-type="table" rid="T2">2</xref>).</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>Quality of performance testing</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Question</td><td align="center">Not at all %</td><td align="center">Neutral %</td><td align="center">To great extent %</td></tr></thead><tbody><tr><td align="left">Fully aware of nature of exam</td><td align="center">4</td><td align="center">9</td><td align="center">87</td></tr><tr><td align="left">Tasks reflected those taught</td><td align="center">4</td><td align="center">23</td><td align="center">73</td></tr><tr><td align="left">Time at each station was adequate</td><td align="center">44</td><td align="center">35</td><td align="center">21</td></tr><tr><td align="left">Setting and context at each station felt authentic</td><td align="center">18</td><td align="center">24</td><td align="center">58</td></tr><tr><td align="left">Instructions were clear and unambiguous</td><td align="center">15</td><td align="center">27</td><td align="center">58</td></tr><tr><td align="left">Tasks asked to perform were fair</td><td align="center">3</td><td align="center">27</td><td align="center">70</td></tr><tr><td align="left">Sequence of stations logical and appropriate</td><td align="center">13</td><td align="center">30</td><td align="center">57</td></tr><tr><td align="left">Exam provided opportunities to learn</td><td align="center">11</td><td align="center">21</td><td align="center">69</td></tr></tbody></table></table-wrap><p>Most saw the OSCE as a useful learning experience and that the content reflected real life situations in Child Health. More than half of the students were satisfied with the conduct, organisation and administration of the OSCE.</p></sec><sec><title>Perception of validity and reliability</title><p>Although half of the students believed that the scores were standardised, they were unsure whether their scores were an actual reflection of their paediatric clinical skills (Table <xref ref-type="table" rid="T3">3</xref>). Student responses to the question about bias due to gender, personality or ethnicity, were not interpretable.</p><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>Student perception of validity and reliability</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Question</td><td align="center">Not at all %</td><td align="center">Neutral %</td><td align="center">To great extent %</td></tr></thead><tbody><tr><td align="left">OSCE exam scores provide true measure of essential clinical skills in paediatrics</td><td align="center">14</td><td align="center">43</td><td align="center">43</td></tr><tr><td align="left">OSCE scores are standardized</td><td align="center">8</td><td align="center">37</td><td align="center">55</td></tr><tr><td align="left">OSCE practical and useful experience</td><td align="center">4</td><td align="center">23</td><td align="center">73</td></tr><tr><td align="left">Personality, ethnicity and gender will not affect OSCE scores</td><td align="center">18</td><td align="center">19</td><td align="center">63</td></tr></tbody></table></table-wrap></sec><sec><title>Comparing assessment formats</title><p>Students were asked to rate the following assessment instruments to which they had been exposed (multiple choice questions, essays / short answer questions, general clerkship ratings, OSCE). A likert scale was used to assess each according to the evaluative labels (Table <xref ref-type="table" rid="T4">4</xref>).</p><table-wrap position="float" id="T4"><label>Table 4</label><caption><p>Student rating of assessment formats</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Question:</td><td align="center">Difficult %</td><td align="center">Undecided %</td><td align="center">Easy %</td></tr></thead><tbody><tr><td align="left" colspan="4"><bold>Which of the following formats is easiest?</bold></td></tr><tr><td align="left">MCQ</td><td align="center">48</td><td align="center">26</td><td align="center">26</td></tr><tr><td align="left">Essay/SAQ</td><td align="center">38</td><td align="center">44</td><td align="center">18</td></tr><tr><td align="left">OSCE</td><td align="center">43</td><td align="center">45</td><td align="center">12</td></tr><tr><td align="left">Clerkship ratings</td><td align="center">21</td><td align="center">47</td><td align="center">32</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">Question:</td><td align="center">Unfair %</td><td align="center">Undecided %</td><td align="center">Fair %</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left" colspan="4"><bold>Which of the following formats is fairest?</bold></td></tr><tr><td align="left">MCQ</td><td align="center">29</td><td align="center">28</td><td align="center">43</td></tr><tr><td align="left">Essay/SAQ</td><td align="center">7</td><td align="center">25</td><td align="center">68</td></tr><tr><td align="left">OSCE</td><td align="center">4</td><td align="center">16</td><td align="center">80</td></tr><tr><td align="left">Clerkship ratings</td><td align="center">16</td><td align="center">26</td><td align="center">58</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">Question:</td><td align="center">Learn very little %</td><td align="center">Undecided %</td><td align="center">Learn a lot %</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left" colspan="4"><bold>From which of the following formats do you learn most?</bold></td></tr><tr><td align="left">MCQ</td><td align="center">28</td><td align="center">37</td><td align="center">35</td></tr><tr><td align="left">Essay/SAQ</td><td align="center">12</td><td align="center">37</td><td align="center">51</td></tr><tr><td align="left">OSCE</td><td align="center">15</td><td align="center">25</td><td align="center">60</td></tr><tr><td align="left">Clerkship ratings</td><td align="center">20</td><td align="center">18</td><td align="center">62</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left">Question:</td><td align="center">Used much less %</td><td align="center">Undecided %</td><td align="center">Used much more %</td></tr><tr><td colspan="4"><hr></hr></td></tr><tr><td align="left" colspan="4"><bold>Which of the following formats should be used more often in the clinical years of the programme?</bold></td></tr><tr><td align="left">MCQ</td><td align="center">31</td><td align="center">59</td><td align="center">10</td></tr><tr><td align="left">Essay/SAQ</td><td align="center">9</td><td align="center">52</td><td align="center">39</td></tr><tr><td align="left">OSCE</td><td align="center">5</td><td align="center">43</td><td align="center">52</td></tr><tr><td align="left">Clerkship ratings</td><td align="center">12</td><td align="center">56</td><td align="center">32</td></tr></tbody></table><table-wrap-foot><p>MCQ &#x02013; multiple choice question; SAQ &#x02013; short answer question; OSCE -objective structured clinical examination</p></table-wrap-foot></table-wrap><p>Thirty-two percent of students felt that the clerkship rating was the easiest, while 48% rated MCQ as a more difficult form of assessment. The OSCE was overwhelmingly considered the fairest assessment format (80%), and essays (68%) to a lesser extent. OSCE (60%) and clerkship ratings (62%) were considered the most useful learning experiences. Compared to the other assessment formats, 52% considered that the OSCE should be used most in the clinical years.</p></sec><sec><title>Qualitative data</title><p>Students were asked follow-up questions related to positive and negative aspects of the OSCE and suggestions for improvement. The open-ended responses were grouped by thematic content.</p><p>Among the positive attributes of the OSCE, students re-affirmed that the assessment was comprehensive (44 comments) and that it was an objective and fair process (43 comments). Some indicated that the opportunity for feedback helped to motivate them and drive the learning process (21 comments).</p><p>Students felt that the time allocated to perform expected tasks was insufficient (36 comments), and that the procedure was stressful (18 comments) and tiring (13 comments). Technical problems (28 comments) included unclear instructions, inadequate time provision and instructions between stations and detention of some candidates at stations by examiners.</p><p>Suggestions for improvement included increasing the duration of stations (29 comments), ensuring clear instructions (8 comments) and having more realistic expectations of students for the expected tasks. A few students wished to have more training with the OSCE and suggested that the examination should be videotaped to increase objectivity and permit review.</p></sec></sec><sec><title>Discussion</title><p>Students overwhelmingly perceived that the OSCE in Child Health had good construct validity. This was demonstrated by the favourable responses concerning transparency and fairness of the examination process, and the authenticity of the required tasks per station. Excellent levels of acceptance of the OSCE by students have been previously described in the literature [<xref ref-type="bibr" rid="B11">11</xref>-<xref ref-type="bibr" rid="B14">14</xref>]. They however expressed concerns and uncertainty about whether the process would minimize their chances of failing or that the results were a true reflection of their clinical skills. This was understandable, since it was their first encounter with this type of assessment.</p><p>Several felt that the examination was stressful and intimidating, yet paradoxically some students perceived it as an enjoyable, practical experience. Studies surveying student attitudes during the OSCE have documented that the OSCE can be a strong anxiety-producing experience, and that the level of anxiety changes little as students progress through the examination [<xref ref-type="bibr" rid="B15">15</xref>].</p><p>It is well recognised that assessment is a catalyst for both curriculum change and student learning. The students recognised the value of the instrument for formative evaluation. In addition, as many medical schools have adopted a student-centred approach to medical education, greater student participation in quality assurance exercises must be encouraged. Students perceived the OSCE to be fairer than any other assessment format to which they were exposed. The findings were somewhat similar to the views of students at Newcastle medical school [<xref ref-type="bibr" rid="B16">16</xref>]. Although student views on fairness may not be consistent with published literature, the impact and influence on acceptability of the instrument should be noted.</p><p>They offered constructive criticism of the structure and organisation of the process. At some stations they felt that the instructions were ambiguous and that the time allocation was inadequate for the expected tasks. The feedback was invaluable and facilitated a critical review and modification of the station content and conduct of the examination over time. Faculty perceived that the concerns about time allocation per station and the degree of stress expressed by the students were due to inadequate preparation for the examination, particularly in competences not previously assessed in the 'traditional' examination.</p><p>The high student response rate has helped to ensure that the findings presented are a valid representation of student opinion. Students have traditionally viewed the end-of-clerkship assessment as a 'high-stake' examination and also perceive it as predictive of their performance at their final MB examination. Student perception of the OSCE however, may have been influenced by anxiety and lack of confidence associated with a new assessment. The responses may also have been affected by the timing of the inquiry (immediately after the examination); hence student stress and fatigue should be taken into consideration. Whereas the high response rate ensured that the views were reasonable representative of the students, differences in assessors could have influenced the interpretation of the results of open-ended responses.</p><p>Implementing the OSCE in Child Health at the University of the West Indies, Jamaica has been challenging, however student participation in the evaluation and their overall acceptance of the instrument have been encouraging. Feedback from students and faculty has been useful in effecting improvements to the process and greater emphasis has been placed on the teaching and evaluation of history taking, communication and technical competencies. It is also sending a clear message to students that the achievement of overall competence is imperative to clinical practice in the current environment. Ultimately, these provide the loop necessary to drive the continuum of curriculum development. This has been timely considering that the Faculty of Medical Sciences, Jamaica is undergoing significant reform [<xref ref-type="bibr" rid="B17">17</xref>]. Further developments involving psychometric evaluation will strengthen the process.</p></sec><sec><title>Conclusions</title><p>In summary, the findings highlight the need for student participation in the development of new assessment tools in medical curricula. Student acceptance will be more favourable for assessment formats that they perceive to be transparent, authentic and valid. 'Traditional' medical curricula must be responsive to global paradigm shifts in undergraduate medical education.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors' contributions</title><p>RP conceptualised the study; developed the proposal, coordinated the conduct of the project, completed initial data entry and analysis, and wrote the report. AW participated in the design of the study, coordinated the conduct of the project, performed the statistical analysis, and assisted in writing the report. MB was the main organizer of the clerkship OSCE, and assisted in editing the final report. MBr and CC participated in overall supervision of project and revision of report. All authors read and approved the final manuscript.</p></sec><sec><title>Pre-publication history</title><p>The pre-publication history for this paper can be accessed here:</p><p><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1472-6920/4/22/prepub"/></p></sec></body><back><ack><sec><title>Acknowledgements</title><p>We wish to thank Dr. Jerome De Lisle of the Centre for Medical Science Education (CMSE), EWMSC, Trinidad, for professional advice and permission to use the questionnaire in this study. We also express our gratitude to the participating students and lecturers in Child Health who contributed to the implementation of the OSCE in the department.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Harden</surname><given-names>RM</given-names></name></person-group><article-title>How to assess clinical competence &#x02013; an overview</article-title><source>Med Teach</source><year>1979</year><volume>1</volume><fpage>289</fpage><lpage>296</lpage></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fowell</surname><given-names>SL</given-names></name><name><surname>Bligh</surname><given-names>JG</given-names></name></person-group><article-title>Recent developments in assessing medical students</article-title><source>Postgrad Med J</source><year>1998</year><volume>74</volume><fpage>18</fpage><lpage>24</lpage><pub-id pub-id-type="pmid">9538481</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Harden</surname><given-names>RM</given-names></name></person-group><article-title>What is an OSCE?</article-title><source>Med Teach</source><year>1988</year><volume>10</volume><fpage>19</fpage><lpage>22</lpage><pub-id pub-id-type="pmid">3221760</pub-id></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Harden</surname><given-names>RM</given-names></name><name><surname>Stevenson</surname><given-names>M</given-names></name><name><surname>Downie</surname><given-names>WW</given-names></name><name><surname>Wilson</surname><given-names>GM</given-names></name></person-group><article-title>Assessment of clinical competence using objective structured examination</article-title><source>Br Med J</source><year>1975</year><volume>1</volume><fpage>447</fpage><lpage>451</lpage><pub-id pub-id-type="pmid">1115966</pub-id></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Waterson</surname><given-names>T</given-names></name><name><surname>Cater</surname><given-names>JI</given-names></name><name><surname>Mitchell</surname><given-names>RG</given-names></name></person-group><article-title>An objective undergraduate clinical examination in child health</article-title><source>Arch Dis Child</source><year>1980</year><volume>55</volume><fpage>917</fpage><lpage>922</lpage><pub-id pub-id-type="pmid">7458391</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Carraccio</surname><given-names>C</given-names></name><name><surname>Englander</surname><given-names>R</given-names></name></person-group><article-title>The objective structured clinical examination, a step in the direction of competency-based evaluation</article-title><source>Arch Pediatr Adolesc Med</source><year>2000</year><volume>154</volume><fpage>736</fpage><lpage>741</lpage><pub-id pub-id-type="pmid">10891028</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Harden</surname><given-names>RM</given-names></name><name><surname>Caincross</surname><given-names>RG</given-names></name></person-group><article-title>The assessment of practical skills: the Objective Structured Practical Examination (OSPE)</article-title><source>Stud High Educ</source><year>1980</year><volume>5</volume><fpage>187</fpage><lpage>196</lpage></citation></ref><ref id="B8"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sherlock</surname><given-names>P</given-names></name><name><surname>Nettleford</surname><given-names>R</given-names></name></person-group><source>The University of the West Indies: a Caribbean response to the challenge of change</source><year>1990</year><publisher-name>Hong Kong: Macmillan Caribbean</publisher-name></citation></ref><ref id="B9"><citation citation-type="book"><person-group person-group-type="author"><name><surname>De Lisle</surname><given-names>J</given-names></name></person-group><source>2001 Phase 2, OSCE student evaluation form</source><year>2001</year><publisher-name>Mount Hope, Trinidad The Centre for Medical Science Education, Faculty of Medical Sciences</publisher-name></citation></ref><ref id="B10"><citation citation-type="book"><person-group person-group-type="author"><collab>StataCorp</collab></person-group><source>Stata Statistical Software: Release 70</source><year>2001</year><publisher-name>College Station, TX: StataCorp LP</publisher-name></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Newble</surname><given-names>DI</given-names></name></person-group><article-title>Eight years experience with a structured clinical examination</article-title><source>Med Educ</source><year>1988</year><volume>22</volume><fpage>200</fpage><lpage>204</lpage><pub-id pub-id-type="pmid">3405114</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Duerson</surname><given-names>MC</given-names></name><name><surname>Romrell</surname><given-names>LJ</given-names></name><name><surname>Stevens</surname><given-names>CB</given-names></name></person-group><article-title>Impacting faculty teaching and student performance: nine years' experience with the objective structured clinical examination</article-title><source>Teach Learn Med</source><year>2000</year><volume>12</volume><fpage>176</fpage><lpage>182</lpage><pub-id pub-id-type="pmid">11273366</pub-id><pub-id pub-id-type="doi">10.1207/S15328015TLM1204_3</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kowlowitz</surname><given-names>V</given-names></name><name><surname>Hoole</surname><given-names>AJ</given-names></name><name><surname>Sloane</surname><given-names>PD</given-names></name></person-group><article-title>Implementation of the Objective Structured Clinical Examination in a traditional medical school</article-title><source>Acad Med</source><year>1991</year><volume>66</volume><fpage>345</fpage><lpage>347</lpage><pub-id pub-id-type="pmid">2069655</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Woodburn</surname><given-names>J</given-names></name><name><surname>Sutcliffe</surname><given-names>N</given-names></name></person-group><article-title>The reliability, validity and evaluation of the objective structured clinical examination in podiatry</article-title><source>Assessment Evaluation Higher Educ</source><year>1996</year><volume>21</volume><fpage>131</fpage><lpage>147</lpage></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>R</given-names></name><name><surname>Heard</surname><given-names>J</given-names></name><name><surname>Savidge</surname><given-names>M</given-names></name><name><surname>Bittengle</surname><given-names>J</given-names></name><name><surname>Cantrell</surname><given-names>M</given-names></name><name><surname>Huffmaster</surname><given-names>T</given-names></name></person-group><article-title>Surveying students' attitudes during the OSCE</article-title><source>Adv Health Sci Educ</source><year>1998</year><volume>3</volume><fpage>197</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1023/A:1009796201104</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Duffield</surname><given-names>KE</given-names></name><name><surname>Spencer</surname><given-names>JA</given-names></name></person-group><article-title>A survey of medical students' views about the purposes and fairness of assessment</article-title><source>Med Educ</source><year>2002</year><volume>36</volume><fpage>879</fpage><lpage>886</lpage><pub-id pub-id-type="pmid">12354251</pub-id><pub-id pub-id-type="doi">10.1046/j.1365-2923.2002.01291.x</pub-id></citation></ref><ref id="B17"><citation citation-type="book"><article-title>Faculty of Medical Sciences, University of the West Indies, Mona</article-title><source>Report &#x02013; MB, BS Undergraduate Programme, First Annual Report on Curriculum Development</source><year>2003</year><publisher-name>FMS, UWI, Mona, Jamaica</publisher-name></citation></ref></ref-list></back></article>



