<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Neurosci</journal-id><journal-title>BMC Neuroscience</journal-title><issn pub-type="epub">1471-2202</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15715907</article-id><article-id pub-id-type="pmc">PMC553984</article-id><article-id pub-id-type="publisher-id">1471-2202-6-12</article-id><article-id pub-id-type="doi">10.1186/1471-2202-6-12</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Statistical model of natural stimuli predicts edge-like pooling of spatial frequency channels in V2</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Hyv&#x000e4;rinen</surname><given-names>Aapo</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>ahyvarin@cc.helsinki.fi</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Gutmann</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>michael.gutmann@alumni.ethz.ch</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Hoyer</surname><given-names>Patrik O</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>patrik.hoyer@hut.fi</email></contrib></contrib-group><aff id="I1"><label>1</label>HIIT Basic Research Unit and Dept of Computer Science, University of Helsinki, Finland</aff><pub-date pub-type="collection"><year>2005</year></pub-date><pub-date pub-type="epub"><day>16</day><month>2</month><year>2005</year></pub-date><volume>6</volume><fpage>12</fpage><lpage>12</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2202/6/12"/><history><date date-type="received"><day>12</day><month>10</month><year>2004</year></date><date date-type="accepted"><day>16</day><month>2</month><year>2005</year></date></history><copyright-statement>Copyright &#x000a9; 2005 Hyv&#x000e4;rinen et al; licensee BioMed Central Ltd.</copyright-statement><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license><abstract><sec><title>Background</title><p>It has been shown that the classical receptive fields of simple and complex cells in the primary visual cortex emerge from the statistical properties of natural images by forcing the cell responses to be maximally sparse or independent. We investigate how to learn features beyond the primary visual cortex from the statistical properties of modelled complex-cell outputs. In previous work, we showed that a new model, non-negative sparse coding, led to the emergence of features which code for contours of a given spatial frequency band.</p></sec><sec><title>Results</title><p>We applied ordinary independent component analysis to modelled outputs of complex cells that span different frequency bands. The analysis led to the emergence of features which pool spatially coherent across-frequency activity in the modelled primary visual cortex. Thus, the statistically optimal way of processing complex-cell outputs abandons separate frequency channels, while preserving and even enhancing orientation tuning and spatial localization. As a technical aside, we found that the non-negativity constraint is not necessary: ordinary independent component analysis produces essentially the same results as our previous work.</p></sec><sec><title>Conclusion</title><p>We propose that the pooling that emerges allows the features to code for realistic low-level image features related to step edges. Further, the results prove the viability of statistical modelling of natural images as a framework that produces quantitative predictions of visual processing.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>A number of models approach the computational modelling of primary visual cortex by using two processing stages. First, there is a linear filtering with filters that are bandpass, oriented, and spatially localized. In some models, the outputs of the linear filters are half-wave rectified, but this difference is inessential because a rectification is done in the second stage anyway. The second stage then consists of pooling together rectified outputs of the first stage, so that cells that have the same orientation and frequency, as well as similar spatial locations, are pooled together. This pooling is then essentially a summation of rectified outputs of filters of different phases. These two processing steps are assumed to roughly correspond to simple and complex cells in V1, respectively. While there is controversy of the validity of such models, see e.g. [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B3">3</xref>], this is probably the simplest and most succesful approach.</p><p>Recent research has seen a number of models that attempt to explain these processing stages based on statistical modelling of natural images (ecologically valid input). First, application of independent component analysis (ICA) [<xref ref-type="bibr" rid="B4">4</xref>] or sparse coding [<xref ref-type="bibr" rid="B5">5</xref>] shows that the statistically optimal linear features of natural images are very similar to those computed in simple cells in V1 [<xref ref-type="bibr" rid="B6">6</xref>-<xref ref-type="bibr" rid="B12">12</xref>]. Second, application of a variant of ICA in which some pooling is done in a second stage leads to processing that is similar to what is done in complex cells [<xref ref-type="bibr" rid="B13">13</xref>]. Thus, models based on natural image statistics have been able to succesfully reproduce the above-mentioned two stages, and many well-known observations on V1.</p><p>It would be most useful if we could use this modelling endeavour in a <italic>predictive </italic>manner, so that we would be able to predict properties of cells in the visual cortex, in cases where the properties have not yet been demonstrated experimentally. This would give testable, quantitative hypotheses that might lead to great advances, especially in the research in extrastriate areas such as V2, whose function is not well understood at this point.</p><p>Here, we attempt to accomplish such predictive modelling in order to predict properties of a third processing step, following the two described above. Previously, we have applied a modification of the ICA / sparse coding model on the outputs of modelled complex cells whose input consisted of natural images [<xref ref-type="bibr" rid="B14">14</xref>]. The modification consisted of assuming that the coefficients in the generative decomposition, as well as the values of the higher-order features, were all non-negative.</p><p>We extend our previous results in two ways. The complex cells in our previous work were all constrained to have the same frequency, which was done in order to reduce the computational load. Here, we first report a technical advance: it is not necessary to make the assumptions of nonnegativity as in [<xref ref-type="bibr" rid="B14">14</xref>]. Thus, we are able to use the conventional, computationally optimized ICA algorithms, in particular the FastICA algorithm [<xref ref-type="bibr" rid="B15">15</xref>]. We are then easily able to incorporate complex cells of different frequencies in the input without exceeding available computational resources. This enables us to study whether some kind of interaction between different frequencies emerges in the statistically optimal higher-order representation.</p></sec><sec><title>Results</title><sec><title>Experiment 1: Using ordinary ICA with no constraints</title><p>As described in Methods, we input a large number of natural image patches into model complex cells that computed the sum of squares of outputs of two simple cells, one odd-symmetric and the other even-symmetric. Then, we performed independent component analysis of the complex cell outputs using the FastICA algorithm.</p><p>In the first experiment, we used only the output from complex cells in a single frequency band, <italic>f</italic><sub>2 </sub>in Figure <xref ref-type="fig" rid="F1">1</xref>. The purpose was to show that the results in [<xref ref-type="bibr" rid="B14">14</xref>] can be replicated using ordinary ICA methods.</p><p>The higher-order features are represented by their basis vectors <bold>a</bold><sub><italic>i </italic></sub>which show the contribution of the third-stage feature of index <italic>i </italic>on the activities of complex cells. A collection of the obtained basis vectors is shown in Figure <xref ref-type="fig" rid="F2">2</xref> for the nonlinearity <italic>g</italic><sub>1 </sub>(see Table <xref ref-type="table" rid="T1">1</xref>), visualized in the same way as in [<xref ref-type="bibr" rid="B14">14</xref>], see Methods. We can see the same kind of emergence of collinear features as in [<xref ref-type="bibr" rid="B14">14</xref>]. That is, the higher-order features code for the simultaneous activation of complex cells that together form something similar to a straight line segment.</p><p>Those coefficients that are clearly different from zero have almost always the same sign in a single basis vector. Defining the sign as explained in Methods, this means that the coefficients are essentially non-negative. We thus see that the constraint of non-negativity of the basis vectors imposed in [<xref ref-type="bibr" rid="B14">14</xref>] has little impact on the results: even without this constraint, the system learns basis vectors which are mainly non-negative.</p><p>Other FastICA nonlinearities led to similar basis vectors. However, some led to a larger number of longer contours. Figure <xref ref-type="fig" rid="F3">3</xref> shows the distribution of lengths for different nonlinearities. The nonlinearity <italic>g</italic><sub>4 </sub>(robust skewness) seems to lead to the largest number of long contours.</p></sec><sec><title>Experiment 2: Emergence of pooling over frequencies</title><p>In the second experiment, the complex-cell set was expanded to include cells of three different preferred frequencies. In total, there were now 432 complex cells. We performed ICA on the complex-cell outputs when their input consisted of natural images. Thus, we obtained 432 higher-order basis vectors (features) <bold>a</bold><sub><italic>i </italic></sub>with corresponding activities <italic>s</italic><sub><italic>i</italic></sub>.</p><p>We visualized a random selection of higher-order features learned from natural images in Figure <xref ref-type="fig" rid="F4">4</xref>. The visualization shows that the features tend to be spatially localized and oriented, and show collinearity as in Experiment 1. What is remarkable in these results is that many cells pool responses over different frequencies. The pooling is coherent in the sense that the complex cells that are pooled together have similar locations and orientations. A smaller number of cells is shown in more detail in Figure <xref ref-type="fig" rid="F5">5</xref>, where the coefficients in all orientation bands are shown separately.</p><p>We computed the frequency pooling measure <italic>P</italic><sub><italic>i </italic></sub>in Equation (4) of Methods for the learned basis vectors. The distribution of this measure for natural image input and white Gaussian noise input is shown in Figure <xref ref-type="fig" rid="F6">6</xref>. The figure shows that frequency pooling according to this measure was essentially nonexistent for white Gaussian noise input, but relatively strong for many basis vectors when the input consisted of natural images. To express this more quantitatively, we computed the 99% quantile for the white Gaussian noise input. Then, 59% of the basis vectors for natural image input had a pooling index <italic>P</italic><sub><italic>i </italic></sub>that was larger than this quantile. (For the 95% quantile the proportion was 63%.) Thus, we can say that more than half of the higher-order basis vectors, when learned from natural images, have a pooling over frequencies that is significantly above chance level.</p><p>To show that the pooling measure is valid, and to further visualize the frequency pooling in the higher-order features, we chose randomly basis vectors learned from natural images that have pooling significantly over chance level (<italic>P</italic><sub><italic>i </italic></sub>above its 99% quantile for white Gaussian noise). These are plotted in Figure <xref ref-type="fig" rid="F7">7</xref>. Visual inspection shows that in this subset, all basis vectors exhibit pooling over frequencies that respects the orientation tuning and collinearity properties.</p><p>The corresponding results when the input is white Gaussian noise are shown in Figure <xref ref-type="fig" rid="F8">8</xref>, for a smaller number of higher-order cells. (To make the comparison fair, these were randomly chosen among the 59% that had higher pooling measures, the same percentage as in Figure <xref ref-type="fig" rid="F7">7</xref>.) Pooling over frequencies as well as collinearity are minimal. Some weak reflections of these properties can be seen, presumably due to the small overlap of the filters in space and frequency, which leads to weak statistical correlations between complex cells that are spatially close to each other or in neighbouring frequency bands.</p><p>We also examined quantitatively whether the higher-order features are tuned to orientation. We investigated which complex cell has the maximum weight in <bold>a</bold><sub><italic>i </italic></sub>for each <italic>i </italic>in each frequency band. When the input consisted of natural images, in 86% of the cells the maximally weighted complex cells were found to be located at the hot-spot (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>)* (i.e., point of maximum activity, see Methods for exact definition) and tuned to the preferred orientation of the higher-order feature for <italic>every </italic>frequency <italic>f</italic>. This shows how the higher-order features are largely selective to a single orientation. When the input consisted of Gaussian white noise, only 34% of the cells were found to be orientation-selective according to this criterion.</p><p>Finally, we synthesized images from higher-order feature activities to further visualize the higher-order features (see Methods). Figure <xref ref-type="fig" rid="F9">9</xref> shows a slice orthogonal to the preferred orientation of one higher-order basis vector (H209 in Figure <xref ref-type="fig" rid="F5">5</xref>). The intensity of the synthesized image shows no side-lobes (unnecessary oscillations), while representing a sharp, localized edge. In contrast, synthesis in the white Gaussian noise case (also shown in Figure <xref ref-type="fig" rid="F9">9</xref>) gives curves that have either side-lobes like the underlying Gabor filters, or do not give a sharp localized edge. Thus, the curve obtained from synthesis of the features learned from natural images corresponds better to the notion of an edge. We propose that the utility of pooling over frequencies is due to the broadband nature of real-world edges. Typical edges in natural images are probably not very similar to typical band-pass Gabor functions (or V1 receptive fields) which have oscillations. A proper representation of such broad-band edges would seem to require pooling over different frequencies.</p></sec></sec><sec><title>Discussion</title><sec><title>Frequency channels and edges</title><p>What is the functional meaning of the pooling we have found? We propose that this spatially coherent pooling of multiple frequencies leads to representation of an edge that is more realistic than the band-pass edges given by typical Gabor filters [<xref ref-type="bibr" rid="B16">16</xref>]. Presumably, this is largely due to the fact that natural images contain many sharp, step-like edges that are not contained in a single frequency band. Thus, representation of such edges is difficult unless information from different frequency bands is combined.</p><p>In terms of frequency channels, the model predicts that frequency channels should be pooled together after complex cell processing. Models based on frequency channels and related concepts have been most prominent in image coding literature in recent years, both in biological and computer vision circles. The utility of frequency channels in the initial processing stages is widely acknowledged, and it is not put into question by our results &#x02013; in fact, the statistical modelling framework does show that using band-pass simple and complex cells is statistically optimal [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B13">13</xref>]. However, the question of when the frequency channels should be pooled or otherwise combined has received little attention [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B18">18</xref>]. Our results point out that a statistically optimal way is to pool them together right after the complex cell "stage", and this pooling should be done among cells of a given orientation which form a local, collinear configuration.</p></sec><sec><title>Related work</title><p>Several investigators have looked at the connection between natural image statistics, Gestalt grouping rules, and local interactions in the visual cortex [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B19">19</xref>-<xref ref-type="bibr" rid="B21">21</xref>]. However, few has considered the statistical relations between features of different frequencies so far. It should be noted that some related work on interactions of different frequencies does exist in the models of contrast gain control [<xref ref-type="bibr" rid="B22">22</xref>].</p><p>Compared to our own previous work [<xref ref-type="bibr" rid="B14">14</xref>], the main difference seems to be in the frequency tuning of the model complex cells. In [<xref ref-type="bibr" rid="B14">14</xref>], the complex cells were all constrained to have the same spatial frequency tuning &#x02013; just as in Experiment 1 of the present paper. Therefore, it was impossible to obtain results related to frequency pooling. It seems that any differences in the results are not due to differences in the statistical analysis of the complex-cell outputs or the natural image data set used, because in Experiment 1 of the present paper, we essentially replicated the results of [<xref ref-type="bibr" rid="B14">14</xref>]. The statistical model for analyzing the outputs of complex cells was somewhat different in our earlier work: the components <italic>s</italic><sub><italic>i </italic></sub>and the coefficients <italic>a</italic><sub><italic>ki </italic></sub>were constrained to be non-negative, following proposals by [<xref ref-type="bibr" rid="B23">23</xref>,<xref ref-type="bibr" rid="B24">24</xref>]. However, this constraint seems to be immaterial, because even without imposing the constraint, the coefficients turned out to be essentially non-negative (after defining the global sign as described in Methods).</p><p>Recent measurements from cat area 18 (somewhat analogous to V2) emphasize responses to "second-order" or "non-Fourier" stimuli, typically sine-wave gratings whose amplitudes are modulated [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B25">25</xref>]. These results and the proposed models are related to our results and predictions, yet fundamentally different. In the model in [<xref ref-type="bibr" rid="B25">25</xref>], a higher-order cell pools outputs of complex cells in the same frequency band to find contours that are defined by texture-like cues instead of luminance. The same cell also receives direct input from simple cells of a different frequency, which enables the cell to combine luminance and second-order cues. This is in stark contrast to higher-order cells in our model, which pool outputs of complex cells of different frequencies. They can hardly find contours defined by second-order cues; instead they seem to be good for coding broad-band contours. Furthermore, in [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B25">25</xref>], any collinearity of pooling seems to be absent. This naturally leads to the question: Why are our predictions so different from these results from area 18? We suspect this is because it is customary to think of visual processing in terms of division into frequency channels &#x02013; "second-order" stimuli are just an extension of this conceptualization. Therefore, not much attempt has been made to find cells that break the division into frequency channels according to our prediction. On the other hand, one can presume that the cells found in area 18 in [<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B25">25</xref>] are different from our predictions because they use a different coding strategy from the one used in our model, perhaps related to the temporal aspects of natural image sequences [<xref ref-type="bibr" rid="B26">26</xref>,<xref ref-type="bibr" rid="B27">27</xref>].</p><p>Another closely related line of work is by Zetzsche and coworkers [<xref ref-type="bibr" rid="B28">28</xref>,<xref ref-type="bibr" rid="B29">29</xref>] who emphasize the importance of decomposing the image information to local phase and amplitude information. The local amplitude is basically given by complex-cell outputs, whereas the physiological coding of the local phases is not known. An important question for future work is how to incorporate phase information in the higher-order units. Some models by Zetzsche et al actually predict some kind of pooling over frequencies, but rather directly after the simple cell stage (see Fig. 16 in [<xref ref-type="bibr" rid="B29">29</xref>]).</p></sec><sec><title>Towards predictive modelling</title><p>The present results are an instance of predictive modelling, where we attempt to predict properties of cells and cell assemblies that have not yet been observed in experiments. To be precise, the prediction is that in V2 (or some related area) there should be cells whose optimal stimulus is a broad-band edge that has no sidelobes while being relatively sharp, i.e. the optimal stimulus is closer to a step-edge than the band-pass edges that tend to be optimal for V1 simple and complex cells. The optimal stimulus should also be more elongated [<xref ref-type="bibr" rid="B30">30</xref>,<xref ref-type="bibr" rid="B31">31</xref>] than what is usually observed in V1, while being highly selective for orientation.</p><p>Statistical models of natural images offer a framework that lends itself to predictive modelling of the visual cortex. First, they offer a framework where we often see emergence of new kinds of feature detectors &#x02013; sometimes very different from what was expected when the model was formulated. Second, the framework is highly constrained and data-driven. The rigorous theory of statistical estimation makes it rather difficult to insert the theorist's subjective expectations in the model, and therefore the results are strongly determined by the data. Third, the framework is very constructive. From just a couple of simple theoretical specifications, e.g. non-Gaussianity, natural images lead to the emergence of complex phenomena.</p><p>We hope that the present work as well as future results in the same direction will serve as a basis for a new kind of synergy between theoretical and experimental neuroscience.</p></sec></sec><sec><title>Conclusion</title><p>We have shown that pooling over complex cells of different frequency preferences emerges when we model the statistical properties of natural images. This is accomplished by applying ordinary ICA on a set of modelled complex cells with multiple frequencies, and inputting natural images to the complex cells. The resulting independent components, as represented by the corresponding basis vectors, code for simultaneous activation of complex cells that have similar orientations, form a collinear configuration, and span multiple frequencies. Thus, statistical modelling of natural stimuli leads to an interesting hypothesis on the existence of a new kind of cells in the visual cortex.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Data and statistical analysis</title><p>The natural images were 1008 gray-scale images of size 1024 &#x000d7; 1536 pixels from van Hateren's database, available at <ext-link ext-link-type="uri" xlink:href="http://hlab.phys.rug.nl/imlib/index.html"/> (category "deblurred") [<xref ref-type="bibr" rid="B8">8</xref>]. We manually chose natural images in the narrower sense, i.e. only wildlife scenes. From the source images, 50,000 image patches of size 24 &#x000d7; 24 pixels were randomly extracted. The mean grey value of each image patch was subtracted and the pixel values were rescaled to unit variance. The resulting image patch will be denoted by <italic>I</italic>(<italic>x</italic>, <italic>y</italic>).</p><p>The complex-cell model was similar to our previous work [<xref ref-type="bibr" rid="B14">14</xref>]. The filter bank consisted of a number of complex cells arranged on a 6 &#x000d7; 6 grid. Complex-cell responses <italic>x</italic><sub><italic>k </italic></sub>to natural images were modelled with a classical energy model:</p><p><inline-graphic xlink:href="1471-2202-6-12-i1.gif"/></p><p>where <inline-graphic xlink:href="1471-2202-6-12-i2.gif"/> and <inline-graphic xlink:href="1471-2202-6-12-i3.gif"/> are even- and odd-symmetric Gabor receptive fields whose energies are pooled together in the complex cell. The complex cells had 6 &#x000d7; 6 = 36 different spatial locations, and at each location, four different preferred orientations and three different frequency bands. The aspect ratio was fixed to 1.5 and frequency bandwidth to 1.5 octaves, which implied an orientation bandwidth of 37&#x000b0;, according to the definitions in [<xref ref-type="bibr" rid="B8">8</xref>]. The frequency tiling of the Gabor filters is shown in Figure <xref ref-type="fig" rid="F1">1</xref>, in which all the filters <italic>W </italic>were normalized to unit norm for visualization purposes. The actual normalization we used in the experiments consisted of standardizing the variances of the complex cell outputs so that they were equal to unity for natural image input. The number of complex cells totalled <italic>K </italic>= 36 &#x000d7; 4 &#x000d7; 3 = 432. Note, however, that in Experiment 1 we only used a single frequency band.</p><p>Independent component analysis (ICA) was performed on the vector <bold>x </bold>= (<italic>x</italic><sub>1</sub>,...,<italic>x</italic><sub><italic>K</italic></sub>) using the FastICA algorithm [<xref ref-type="bibr" rid="B15">15</xref>]. The orthogonalization approach was symmetric. Different nonlinearities <italic>g </italic>were used, see Table <xref ref-type="table" rid="T1">1</xref>. Thus we learned (estimated) a linear decomposition of the form</p><p><inline-graphic xlink:href="1471-2202-6-12-i4.gif"/></p><p>or in vector form</p><p><inline-graphic xlink:href="1471-2202-6-12-i5.gif"/></p><p>where the vector <bold>a</bold><sub><italic>i </italic></sub>= (<italic>a</italic><sub>1<italic>i</italic></sub>,...,<italic>a</italic><sub><italic>ki</italic></sub>) gives a higher-order basis vector. The <italic>s</italic><sub><italic>i </italic></sub>define the values of the higher-order features in the third cortical processing stage.</p><p>Note that the signs of the basis vectors are not defined by the ICA model [<xref ref-type="bibr" rid="B4">4</xref>], i.e. the model does not distinguish between <bold>a</bold><sub><italic>i </italic></sub>and -<bold>a</bold><sub><italic>i </italic></sub>because any change in sign of the basis vector can be cancelled by changing the sign of <italic>s</italic><sub><italic>i </italic></sub>accordingly. Here, we defined the sign for each vector <bold>a</bold><sub><italic>i </italic></sub>so that the sign of the element with the maximal absolute value was positive.</p><p>To obtain a baseline with which to compare our results, and to show which part of the results is due to the statistical properties of natural images instead of some intrinsic properties of our filterbank and analysis methods, we did exactly the same kind of analysis for 24 &#x000d7; 24 image patches that consisted of white Gaussian noise, i.e. the gray-scale value in each pixel was randomly and independently drawn from a Gaussian distribution of zero mean and unit variance. The white Gaussian noise input provides a "chance level" for any quantities computed from the ICA results.</p></sec><sec><title>Analysis of the ICA results</title><p>We visualized the resulting higher-order basis vectors <bold>a</bold><sub><italic>i </italic></sub>following [<xref ref-type="bibr" rid="B14">14</xref>] by plotting an ellipse at each centrepoint of complex cells. The orientation of the ellipse is the orientation of the complex cell <italic>k</italic>, and the brightness of the ellipse is proportional to the <italic>a</italic><sub><italic>ki </italic></sub>coefficient of the basis vector <bold>a</bold><sub><italic>i</italic></sub>, using a gray-scale coding of coefficient values. In Experiment 1, i.e. the case with a single frequency band, we used this method directly to visualize each higher-order basis vector in a single display. In Experiment 2, i.e. the multifrequency case, we visualized each frequency band separately.</p><p>In Experiment 2, we are interested in the frequency pooling of complex cells in different higher-order features. We quantified the pooling over frequencies using a simple measure defined as follows. Let us denote by <italic>a</italic><sub><italic>i</italic></sub>(<italic>x</italic>, <italic>y</italic>, <italic>&#x003b8;</italic>, <italic>f</italic><sub><italic>n</italic></sub>) the coefficient in the higher-order basis vector <bold>a</bold><sub><italic>i </italic></sub>that corresponds to the complex cell with spatial location (<italic>x</italic>, <italic>y</italic>), orientation <italic>&#x003b8; </italic>and preferred frequency <italic>f</italic><sub><italic>n</italic></sub>. We computed a quantity which is similar to the sums of correlations of the coefficients over the three frequency bands, but normalized in a slightly different way. This measure <italic>P</italic><sub><italic>i </italic></sub>was defined as follows:</p><p><inline-graphic xlink:href="1471-2202-6-12-i6.gif"/></p><p>where the normalization constant <italic>C</italic><sub><italic>m </italic></sub>is defined as</p><p><inline-graphic xlink:href="1471-2202-6-12-i7.gif"/></p><p>and likewise for <italic>C</italic><sub><italic>n</italic></sub>.</p><p>For further analysis of the estimated basis vectors, we defined the preferred orientation of a higher-order feature. First, let us define for a higher-order feature of index <italic>i </italic>the hot-spot (<italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>)* as the centre location (<italic>x</italic>, <italic>y</italic>) of complex cells where the higher-order component <italic>s</italic><sub><italic>i </italic></sub>generates the maximum amount of activity. That is, we sum the elements of <bold>a</bold><sub><italic>i </italic></sub>that correspond to a single spatial location, and choose the largest sum. This allows us to define the tuning to a given orientation of a higher-order feature <italic>i </italic>by summing over the elements of <bold>a</bold><sub><italic>i </italic></sub>that correspond to the spatial hotspot and a given orientation; the preferred orientation is the orientation for which this sum is maximized. We also computed the length of a higher-order feature as described in [<xref ref-type="bibr" rid="B14">14</xref>].</p><p>It is also possible to perform an image synthesis from a higher-order basis vector. However, the mapping from image to complex-cell outputs is not one-to-one. This means that the generation of the image is not uniquely defined given the activities of higher-order features alone. A unique definition can be achieved by constraining the phases of the complex cells. We assume that only odd-symmetric Gabor filters are active. Furthermore, we make the simplifying assumptions that the receptive fields <italic>W </italic>in simple cells are equal to the corresponding basis vectors, and that all the elements in the higher-order basis vector are non-negative (or small enough to be ignored). Then, the synthesized image <inline-graphic xlink:href="1471-2202-6-12-i8.gif"/> for higher-order basis vector <bold>a</bold><sub><italic>i </italic></sub>is given by</p><p><inline-graphic xlink:href="1471-2202-6-12-i9.gif"/></p><p>where the square root cancels the squaring operation in the computation of complex-cell responses, and <italic>H </italic>denotes the set of indices that correspond to complex cells of the preferred orientation at the hotspot. Negative values of <italic>a</italic><sub><italic>ki </italic></sub>were set to zero in this synthesis formula.</p></sec></sec><sec><title>Authors' contributions</title><p>A.H. conceived the basic idea and the principles of the experimental set-up, and wrote the paper. M.G. performed the experiments and elaborated the experimental set-up. P.O.H. assisted in the experiments and the writing.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>A. H. was funded by the Academy of Finland, Academy Research Fellow position and project #48593. P.O.H. was funded by the Academy of Finland, project #204826. M.G. would like to thank Rodney Douglas for supporting this collaborative effort between HIIT and the Institute of Neuroinformatics, Zurich.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chance</surname><given-names>FS</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><article-title>Complex cells as cortically amplified simple cells</article-title><source>Nature Neuroscience</source><year>1999</year><volume>2</volume><fpage>277</fpage><lpage>282</lpage><pub-id pub-id-type="pmid">10195222</pub-id><pub-id pub-id-type="doi">10.1038/6381</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mechler</surname><given-names>F</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name></person-group><article-title>On the classification of simple and complex cells</article-title><source>Vision Research</source><year>2002</year><volume>42</volume><fpage>1017</fpage><lpage>33</lpage><pub-id pub-id-type="pmid">11934453</pub-id><pub-id pub-id-type="doi">10.1016/S0042-6989(02)00025-1</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kagan</surname><given-names>I</given-names></name><name><surname>Gur</surname><given-names>M</given-names></name><name><surname>Snodderly</surname><given-names>D</given-names></name></person-group><article-title>Spatial organization of receptive fields of V1 neurons of alert monkeys: comparison with responses to gratings</article-title><source>J Neurophysiol</source><year>2002</year><volume>88</volume><fpage>2557</fpage><lpage>2574</lpage><pub-id pub-id-type="pmid">12424294</pub-id></citation></ref><ref id="B4"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Hyv&#x000e4;rinen</surname><given-names>A</given-names></name><name><surname>Karhunen</surname><given-names>J</given-names></name><name><surname>Oja</surname><given-names>E</given-names></name></person-group><source>Independent Component Analysis</source><year>2001</year><publisher-name>Wiley Interscience</publisher-name><ext-link ext-link-type="uri" xlink:href="http://www.cis.hut.fi/projects/ica/book/"/></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Field</surname><given-names>D</given-names></name></person-group><article-title>What is the goal of sensory coding?</article-title><source>Neural Computation</source><year>1994</year><volume>6</volume><fpage>559</fpage><lpage>601</lpage></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title><source>Nature</source><year>1996</year><volume>381</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="pmid">8637596</pub-id><pub-id pub-id-type="doi">10.1038/381607a0</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>A</given-names></name><name><surname>Sejnowski</surname><given-names>T</given-names></name></person-group><article-title>The 'Independent Components' of Natural Scenes are Edge Filters</article-title><source>Vision Research</source><year>1997</year><volume>37</volume><fpage>3327</fpage><lpage>3338</lpage><pub-id pub-id-type="pmid">9425547</pub-id><pub-id pub-id-type="doi">10.1016/S0042-6989(97)00121-1</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>van Hateren</surname><given-names>JH</given-names></name><name><surname>van der Schaaf</surname><given-names>A</given-names></name></person-group><article-title>Independent component filters of natural images compared with simple cells in primary visual cortex</article-title><source>Proc Royal Society, Ser B</source><year>1998</year><volume>265</volume><fpage>359</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1098/rspb.1998.0303</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>van Hateren</surname><given-names>JH</given-names></name><name><surname>Ruderman</surname><given-names>DL</given-names></name></person-group><article-title>Independent component analysis of natural image sequences yields spatiotem poral filters similar to simple cells in primary visual cortex</article-title><source>Proc Royal Society, Ser B</source><year>1998</year><volume>265</volume><fpage>2315</fpage><lpage>2320</lpage><pub-id pub-id-type="doi">10.1098/rspb.1998.0577</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hoyer</surname><given-names>PO</given-names></name><name><surname>Hyv&#x000e4;rinen</surname><given-names>A</given-names></name></person-group><article-title>Independent Component Analysis Applied to Feature Extraction from Colour and Stereo Images</article-title><source>Network: Computation in Neural Systems</source><year>2000</year><volume>11</volume><fpage>191</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/11/3/302</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Caywood</surname><given-names>M</given-names></name><name><surname>Willmore</surname><given-names>B</given-names></name><name><surname>Tolhurst</surname><given-names>D</given-names></name></person-group><article-title>Independent Components of Color Natural Scenes Resemble V1 Neurons in Their Spatial and Color Tuning</article-title><source>J of Neurophysiology</source><year>2004</year><volume>91</volume><fpage>2859</fpage><lpage>2873</lpage><pub-id pub-id-type="doi">10.1152/jn.00775.2003</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wachtler</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>TW</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><article-title>Chromatic structure of natural scenes</article-title><source>J Opt Soc Am A</source><year>2001</year><volume>18</volume><fpage>65</fpage><lpage>77</lpage></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hyv&#x000e4;rinen</surname><given-names>A</given-names></name><name><surname>Hoyer</surname><given-names>PO</given-names></name></person-group><article-title>Emergence of phase and shift invariant features by decomposition of natural images into independent feature subspaces</article-title><source>Neural Computation</source><year>2000</year><volume>12</volume><fpage>1705</fpage><lpage>1720</lpage><pub-id pub-id-type="pmid">10935923</pub-id><pub-id pub-id-type="doi">10.1162/089976600300015312</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hoyer</surname><given-names>PO</given-names></name><name><surname>Hyv&#x000e4;rinen</surname><given-names>A</given-names></name></person-group><article-title>A multi-layer sparse coding network learns contour coding from natural images</article-title><source>Vision Research</source><year>2002</year><volume>42</volume><fpage>1593</fpage><lpage>1605</lpage><pub-id pub-id-type="pmid">12074953</pub-id><pub-id pub-id-type="doi">10.1016/S0042-6989(02)00017-2</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hyv&#x000e4;rinen</surname><given-names>A</given-names></name></person-group><article-title>Fast and Robust Fixed-Point Algorithms for Independent Component Analysis</article-title><source>IEEE Transactions on Neural Networks</source><year>1999</year><volume>10</volume><fpage>626</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1109/72.761722</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Griffin</surname><given-names>L</given-names></name><name><surname>Lillholm</surname><given-names>M</given-names></name><name><surname>Nielsen</surname><given-names>M</given-names></name></person-group><article-title>Natural image profiles are most likely to be step edges</article-title><source>Vision Research</source><year>2004</year><volume>44</volume><fpage>407</fpage><lpage>421</lpage><pub-id pub-id-type="pmid">14659967</pub-id><pub-id pub-id-type="doi">10.1016/j.visres.2003.09.025</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mareschal</surname><given-names>I</given-names></name><name><surname>Baker</surname><given-names>CL</given-names></name></person-group><article-title>A cortical locus for the processing of contrast-defined contours</article-title><source>Nature Neuroscience</source><year>1998</year><volume>1</volume><fpage>150</fpage><lpage>154</lpage><pub-id pub-id-type="pmid">10195131</pub-id><pub-id pub-id-type="doi">10.1038/401</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Olzak</surname><given-names>L</given-names></name><name><surname>Wickens</surname><given-names>T</given-names></name></person-group><article-title>Discrimination of complex patterns: orientation information is integrated across spatial scale; spatial-frequency and contrast information are not</article-title><source>Perception</source><year>1997</year><volume>26</volume><fpage>1101</fpage><lpage>1120</lpage><pub-id pub-id-type="pmid">9509146</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>WS</given-names></name><name><surname>Perry</surname><given-names>JS</given-names></name><name><surname>Super</surname><given-names>BJ</given-names></name><name><surname>Gallogly</surname><given-names>DP</given-names></name></person-group><article-title>Edge co-occurence in natural images predicts contour grouping performance</article-title><source>Vision Research</source><year>2001</year><volume>41</volume><fpage>711</fpage><lpage>724</lpage><pub-id pub-id-type="pmid">11248261</pub-id><pub-id pub-id-type="doi">10.1016/S0042-6989(00)00277-7</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Cecchi</surname><given-names>GA</given-names></name><name><surname>Gilbert</surname><given-names>CD</given-names></name><name><surname>Magnasco</surname><given-names>MO</given-names></name></person-group><article-title>On a common circle: Natural scenes and Gestalt rules</article-title><source>Proceedings of the National Academy of Science, USA</source><year>2001</year><volume>98</volume><fpage>1935</fpage><lpage>1940</lpage><pub-id pub-id-type="doi">10.1073/pnas.031571498</pub-id></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Elder</surname><given-names>J</given-names></name><name><surname>Goldberg</surname><given-names>R</given-names></name></person-group><article-title>Ecological statistics of Gestalt laws for the perceptual organization of contours</article-title><source>Journal of Vision</source><year>2002</year><volume>2</volume><fpage>324</fpage><lpage>353</lpage><pub-id pub-id-type="pmid">12678582</pub-id></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>O</given-names></name><name><surname>Simoncelli</surname><given-names>E</given-names></name></person-group><article-title>Natural signal statistics and sensory gain control</article-title><source>Nature Neuroscience</source><year>2001</year><volume>4</volume><fpage>819</fpage><lpage>825</lpage><pub-id pub-id-type="pmid">11477428</pub-id><pub-id pub-id-type="doi">10.1038/90526</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Paatero</surname><given-names>P</given-names></name><name><surname>Tapper</surname><given-names>U</given-names></name></person-group><article-title>Positive Matrix Factorization: A Non-negative Factor Model with Optimal Utilization of Error Estimates of Data Values</article-title><source>Environmetrics</source><year>1994</year><volume>5</volume><fpage>111</fpage><lpage>126</lpage></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>DD</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><article-title>Learning the parts of objects by non-negative matrix factorization</article-title><source>Nature</source><year>1999</year><volume>401</volume><fpage>788</fpage><lpage>791</lpage><pub-id pub-id-type="pmid">10548103</pub-id><pub-id pub-id-type="doi">10.1038/44565</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Mareschal</surname><given-names>I</given-names></name><name><surname>Baker</surname><given-names>C</given-names></name></person-group><article-title>Temporal and spatial response to second-order stimuli in cat area 18</article-title><source>J Neurophysiol</source><year>1998</year><volume>80</volume><fpage>2811</fpage><lpage>2823</lpage><pub-id pub-id-type="pmid">9862886</pub-id></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hurri</surname><given-names>J</given-names></name><name><surname>Hyv&#x000e4;rinen</surname><given-names>A</given-names></name></person-group><article-title>Simple-Cell-Like Receptive Fields Maximize Temporal Coherence in Natural Video</article-title><source>Neural Computation</source><year>2003</year><volume>15</volume><fpage>663</fpage><lpage>691</lpage><pub-id pub-id-type="pmid">12620162</pub-id><pub-id pub-id-type="doi">10.1162/089976603321192121</pub-id></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hyv&#x000e4;rinen</surname><given-names>A</given-names></name><name><surname>Hurri</surname><given-names>J</given-names></name><name><surname>V&#x000e4;yrynen</surname><given-names>J</given-names></name></person-group><article-title>Bubbles: A unifying framework for low-level statistical properties of natural image sequences</article-title><source>J Opt Soc Am A Opt Image Sci Vis</source><year>2003</year><volume>20</volume><fpage>1237</fpage><lpage>1252</lpage><pub-id pub-id-type="pmid">12868630</pub-id></citation></ref><ref id="B28"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Zetzsche</surname><given-names>C</given-names></name><name><surname>Krieger</surname><given-names>G</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Rogowitz B, Pappas T</surname></name></person-group><article-title>Nonlinear neurons and high-order statistics: New approaches to human vision and electronic image processing</article-title><source>Human Vision and Electronic Imaging IV (Proc SPIE vol 3644)</source><year>1999</year><publisher-name>SPIE</publisher-name><fpage>2</fpage><lpage>33</lpage></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zetzsche</surname><given-names>C</given-names></name><name><surname>R&#x000f6;hrbein</surname><given-names>F</given-names></name></person-group><article-title>Nonlinear and extra-classical receptive field properties and the statistics of natural scenes</article-title><source>Network: Computation in Neural Systems</source><year>2001</year><volume>12</volume><fpage>331</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/12/3/306</pub-id></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Polat</surname><given-names>U</given-names></name><name><surname>Tyler</surname><given-names>C</given-names></name></person-group><article-title>What pattern the eye sees best</article-title><source>Vision Research</source><year>1999</year><volume>39</volume><fpage>887</fpage><lpage>895</lpage><pub-id pub-id-type="pmid">10341942</pub-id><pub-id pub-id-type="doi">10.1016/S0042-6989(98)00245-4</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gilbert</surname><given-names>CD</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><article-title>Intrinsic connectivity and receptive field properties in visual cortex</article-title><source>Vision Research</source><year>1985</year><volume>25</volume><fpage>365</fpage><lpage>374</lpage><pub-id pub-id-type="pmid">3895724</pub-id><pub-id pub-id-type="doi">10.1016/0042-6989(85)90061-6</pub-id></citation></ref></ref-list><sec sec-type="display-objects"><title>Figures and Tables</title><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Frequency tuning of complex cells. </bold>We used three different frequency bands. The underlying Gabor filters had logarithmically spaced frequency peaks and their frequency responses overlapped at the -3dB points. Peak spatial frequencies were chosen as follows: <italic>f</italic><sub>1 </sub>= 0.1 cycles/pixel, <italic>f</italic><sub>2 </sub>= 0.21 cycles/pixel and <italic>f</italic><sub>3 </sub>= 0.42 cycles/pixel. The amplitudes of the Fourier Transforms of the odd-symmetric Gabor filters are shown.</p></caption><graphic xlink:href="1471-2202-6-12-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>Basis vectors of Experiment 1. </bold>Random selection of learned basis vectors <bold>a</bold><sub><italic>i </italic></sub>when the complex cells are all in a single frequency band. ICA non-linearity <italic>g </italic>was the tanh nonlinearity <italic>g</italic><sub>1</sub>. Each patch gives the coefficients of one higher-order feature. Each ellipse means that the complex cell in the corresponding location and orientation is present in the higher-order feature, brightness of ellipse is proportional to coefficient <italic>a</italic><sub><italic>ki</italic></sub>.</p></caption><graphic xlink:href="1471-2202-6-12-2"/></fig><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>Comparison of nonlinearities. </bold>Comparison of different FastICA nonlinearities in Experiment 1. The histogram gives the lengths of the contour patterns for the four different nonlinearities <italic>g</italic><sub>1</sub>,..., <italic>g</italic><sub>4 </sub>in Table 1.</p></caption><graphic xlink:href="1471-2202-6-12-3"/></fig><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>Basis vectors of Experiment 2. </bold>A random selection of higher-order basis vectors <bold>a</bold><sub><italic>i </italic></sub>estimated from natural images in Experiment 2. ICA nonlinearity <italic>g </italic>was the tanh nonlinearity <italic>g</italic><sub>1</sub>. Each display of three patches gives the coefficients of one higher-order feature. Each patch gives the coefficients of one higher-order feature in one frequency band. Each ellipse means that the complex cell in the corresponding location, and of the corresponding orientation and frequency is present in the higher-order feature, brightness of ellipse is proportional to coefficient <italic>a</italic><sub><italic>ki</italic></sub></p></caption><graphic xlink:href="1471-2202-6-12-4"/></fig><fig position="float" id="F5"><label>Figure 5</label><caption><p><bold>Basis vectors in detail. </bold>Higher-order basis vectors of four selected higher-order features in Experiment 2, shown in detail. The coefficients in each orientation and frequency band are plotted separately.</p></caption><graphic xlink:href="1471-2202-6-12-5"/></fig><fig position="float" id="F6"><label>Figure 6</label><caption><p><bold>Pooling measure. </bold>The distributions of the frequency pooling measure in Equation (4) for natural images and white Gaussian noise.</p></caption><graphic xlink:href="1471-2202-6-12-6"/></fig><fig position="float" id="F7"><label>Figure 7</label><caption><p><bold>Basis vectors with significant pooling. </bold>A selection of higher-order basis vectors <bold>a</bold><sub><italic>i </italic></sub>estimated from natural images in Experiment 2. These basis vectors were chosen randomly among those that have frequency pooling significantly above chance level.</p></caption><graphic xlink:href="1471-2202-6-12-7"/></fig><fig position="float" id="F8"><label>Figure 8</label><caption><p><bold>Basis vectors for white Gaussian noise. </bold>For comparison, higher-order basis vectors estimated from white Gaussian noise, with each frequency band shown separately.</p></caption><graphic xlink:href="1471-2202-6-12-8"/></fig><fig position="float" id="F9"><label>Figure 9</label><caption><p><bold>Image synthesis. </bold>Local image synthesis from the three odd-symmetric Gabor elements that have preferred orientation at the hotspot of a higher-order basis vector (H209 in Figure 5). The thick dotted curve shows the synthesis using coefficients from natural images, and the solid curves show various synthesis results using coefficients learned from white Gaussian noise input.</p></caption><graphic xlink:href="1471-2202-6-12-9"/></fig><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Nonlinearities <italic>g </italic>used in FastICA. The nonlinearities probe the non-Gaussianity of the estimated components in different ways.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left"><italic>g</italic><sub>1 </sub>(<italic>y</italic>) = tanh (<italic>y</italic>)</td><td align="left">Classic measure of sparseness</td></tr><tr><td align="left"><italic>g</italic><sub>2 </sub>(<italic>y</italic>) = <italic>y </italic>exp(-<italic>y</italic><sup>2</sup>/2)</td><td align="left">More robust variant of <italic>g</italic><sub>1</sub></td></tr><tr><td align="left"><italic>g</italic><sub>3 </sub>(<italic>y</italic>) = <italic>y</italic><sup>2</sup></td><td align="left">Skewness (asymmetry)</td></tr><tr><td align="left"><italic>g</italic><sub>4 </sub>(<italic>y</italic>) = exp(-<italic>y</italic><sup>2</sup>/2)</td><td align="left">Robust variant of <italic>g</italic><sub>3</sub></td></tr></tbody></table></table-wrap></sec></back></article>



