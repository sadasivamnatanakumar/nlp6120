<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Genome Biol</journal-id><journal-title>Genome Biology</journal-title><issn pub-type="ppub">1465-6906</issn><issn pub-type="epub">1465-6914</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15693945</article-id><article-id pub-id-type="pmc">PMC551536</article-id><article-id pub-id-type="publisher-id">gb-2005-6-2-r16</article-id><article-id pub-id-type="doi">10.1186/gb-2005-6-2-r16</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Preferred analysis methods for Affymetrix GeneChips revealed by a wholly defined control dataset</article-title></title-group><contrib-group><contrib id="A1" contrib-type="author"><name><surname>Choe</surname><given-names>Sung E</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><email>sung_choe@post.harvard.edu</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Boutros</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I6">6</xref><email>m.boutros@dkfz.de</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Michelson</surname><given-names>Alan M</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I3">3</xref><email>michelson@receptor.med.harvard.edu</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Church</surname><given-names>George M</given-names></name><xref ref-type="aff" rid="I1">1</xref></contrib><contrib id="A5" corresp="yes" contrib-type="author"><name><surname>Halfon</surname><given-names>Marc S</given-names></name><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I4">4</xref><xref ref-type="aff" rid="I5">5</xref><email>mshalfon@buffalo.edu</email></contrib></contrib-group><aff id="I1"><label>1</label>Department of Genetics, Harvard Medical School, New Research Building, 77 Avenue Louis Pasteur, Boston, MA 02115, USA</aff><aff id="I2"><label>2</label>Division of Genetics, Department of Medicine, Brigham and Women's Hospital, New Research Building, 77 Avenue Louis Pasteur, Boston, MA 02115, USA</aff><aff id="I3"><label>3</label>Howard Hughes Medical Institute, Brigham and Women's Hospital, 20 Shattuck Street, Boston, MA 02115, USA</aff><aff id="I4"><label>4</label>Department of Biochemistry, 140 Farber Hall, 3435 Main St., SUNY at Buffalo, Buffalo, NY 14214, USA</aff><aff id="I5"><label>5</label>Center of Excellence in Bioinformatics, 140 Farber Hall, 3435 Main St., SUNY at Buffalo, Buffalo, NY 14214, USA</aff><aff id="I6"><label>6</label>German Cancer Research Center (DKFZ/B110), Im Neuenheimer Feld 580, 69120 Heidelberg, Germany</aff><pub-date pub-type="ppub"><year>2005</year></pub-date><pub-date pub-type="epub"><day>28</day><month>1</month><year>2005</year></pub-date><volume>6</volume><issue>2</issue><fpage>R16</fpage><lpage>R16</lpage><ext-link ext-link-type="uri" xlink:href="http://genomebiology.com/2005/6/2/R16"/><history><date date-type="received"><day>3</day><month>8</month><year>2004</year></date><date date-type="rev-recd"><day>20</day><month>10</month><year>2004</year></date><date date-type="accepted"><day>2</day><month>12</month><year>2004</year></date></history><copyright-statement>Copyright &#x000a9; 2005 Choe et al.; licensee BioMed Central Ltd.</copyright-statement><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license><abstract abstract-type="short"><p>A 'spike-in' experiment for Affymetrix GeneChips is described that provides a defined dataset of 3,860 RNA species. A 'best route' combination of analysis methods is presented which allows detection of approximately 70% of true positives before reaching a 10% false discovery rate.</p></abstract><abstract><sec><title>Background</title><p>As more methods are developed to analyze RNA-profiling data, assessing their performance using control datasets becomes increasingly important.</p></sec><sec><title>Results</title><p>We present a 'spike-in' experiment for Affymetrix GeneChips that provides a defined dataset of 3,860 RNA species, which we use to evaluate analysis options for identifying differentially expressed genes. The experimental design incorporates two novel features. First, to obtain accurate estimates of false-positive and false-negative rates, 100-200 RNAs are spiked in at each fold-change level of interest, ranging from 1.2 to 4-fold. Second, instead of using an uncharacterized background RNA sample, a set of 2,551 RNA species is used as the constant (1x) set, allowing us to know whether any given probe set is truly present or absent. Application of a large number of analysis methods to this dataset reveals clear variation in their ability to identify differentially expressed genes. False-negative and false-positive rates are minimized when the following options are chosen: subtracting nonspecific signal from the PM probe intensities; performing an intensity-dependent normalization at the probe set level; and incorporating a signal intensity-dependent standard deviation in the test statistic.</p></sec><sec><title>Conclusions</title><p>A best-route combination of analysis methods is presented that allows detection of approximately 70% of true positives before reaching a 10% false-discovery rate. We highlight areas in need of improvement, including better estimate of false-discovery rates and decreased false-negative rates.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Since their introduction in the mid 1990s [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>], expression-profiling methods have become a widespread tool in numerous areas of biological and biomedical research. However, choosing a method for analyzing microarray data is a daunting task. Dozens of methods have been proposed for the analysis of both high-density oligonucleotide (for example, Affymetrix GeneChip) and spotted cDNA or long oligonucleotide arrays, with more being put forward on a regular basis [<xref ref-type="bibr" rid="B3">3</xref>]. Moreover, it is clear that different methods can produce substantially different results. For example, two lists of differentially expressed genes generated from the same dataset can display as little as 60-70% overlap when analyzed using different methods ([<xref ref-type="bibr" rid="B4">4</xref>] and see Additional data file 1). Despite the large number of proposed algorithms, there are relatively few studies that assess their relative performance [<xref ref-type="bibr" rid="B5">5</xref>-<xref ref-type="bibr" rid="B9">9</xref>]. A significant challenge to undertaking such studies is the scarcity of control datasets that contain a sufficiently large number of known differentially expressed genes to obtain adequate statistics. The comparative studies that have been performed have used a small number of positive controls, and have included a background RNA sample in which the concentrations of the various genes are unknown, preventing an accurate assessment of false-positive rates and nonspecific hybridization.</p><p>The most useful control datasets to date for evaluating the effectiveness of analysis methods for Affymetrix arrays are cRNA spike-in datasets from Affymetrix and Gene Logic. The Affymetrix Latin square dataset [<xref ref-type="bibr" rid="B10">10</xref>] is a series of transcriptional profiles of the same biological RNA sample, into which 42 cRNAs have been spiked at various known concentrations. The dataset is designed so that, when comparing any two hybridizations in the series, all known fold changes are powers of two. The Gene Logic dataset [<xref ref-type="bibr" rid="B11">11</xref>] has a similar experimental design, but with 11 cRNAs spiked in at varying fold changes, ranging from 1.3-fold upwards.</p><p>Here we present a new control dataset for the purpose of evaluating methods for identifying differentially expressed genes (DEGs) between two sets of replicated hybridizations to Affymetrix GeneChips. This dataset has several features to facilitate the relative assessment of different analysis options. First, rather than containing a limited number of spiked-in cRNAs, the current dataset has 1309 individual cRNAs that differ by known relative concentrations between the spike-in and control samples. This large number of defined RNAs enables us to generate accurate estimates of false-negative and false-positive rates at each fold-change level. Second, the dataset includes low fold changes, beginning at only a 1.2-fold concentration difference. This is important, as small fold changes can be biologically relevant, yet are frequently overlooked in microarray datasets because of a lack of knowledge as to how reliably such small changes can be detected. Third, our dataset uses a defined background sample of 2,551 RNA species present at identical concentrations in both sets of microarrays, rather than a biological RNA sample of unknown composition. This background RNA population is sufficiently large for normalization purposes, yet also enables us to observe the distribution of truly nonspecific signal from probe sets which correspond to RNAs not present in the sample.</p><p>We have used this dataset to compare several algorithms commonly used for microarray analysis. To perform a direct comparison of the selected methods at each stage of analysis, we applied all possible combinations of options to the data. Thus, it was possible to assess whether some steps are more critical than others in maximizing the detection of true DEGs. Our results show that at several steps of analysis, large differences exist in the effectiveness of the various options that we considered. These key steps are: first, adjusting the perfect match probe signal with an estimate of nonspecific signal (the method from MAS 5.0 [<xref ref-type="bibr" rid="B12">12</xref>] performs best); second, checking that the log fold changes are roughly distributed around 0 (by observing the so-called M versus A plot [<xref ref-type="bibr" rid="B13">13</xref>], the plot of log fold change (M) <italic>versus </italic>average log signal intensity (A)), and if necessary, performing a normalization at the probe-set level to center this plot around M = 0; and third, choosing the best test statistic (the regularized <italic>t</italic>-statistic from CyberT [<xref ref-type="bibr" rid="B14">14</xref>] is most accurate). Overall, we find a significant limit to the sensitivity of microarray experiments to detect small changes: in the best-case scenario we could detect approximately 95% of true DEGs with changes greater than twofold, but less than 30% with changes below 1.7-fold before exceeding a 10% false-discovery rate. We propose a 'best-route' combination of existing methods to achieve the most accurate assessment of DEGs in Affymetrix experiments.</p></sec><sec><title>Results and discussion</title><sec><title>Experimental design</title><p>A common use of microarrays is to compare two samples, for example, a treatment and a control, to identify genes that are differentially expressed. We constructed a control dataset to mimic this scenario using 3,860 individual cRNAs of known sequence in a concentration range similar to what would be used in an actual experimental situation (see Materials and methods). The cRNAs were divided into two samples - 'constant' (C) and 'spike' (S) - and each sample was hybridized in triplicate to Affymetrix GeneChips (six chips total). The S sample contains the same cRNAs as the C sample, except that selected groups of approximately 180 cRNAs each are present at a defined increased concentration compared to the C sample (Figure <xref ref-type="fig" rid="F1">1</xref>, Table <xref ref-type="table" rid="T1">1</xref>). Out of the 3,860 cRNAs, 1,309 were spiked in with differing concentrations between the S and C samples. The rest (2,551) are present at identical relative concentration in each sample, to serve as a guide for normalization between the two sets of microarrays. For the sake of consistency with typical discussions of microarray experiments, we sometimes refer to the cRNAs with positive log fold changes as DEGs, despite their not representing true gene-expression data.</p></sec><sec><title>Assignment of Affymetrix probe sets to DGC clones</title><p>In the Affymetrix GeneChip design, the expression level of each RNA species is reported by a probe set, which in the DrosGenome1 chip [<xref ref-type="bibr" rid="B15">15</xref>] comprises 14 oligonucleotide probe pairs. Each probe pair contains two 25-mer DNA oligonucleotide probes; the perfect match (or PM) probe matches perfectly to the target RNA, and the mismatch (or MM) probe is identical to its PM partner probe except for a single homomeric mismatch at the central base-pair position, and thus serves to estimate nonspecific signal.</p><p>The DrosGenome1 chip used in this experiment is based on release version 1.0 of the <italic>Drosophila </italic>genome sequence and thus does not represent the most up-to-date annotated version of the genome. To ensure that probe-target assignments are made correctly, we assigned the 14,010 probe sets on the DrosGenome1 GeneChip to the spiked-in RNAs by BLAST of the individual PM probe sequences against the <italic>Drosophila </italic>Gene Collection release 1.0 (DGC [<xref ref-type="bibr" rid="B16">16</xref>]) clone sequences that served as the template for the cRNA samples (Materials and methods). Of the 3,860 DGC clones used in this study, 3,762 (97%) have full-length cDNA sequence available at the DGC web site, 90 have 3' and 5'-end sequence only, and eight have no available sequence. For each probe set, all clone sequences with BLAST matches to PM probe sequences in that probe set are collected, allowing at most two (out of 25 base-pair (bp)) mismatches, and only allowing matches on the correct strand. If at least three PM sequences match to a given clone, then the probe set is assigned to that clone. Matches of one probe set to more than one clone are allowed. In this manner, 3,866 probe sets are assigned to at least one DGC clone each. Among these probe sets, 1,331 have an increased concentration between the S and C chips, whereas 2,535 represent RNAs with equal concentration between the two samples. Among those probe sets which do not have any assignment using this criterion, if fewer than three PM probes within the probe set have a BLAST match to any clone, the probe set is then called 'empty' (that is, its signal should correspond to nonspecific hybridization). There are 10,131 empty probe sets; combined with the 2,535 1x probe sets, about 90% of the probe sets on the chip represent RNAs with constant expression level between the C and S samples. The rest of the probe sets are then called 'mixed', meaning that they match to more than one clone, but each with only a few PM probe matches. There are only 13 mixed probe sets. The numbers of probe sets assigned to each fold-change class are depicted in Table <xref ref-type="table" rid="T1">1</xref>.</p></sec><sec><title>Assessment of absent/present call metrics</title><p>Our dataset design provides the rare knowledge of virtually all of the RNA sequences within a complex sample (excepting the small number (3%) of clones for which only partial sequence was available, and the possible rare mistakenly assigned or contaminated clone). We can therefore evaluate various absent/present call metrics on the basis of their ability to distinguish between the known present and absent RNAs. We investigate this issue at both the probe pair level and probe set level. For the probe pair level assessment, we first identify the probe pairs which we expect to show signal, and those which should not. We thus define two classes of probe pairs: first, perfect probe pairs, whose PM probe matches perfectly to a target RNA sequence, and neither PM nor MM probe matches to any other RNA in the sample with a BLAST E-value cutoff of 1 and word size of 7, and second, empty probe pairs, whose PM and MM probes do not match to any RNA sequence when using the same criteria.</p><p>On the chip, which contains 195,994 probe pairs, there are 50,859 perfect probe pairs and 117,904 empty ones. Observation of the signal for these probe pairs (Figure <xref ref-type="fig" rid="F2">2a,b</xref>) clearly shows that there is considerable signal intensity for the empty probe pairs. Figure <xref ref-type="fig" rid="F2">2c</xref> shows the ability of several metrics - log<sub>2</sub>(PM/MM), PM-MM, <inline-graphic xlink:href="gb-2005-6-2-r16-i1.gif"/>, and log<sub>2</sub>(PM) - to distinguish between perfect and empty probe pairs, by calculating receiver-operator characteristics (ROC) curves using the perfect probe pairs as true positives and the empty ones as true negatives. Each point on a curve depicts the specificity and sensitivity for RNA detection, when using a specific value of the corresponding metric as a cutoff for classifying probe sets as present or absent. Instead of depicting the false-positive rate (the fraction of true negatives that are detected as present) on the <italic>x</italic>-axis, which is customary for these types of graphs, we show the false-discovery rate (the fraction of detected probe sets which are true negatives), which distinguishes between the metrics more effectively for the top-scoring probe sets. Figure <xref ref-type="fig" rid="F2">2</xref> clearly shows that metrics that compare the PM signal with the MM signal, such as log<sub>2</sub>(PM/MM) and PM-MM, are the most successful at distinguishing perfect from empty probe pairs. This indicates that the PM signal alone is a less effective indicator of RNA presence, probably because the probe hybridization affinity is highly sequence-dependent. However, even with the more successful metrics, only about 60% of the perfect probe sets are detected before reaching a 10% false-discovery rate, indicating that there is still a high level of variability in probe pair sensitivity, even when using the MM signal to estimate the probe hybridization affinity.</p><p>When signals from the 14 probe pairs in each probe set are combined to create a composite absence/presence call, a much larger fraction of the spiked-in RNA species can be detected reliably. To obtain absent/present calls at the probe-set level, we perform the Wilcoxon signed rank test using each of the metrics listed above [<xref ref-type="bibr" rid="B17">17</xref>]. The <italic>p</italic>-values from this test are used to generate the ROC curves in Figure <xref ref-type="fig" rid="F2">2d</xref>. Again, the best results are obtained when the metric compares PM with MM signals, as opposed to monitoring signal alone. The metric used in MAS 5.0 ((PM-MM)/(PM+MM)), which is equivalent to log<sub>2</sub>(PM/MM), performs best. Therefore, the MM signals are important in generating accurate presence/absence calls. In our dataset, about 85% of the true positives could be detected before having a 10% false-discovery rate. The detection of perfect probe pairs is not improved when we include additional information from replicates. The 15% of probe sets which are called absent may represent truly absent RNAs, owing to failed transcription or labeling (see Additional data file 5). However, as we do not have an independent measure of failed transcription for the individual cRNA sequences in the target sample, we cannot completely rule out the possibility that they are the result of non-responsive probes or a suboptimal absent/present metric that fails to score low-abundance cRNAs. Regardless, as non-responsive probes or missing target cRNAs should affect both the C and S chips identically, these factors should not limit the value of this dataset in making relative assessments of different analysis methods.</p></sec><sec><title>Generating expression summary values</title><p>The first task in analyzing Affymetrix microarrays is to combine the 14 PM and 14 MM probe intensities into a single number ('expression summary') which reflects the concentration of the probe set's target RNA species. Generating this value involves several discrete steps designed to subtract background levels, normalize signal intensities between arrays and correct for nonspecific hybridization. To compare the effectiveness of different analysis packages at each of these steps, we created multiple expression summary datasets using every possible (that is, compatible) combination of the options described below. Algorithms were chosen for their popularity with microarray researchers and their open-source availability, and were generated using the implementations found in the Bioconductor 'affy' package [<xref ref-type="bibr" rid="B18">18</xref>]. Figure <xref ref-type="fig" rid="F3">3</xref> summarizes the options that we chose within Bioconductor. We also used the dChip [<xref ref-type="bibr" rid="B19">19</xref>] and MAS 5.0 [<xref ref-type="bibr" rid="B12">12</xref>] executables made available by the respective authors in order to cross-check with the open-source implementations within Bioconductor. In addition, we applied two analysis methods that incorporate probe sequence-dependent models of nonspecific signal (<italic>Perfect Match </italic>[<xref ref-type="bibr" rid="B20">20</xref>] and <italic>gcrma </italic>[<xref ref-type="bibr" rid="B21">21</xref>]). The combinations of options that were used to generate the 152 expression summary datasets are detailed in Additional data file 2.</p><sec><title>Background correction</title><p>An estimate of the background signal, which is the signal due to nonspecific binding of fluorescent molecules or the autofluorescence of the chip surface, was generated using two possible metrics. The <italic>MAS </italic>background [<xref ref-type="bibr" rid="B17">17</xref>] is calculated on the basis of the 2nd percentile signal in each of 16 subsections of the chip, and is thus a spatially varying metric. The Robust Multi-chip Average (<italic>RMA</italic>) algorithm [<xref ref-type="bibr" rid="B22">22</xref>] subtracts a background value which is based on modeling the PM signal intensities as a convolution of an exponential distribution of signal and a normal distribution of nonspecific signal.</p></sec><sec><title>Normalization at the probe level</title><p>The signal intensities are normalized between chips to allow comparisons between them. Because in our dataset, a large number of RNAs are increased in S versus C (and none are decreased), commonly used methods often result in apparent downregulation for spiked-in probe sets in the 1x change category. We thus added a set of modified normalization methods which used our knowledge of the 1x probe sets. The following different methods were applied. <italic>Constant </italic>is a global adjustment by a constant value to equalize the chip-wide mean (or median) signal intensity between chips. <italic>Constantsubset </italic>is the same global adjustment but equalizing the mean intensity for only the probe sets with fold change equal to 1. <italic>Invariantset </italic>[<xref ref-type="bibr" rid="B23">23</xref>] is a nonlinear, intensity-dependent normalization based on a subset of probes which have similar ranks (the rank-invariant set) between two chips. <italic>Invariantsetsubset </italic>is the same as invariantset but the rank-invariant set is selected as a subset of the probe sets with fold change equal to 1. <italic>Loess </italic>normalization [<xref ref-type="bibr" rid="B24">24</xref>] is a nonlinear intensity-dependent normalization which uses a local regression to make the median fold change equal to zero, at all average intensity levels. <italic>Loesssubset </italic>normalization is the same as loess but using only the probe sets with fold change equal to 1. <italic>Quantile </italic>normalization [<xref ref-type="bibr" rid="B24">24</xref>] enforces all the chips in a dataset to have the same distribution of signal intensity. <italic>Quantilesubset </italic>normalization is the same as quantile but normalizes the spiked-in and non-spiked-in probe sets separately.</p></sec><sec><title>PM correction</title><p>We chose three ways to adjust the PM signal intensities to account for nonspecific signal. The first is to subtract the corresponding MM probe signal (<italic>subtractmm</italic>). The second is the method used in <italic>MAS </italic>5.0, in which negative values are avoided by estimating the nonspecific signal when the MM value exceeds its corresponding PM intensity [<xref ref-type="bibr" rid="B17">17</xref>]. The third is <italic>PM only </italic>(no correction). The subtractmm and MAS methods are compatible only with the MAS background correction method; that is, it does not make sense to combine these with RMA background correction.</p></sec><sec><title>Expression summary</title><p>The 14 probe intensity values were combined using one of the following robust estimators: Tukey-biweight (<italic>MAS </italic>5.0); <italic>median polish </italic>(RMA); or the model-based <italic>Li-Wong </italic>expression index (dChip). Analyses including the <italic>subtractmm </italic>PM correction method require dealing with negative values when PM is less than MM, which occurs in about a third of the cases. Within Bioconductor, the <italic>Li-Wong </italic>estimator can handle negative values, but the other two metrics mostly output 'not applicable' (NA) for the probe set when any of the constituent probe pairs has negative PM - MM. The result for <italic>MAS </italic>and <italic>median polish </italic>is NA for about 85% of the probe sets on the chip. To study the consequence of losing so many probe sets, we modified one of these two metrics (<italic>median polish</italic>) to accept negative (PM - MM) (<italic>medianpolishna</italic>), and added this metric whenever <italic>subtractmm </italic>was used.</p></sec><sec><title>Normalization at the probe set level</title><p>Many of the expression summary datasets that were produced still show a dependence of fold change on the signal intensity (Figure <xref ref-type="fig" rid="F4">4a</xref>). To correct this, a second set of expression summary datasets was created, in which a loess normalization at the probe set level was used to center the log-fold changes around zero (Figure <xref ref-type="fig" rid="F4">4b</xref>).</p></sec></sec><sec><title>Comparison of the observed fold changes with known fold changes</title><p>For each of the 150 expression summary datasets that we generated, fold changes between the S and C samples were calculated and then compared with the actual fold changes. Most expression summary datasets show good correlation between the observed and actual fold changes (Figure <xref ref-type="fig" rid="F5">5</xref>). The greatest sources of variability are probe sets with low signal intensity; as Figure <xref ref-type="fig" rid="F5">5b</xref> shows, the correlation improves dramatically when we filter out the probe sets with low signal. For all the expression summary datasets, the agreement between observed and actual fold changes is good (R<sup>2 </sup>= 86 &#x000b1; 3%) when the probe sets in the lowest quartile of signal intensity are filtered out. The expression summary datasets which involve correcting the PM signal by subtracting the MM signal (<italic>subtractmm</italic>) have the highest correlation coefficient, because low-intensity probe sets have been filtered out during processing, as described above. We therefore suggest that an important feature of a successful microarray analysis is to account for probe sets with low signal intensity, either by filtering them out or by using a signal-dependent metric for significance. Several ways of accomplishing such filtering are described below.</p><p>We also observed that the fold changes resulting from the chips are consistently lower than the actual fold changes. Apparently, the decrease in fold change is only partly the result of signal saturation (Figure <xref ref-type="fig" rid="F5">5b-c</xref>), and is not a byproduct of the robust estimators used to calculate expression summaries (because the low fold changes are also observed at the probe pair level; see Additional data file 3). In other experiments we have also observed that our Affymetrix fold-change levels are smaller than those obtained by quantitative reverse transcription (RT)-PCR (data not shown). One likely explanation is that we do not have an adequate estimate for nonspecific signal. For example, if we choose the MM signal as the nonspecific signal (thus calculating PM - MM, or PM - CT from MAS 5.0), we are probably overestimating the nonspecific signal, as the MM intensity value responds to increasing target RNA concentrations, and therefore contains some real signal. On the other hand, if we choose not to use a probe sequence-dependent nonspecific signal (such as in RMA), we are likely to underestimate the nonspecific signal for a large number of probes. In either case, the result is decreased fold change magnitudes. Artificially low fold-change values have been noted by others, including those investigating the Affymetrix Latin square [<xref ref-type="bibr" rid="B6">6</xref>], GeneLogic [<xref ref-type="bibr" rid="B22">22</xref>] and other [<xref ref-type="bibr" rid="B25">25</xref>] datasets, although some of the differences they report are smaller than are observed here.</p></sec><sec><title>Test statistics and ROC curves</title><p>Because a typical microarray experiment contains a large number of hypotheses (here 14,010) and a limited number of replicates (in this case three), high false-positive rates are a common problem in identifying DEGs. An important factor in minimizing false positives is to incorporate an appropriate error model into the signal/noise metric. We compared three <italic>t</italic>-statistic variants, which differ in their calculations of noise. The first is significance analysis for microarrays (<italic>SAM</italic>) [<xref ref-type="bibr" rid="B26">26</xref>], in which the <italic>t</italic>-statistic has a constant value added to the standard deviation. This constant 'fudge factor' is chosen to minimize the dependence of the <italic>t</italic>-statistic variance on standard deviation levels. The second is <italic>CyberT </italic>[<xref ref-type="bibr" rid="B14">14</xref>], in which the standard deviation is modeled as a function of signal intensity. The third is the <italic>basic </italic>(Student's) <italic>t</italic>-statistic. For <italic>CyberT </italic>and the <italic>basic t</italic>-test, we performed the tests on the expression summaries after log transformation, as well as on the raw data. As shown in the example ROC curve, the <italic>CyberT </italic>statistic outperforms the other statistics for the vast majority of expression summary datasets (Figure <xref ref-type="fig" rid="F6">6a</xref>). Inspection of the false positives and false negatives shows the reason for the different performance. Because <italic>CyberT </italic>uses a signal intensity-dependent standard deviation, probe sets at low signal intensities have reduced significance even when their observed fold change is high (Figure <xref ref-type="fig" rid="F6">6b</xref>). As shown in Figure <xref ref-type="fig" rid="F6">6c</xref>, the <italic>SAM </italic>algorithm (using the authors' Excel Add-in) does not effectively filter out these same false-positive probe sets (with low signal intensity and high fold change). Upon further inspection, we observed that the <italic>SAM </italic>algorithm favors using large values for the constant fudge factor, so that the <italic>t</italic>-statistic depends more on the fold change value, than on the noise level. The <italic>basic t</italic>-statistic is prone to false positives resulting from artificially low standard deviations, owing to the limited number of replicates in a typical microarray experiment (scattered magenta spots in Figure <xref ref-type="fig" rid="F6">6d</xref>). This comparison agrees with the result of Broberg [<xref ref-type="bibr" rid="B9">9</xref>], who also found that the <italic>CyberT </italic>approach (there called 'samroc') outperforms several other methods. Because the <italic>CyberT </italic>statistic clearly performs the best, we use only this statistic to compare the options for the other steps in microarray analysis, below.</p></sec><sec><title>Comparison of options at each of the other analysis steps</title><p>Performance of the various options that were investigated varied significantly, as seen by the ROC curves shown in Figure <xref ref-type="fig" rid="F7">7</xref>. First, we find that a second loess normalization at the probe set level generally yields a superior result (Figure <xref ref-type="fig" rid="F7">7a,f</xref>), as could be expected by observing the strong intensity-dependence of the fold-change values in Figure <xref ref-type="fig" rid="F4">4</xref>. This intensity-dependence is most likely the result of the unequal concentrations of labeled cRNA for the C and S chips. However, this artifact is not unique to this dataset. We routinely observe similar intensity-dependent fold changes in comparisons of biological samples, especially when there are small differences in starting RNA amounts between the two samples (see Additional data file 4 for an example). Therefore, in the absence of a biological reason to suppose that the fold change should depend on signal intensity, it is important to view the plot of log fold change versus signal and recenter it around <italic>y </italic>= 0 when necessary. Owing to the significant improvement seen when the second normalization is used, the subsequent figures (Figure <xref ref-type="fig" rid="F7">7b-f</xref>) only show the comparison of the remaining options in conjunction with this step (blue curves in Figure <xref ref-type="fig" rid="F7">7a</xref>).</p><p>Among the background correction methods, the <italic>MAS </italic>5.0 method generally performs better than the <italic>RMA </italic>method (Figure <xref ref-type="fig" rid="F7">7b</xref>). No clearly superior normalization method was found at the probe level (Figure <xref ref-type="fig" rid="F7">7c</xref>), even when using the subset normalization variants, although quantile normalization tended to underperform in the absence of the second normalization step.</p><p>With respect to adjusting the PM probe intensity with an estimate of nonspecific signal, Figure <xref ref-type="fig" rid="F7">7d</xref> clearly shows that either subtracting the MM signal (<italic>subtractmm</italic>), or using the <italic>MAS </italic>5.0 correction method, is better than using uncorrected or RMA-corrected PM values (<italic>PM-only</italic>). The <italic>MAS </italic>5.0 method performs the best because it does not create any negative values. This result is in apparent conflict with the conclusions of Irizarry <italic>et al</italic>. [<xref ref-type="bibr" rid="B5">5</xref>], who show drastically reduced noise at low signal intensity levels when the PM signal is not adjusted with MM values, and therefore better detection of spiked-in probe sets when using the fold change as the cutoff criterion. However, when Irizarry <italic>et al</italic>. use a test statistic that takes the variance into account, <italic>PM-only </italic>and MM-corrected methods (<italic>MAS</italic>) have similar sensitivity/specificity (Figure <xref ref-type="fig" rid="F3">3d,e</xref> from [<xref ref-type="bibr" rid="B5">5</xref>]). In the dataset presented here, the <italic>MAS </italic>PM-correction method yields a high variance at low signal-intensity levels, which effectively reduces the false-positive calls at this intensity range when using CyberT, thus resulting in better performance than when using <italic>PM-only</italic>. We can reconcile the Irizarry <italic>et al</italic>. result with our observations by considering a major difference between the datasets used by the two studies. Both the Affymetrix and GeneLogic Latin square datasets used in [<xref ref-type="bibr" rid="B5">5</xref>] involve a small number (10-20) of spiked-in cRNAs in a common biological RNA sample, and therefore comparisons are made between two samples that are almost exactly the same. As a result, the nonspecific component of any given probe's signal is expected to be almost identical in the two samples, and should not contribute to false-positive differential expression calls. In contrast, a large fraction of our dataset is differentially expressed; in addition, the C sample contains a high concentration of (unlabeled) poly(C) RNA. Because nonspecific hybridization depends both on a probe's affinity and on the concentrations of RNAs that can hybridize to it in a nonspecific fashion, we expect that each probe's signal can have different contributions of nonspecific hybridization between the C and S chips. Figure <xref ref-type="fig" rid="F2">2a</xref> shows that nonspecific hybridization can be a large component of a probe's signal. We hypothesize that, for our dataset, <italic>PM-only </italic>performs worse than MM-corrected methods (<italic>subtractmm </italic>or <italic>MAS</italic>) because <italic>PM-only </italic>does not try to correct for nonspecific hybridization in a probe-specific fashion. In contrast, for the Latin square datasets used in [<xref ref-type="bibr" rid="B5">5</xref>], <italic>PM-only </italic>works just as well as MM-corrected methods because the contribution of nonspecific hybridization is constant. Therefore, datasets which compare substantially different RNA samples (such as two different tissue types) should probably be processed using the <italic>MAS </italic>5.0 method for PM correction.</p><p>Figure <xref ref-type="fig" rid="F7">7e</xref> compares the different robust estimators that were used to create expression summaries. Of these, <italic>median polish </italic>(RMA) and the Tukey Biweight methods (<italic>MAS </italic>5.0) perform the best. Figure <xref ref-type="fig" rid="F7">7f</xref> highlights the 10 best summary method option sets, which are also depicted in Figure <xref ref-type="fig" rid="F3">3</xref>, as well as straight applications of some popular software, with or without an additional normalization step at the probe-set level. The result from the MAS 5.0 software, when adjusted with the second loess normalization step, ranks among the top 10. However, the other methods (dChip, RMA and MAS 5.0 without probe-set normalization) are not as sensitive or specific at detecting DEGs.</p><p>We were concerned that some of our analyses might be confounded by a possible correlation between low fold change and low expression summary levels, which could affect the interpretations of Figure <xref ref-type="fig" rid="F7">7</xref> (comparing different methods) and the detection of small fold changes (see below). We therefore examined the distribution of expression levels within each spiked-in fold change group, and compared the methods with respect to their ability to detect a subset of probe sets with low expression summary levels (Additional data file 5). We found that the distribution of expression levels for the known DEGs was comparable among all the fold-change groups, and that all the conclusions reported here are similarly applicable to the low expression subset. However, the sensitivity of all methods was reduced, suggesting that they perform less well on weakly expressed than on highly expressed genes. As the number of low signal spike-ins was relatively small (265 probe sets), resulting in reduced accuracy for the ROC curves, the development of additional control datasets specifically focusing on DEG detection at low cRNA concentrations will be an important extension of this study.</p><p>Models dependent on probe sequence provide a promising route to improving the accuracy of nonspecific signal measures. Here, we applied two different models (<italic>perfect match </italic>and <italic>gcrma</italic>) to the control dataset. With respect to detecting the true DEGs, these two models perform reasonably well, although slightly less well than the MAS 5.0 PM correction method. When we consider only the low signal DEGs (Additional data file 5), <italic>gcrma </italic>outperforms perfect match, and is similar in effectiveness to the top analysis option combinations.</p></sec><sec><title>Estimating false discovery rates</title><p>We have identified a set of analysis choices that optimally ranks genes according to significance of differential expression. To decide how many of the top genes to investigate further in follow-up experiments, it would be useful to have accurate estimates of the false-discovery rate (FDR or <italic>q</italic>-value), which is the fraction of false positives within a list of genes exceeding a given statistical cutoff. We used our control dataset to compare the actual <italic>q</italic>-values for the 10 optimal expression summary datasets with <italic>q</italic>-value estimates from the permutation method implemented in SAM. As shown in Figure <xref ref-type="fig" rid="F8">8b</xref>, permutation-based <italic>q</italic>-value calculations using each of the top ten datasets underestimate the actual <italic>q</italic>-value for a given cutoff. We attempted to reduce the contribution of biases inherent in any given data-processing step by combining the results from the top 10 expression summary datasets. The goal is to pinpoint those genes that are called significant regardless of small changes in the analysis protocol (changes that only marginally affect the DEG detection sensitivity and specificity according to our control dataset). To identify these 'robustly significant' genes, we created a combined statistic from the top 10 datasets depicted in Figure <xref ref-type="fig" rid="F7">7f</xref>, taking into account the significance of each individual test, as well as the variation in fold change between datasets (see Materials and methods). This combined statistic distinguishes between true and false DEGs equally as well as the best of the 10 input datasets (Figure <xref ref-type="fig" rid="F8">8a</xref>). To make false-discovery rate estimates using this combined statistic, each of the 10 datasets was permuted (using the same permutation) and the combined statistic was recalculated. Figure <xref ref-type="fig" rid="F8">8b</xref> shows that this combined statistic gives a more accurate <italic>q</italic>-value estimate than any of the individual datasets. However, there is still considerable difference between the estimated and actual <italic>q</italic>-values. For example, if we estimate <italic>q </italic>= 0.05, the corresponding CyberT statistic has an actual <italic>q </italic>= 0.18, and if we estimate <italic>q </italic>= 0.1, then the actual <italic>q </italic>= 0.3. Therefore, until more accurate methods for estimating the false-discovery rate are developed, we recommend that a conservative choice of false-discovery rate cutoff be used (for example &#x0003c; 1%) to prevent actual numbers of false-positive DEG calls (that is, the true, rather than estimated, FDR) from being too high.</p></sec><sec><title>Assessment of sensitivity and specificity</title><p>As the identities and relative concentrations of each of the RNAs in the experiment were known, we were able to assess directly the sensitivity and specificity obtained by the best-performing methods. Examination of the ROC curves in Figure <xref ref-type="fig" rid="F7">7</xref> reveals that sensitivity begins to plateau as the false discovery rate (<italic>q</italic>) increases from 10% to 30%. Taking an upper acceptable bound for <italic>q </italic>as 10%, the maximum sensitivity obtained is about 71%. Thus, under the best-performing analysis scheme, roughly 380 (29%) of the 1,309 DEGs are not detected as being differentially expressed, with the number of false positives equaling about 105. At <italic>q </italic>= 2%, sensitivity reduces to around 60%, meaning that more than 520 DEGs are missed, albeit with fewer than 20 false positives.</p><p>We next looked at the dependence of sensitivity and specificity on the magnitude of the spiked-in fold-change value. We find that at <italic>q </italic>= 10%, sensitivity is increased to 93% when only cRNAs that differ by twofold or more are considered as DEGs (Figure <xref ref-type="fig" rid="F9">9a</xref>). This sensitivity decreases only slightly (to 90%) when <italic>q </italic>is lowered to 5%. However, sensitivity drops off sharply as differences in expression below twofold are considered. At <italic>q </italic>= 10%, only 82% of DEGs with 1.5-fold or greater changes in expression are identified, dropping to 71% for all DEGs at 1.2-fold change or above (77% and 67% at <italic>q </italic>= 5%, respectively). The reduction in sensitivity is almost wholly due to the low-fold-change genes: less than 50% of DEGs with fold change 1.5, and none of the DEGs with fold change 1.2, are detected at <italic>q </italic>= 10% (Figure <xref ref-type="fig" rid="F9">9b</xref>).</p><p>It is tempting to conclude from this that we are achieving adequate sensitivity in our experiments and merely need not bother with DEGs below the twofold change level. However, we would argue that obtaining greater sensitivity should be an important goal. There is ample demonstration in the biological and medical literature that small changes in gene expression can have serious phenotypic consequences, as seen both from haploinsufficiencies and from mutations that reduce levels of gene expression through transcriptional regulation or effects on mRNA stability. Furthermore, effective fold changes seen in a microarray experiment might be considerably smaller than actual fold changes within a cell, if the sample contains additional cell populations that dilute the fold-change signal. As it is often not possible to obtain completely homogeneous samples (for example, when profiling an organ composed of several specialized cell types), this is likely to prove a very real limitation to detecting DEGs. In cases where pure cell populations can be obtained, for example by laser capture microdissection, the numbers of cells are often small and RNA needs to undergo amplification in order to have enough for hybridization. Here, non-linearities in RNA amplification might also lead to observed fold changes that fall below the twofold level. We used three microarray replicates for this study, as this is frequently the number chosen by experimentalists because of cost and limiting amounts of RNA. One possible extension of this work would be to examine how many replicates are necessary for reliable detection of DEGs at a given fold change level.</p></sec></sec><sec><title>Conclusions</title><p>We have compared a number of popular analysis options for the purpose of identifying differentially expressed genes using an Affymetrix GeneChip control dataset. Clear differences in sensitivity and specificity were observed among the analysis method choices. By trying all possible combinations of options, we could see that choices at some steps of analysis are more critical than at others; for example, the normalization methods that we considered perform similarly, whereas the choice of the PM adjustment method can strongly influence the accuracy of the results. On the basis of our observations, we have chosen a best route for finding DEGs (Figure <xref ref-type="fig" rid="F3">3</xref>). As any single choice of analysis methods can introduce bias, we have proposed a way to combine the results from several expression summary datasets in order to obtain more accurate FDR estimates. However, these estimates remain substantially lower than actual false-discovery rates, demonstrating the need for continued development of ways to assess the false-discovery rate in experimental datasets. Our analysis further revealed the existence of a high false-negative rate (low sensitivity), especially for those DEGs with a small fold change, and thus suggests the need for improved analysis methods for Affymetrix microarrays. In order to be feasible, this study investigated only a fraction of the current options. The raw data from our hybridizations are available in Additional data files 6-7 and on our websites [<xref ref-type="bibr" rid="B27">27</xref>,<xref ref-type="bibr" rid="B28">28</xref>], and we encourage the use of this dataset for benchmarking existing and future algorithms. Also important will be the construction of additional control datasets to explore issues not well covered by the present study, such as performance of the analysis methods for specifically detecting low-abundance RNAs and the effects of including larger numbers of replicate arrays. We hope that these experiments will help researchers to choose the most effective analysis routines among those available, as well as guide the design of new methods that maximize the information that can be obtained from expression-profiling data.</p></sec><sec sec-type="materials|methods"><title>Materials and methods</title><sec><title>cRNA and hybridization</title><p>PCR products from <italic>Drosophila </italic>Gene Collection release 1.0 cDNA clones [<xref ref-type="bibr" rid="B16">16</xref>] were generated in 96-well format, essentially as described [<xref ref-type="bibr" rid="B29">29</xref>]. Each PCR product includes T7 and SP6 promoters located 5' and 3' to the coding region of the cDNA, respectively. Each PCR reaction was checked by gel electrophoresis for a band of detectable intensity and the correct approximate size. Those clones which did not yield PCR product were labeled as 'failed' and eliminated from subsequent analysis. From sequence verification of randomly selected clones, we estimate the number of mislabeled clones to be &#x0003c; 3%. The contents of the plates were collected into 19 pools, such that each pool contained the PCR product from one to four plates (approximately 96-384 clones). Biotinylated cRNA was generated from each pool using SP6 polymerase (detailed protocol available upon request) and the reactions were purified using RNeasy columns (Qiagen). Concentration and purity for each pool was determined both by spectrophotometry and with an Agilent Bioanalyzer. The labeled products were then divided into each of two samples - constant (C) and spike (S) - at specific relative concentrations (Table <xref ref-type="table" rid="T1">1</xref>, Figure <xref ref-type="fig" rid="F1">1</xref>). Because the C sample contains less total RNA than the S sample, 20 &#x003bc;g of (unlabeled) poly(C) RNA was added to the C sample to equalize the nucleic acid concentrations. By mixing the labeled pools just before hybridization, we ensured that the fold change between C and S is uniform for all RNAs within a single pool, while still allowing the absolute concentrations of individual RNAs to vary. The two samples were then hybridized in triplicate to Affymetrix <italic>Drosophila </italic>arrays (DrosGenome1) using standard Affymetrix protocols. We chose to hybridize each replicate chip from an aliquot of a single C (or S) sample, resulting in technical replication; thus this dataset does not address the noise introduced by the labeling and mixing steps. The clones comprising each pool can be found in Additional data file 8, and the resulting Affymetrix chip intensity files (.CEL) files are available in Additional data files 6-7.</p></sec><sec><title>Estimate of RNA concentrations</title><p>The total amount of labeled cRNA that was added to each chip (approximately 18 &#x003bc;g) was comparable to a typical Affymetrix experiment (20 &#x003bc;g). Although we do not know the individual RNA concentrations, we estimate that these span the average RNA concentration in a biological GeneChip experiment. Our biological RNA samples typically result in about 40% of the probe sets on the DrosGenome1 chip called present, so the mean amount of individual RNA is 20 &#x003bc;g/(14,010 &#x000d7; 0.40) = 0.003 &#x003bc;g/RNA. In the C chips, the average concentration of individual RNAs in the different pools range from 0.0008 to 0.007 &#x003bc;g/RNA, so the concentrations are roughly similar to those in a typical experiment. We note, however, that there is no way to ensure that the concentration distribution is truly reflective of a real RNA distribution. This is especially true with respect to the low end of the range, as it is usually unknown how many of the absent genes on an array are truly absent versus weakly expressed and thus poorly detected by the analysis algorithms used. Therefore, our analysis possibly favors methods that perform best when applied to highly expressed genes.</p></sec><sec><title>Software</title><p>All of the analysis was performed using the statistical program R [<xref ref-type="bibr" rid="B30">30</xref>], including the affy and gcrma packages from Bioconductor [<xref ref-type="bibr" rid="B18">18</xref>], and scripts adapted from the hdarray library by Baldi <italic>et al</italic>. [<xref ref-type="bibr" rid="B31">31</xref>,<xref ref-type="bibr" rid="B32">32</xref>]. In addition, we used the dChip [<xref ref-type="bibr" rid="B19">19</xref>], MAS 5.0 [<xref ref-type="bibr" rid="B12">12</xref>], Perfect Match [<xref ref-type="bibr" rid="B20">20</xref>,<xref ref-type="bibr" rid="B21">21</xref>] and SAM [<xref ref-type="bibr" rid="B27">27</xref>] executables made available by the respective authors. Note that the false-discovery rate calculations were slightly different depending on the <italic>t</italic>-statistic variant: for the SAM statistic, false discovery rates from the authors' Excel Add-in software was used, whereas for the CyberT and basic <italic>t</italic>-statistics, the Bioconductor false-discovery rate implementation was applied, which includes an extra step to enforce monotonicity of the ROC curve. In our experience, this extra step does not qualitatively alter the results. All scripts generated in this study are available for use [<xref ref-type="bibr" rid="B27">27</xref>,<xref ref-type="bibr" rid="B28">28</xref>].</p></sec><sec><title>Calculation of the statistic that combines the results of multiple expression summary datasets</title><p>Say we have <italic>n </italic>datasets and <italic>C</italic><sub><italic>ij</italic></sub>, <italic>S</italic><sub><italic>ij </italic></sub>are the logged signals for a given probe set in the <italic>j</italic>th C and S chips, respectively, in dataset <italic>i</italic>. The mean signal (for this probe set) for the C chips in dataset <italic>i </italic>is:</p><p><inline-graphic xlink:href="gb-2005-6-2-r16-i2.gif"/></p><p>where <inline-graphic xlink:href="gb-2005-6-2-r16-i3.gif"/> is the number of C chips in dataset <italic>i</italic>; similarly, the mean signal for the S chips in dataset <italic>i </italic>is:</p><p><inline-graphic xlink:href="gb-2005-6-2-r16-i4.gif"/></p><p>The mean fold change over all datasets is:</p><p><inline-graphic xlink:href="gb-2005-6-2-r16-i5.gif"/></p><p>The modified standard deviation for the C chips in dataset <italic>i </italic>is based on the CyberT estimate:</p><p><inline-graphic xlink:href="gb-2005-6-2-r16-i6.gif"/></p><p>where <italic>const </italic>is the weight for the contribution of the average standard deviation <inline-graphic xlink:href="gb-2005-6-2-r16-i7.gif"/> for probe sets with the same average signal intensity as <italic>C</italic><sub><italic>ij</italic></sub>. The modified standard deviation for the S chips in dataset <italic>i </italic>(<italic>sd.S</italic><sub><italic>i</italic></sub>) is defined analogously. The pooled variance over all 10 datasets is defined as:</p><p><inline-graphic xlink:href="gb-2005-6-2-r16-i8.gif"/></p><p>The variance between the 10 datasets is defined as:</p><p><inline-graphic xlink:href="gb-2005-6-2-r16-i9.gif"/></p><p>Then the combined statistic was chosen to be:</p><p><inline-graphic xlink:href="gb-2005-6-2-r16-i10.gif"/></p></sec></sec><sec><title>Additional data files</title><p>Additional data is available with the online version of this article. Additional data file contains a figure and explanatory legend showing the degree of overlap between two lists of differentially expressed genes. Additional data file <xref ref-type="supplementary-material" rid="s2">2</xref> lists all analysis option combinations used to generate the expression summary datasets in this study. Additional data file <xref ref-type="supplementary-material" rid="s3">3</xref> is a plot of observed vs actual spiked-in fold changes at the probe level. Additional data file <xref ref-type="supplementary-material" rid="s4">4</xref> shows an example of asymmetric M (log<sub>2 </sub>fold change) vs A (average log<sub>2 </sub>signal) plot for the comparison of two biological samples. Additional data file <xref ref-type="supplementary-material" rid="s5">5</xref> contains a comparison of the analysis methods with respect to the detection of DEGs with low signal. Additional data file <xref ref-type="supplementary-material" rid="s6">6</xref> is a Zip archive containing plain text files (in Affymetrix CEL format), Affymetrix *.CEL files for the C chips in this dataset. Additional data file <xref ref-type="supplementary-material" rid="s7">7</xref> is a Zip archive containing plain text files (in Affymetrix CEL format), Affymetrix *.CEL files for the S chips in this dataset. Additional data file <xref ref-type="supplementary-material" rid="s8">8</xref> contains detailed information for the individual DGC clones used in this study.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="s1"><caption><title>Additional data file 1</title><p>A figure and explanatory legend showing the degree of overlap between two lists of differentially expressed genes</p></caption><media xlink:href="gb-2005-6-2-r16-s1.doc" mimetype="application" mime-subtype="msword"><caption><p>Click here for additional data file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="s2"><caption><title>Additional data file 2</title><p>All analysis option combinations used to generate the expression summary datasets in this study</p></caption><media xlink:href="gb-2005-6-2-r16-s2.xls" mimetype="application" mime-subtype="vnd.ms-excel"><caption><p>Click here for additional data file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="s3"><caption><title>Additional data file 3</title><p>A plot of observed vs actual spiked-in fold changes at the probe level</p></caption><media xlink:href="gb-2005-6-2-r16-s3.doc" mimetype="application" mime-subtype="msword"><caption><p>Click here for additional data file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="s4"><caption><title>Additional data file 4</title><p>An example of asymmetric M (log<sub>2 </sub>fold change) vs A (average log<sub>2 </sub>signal) plot for the comparison of two biological samples</p></caption><media xlink:href="gb-2005-6-2-r16-s4.doc" mimetype="application" mime-subtype="msword"><caption><p>Click here for additional data file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="s5"><caption><title>Additional data file 5</title><p>A comparison of the analysis methods with respect to the detection of DEGs with low signal</p></caption><media xlink:href="gb-2005-6-2-r16-s5.doc" mimetype="application" mime-subtype="msword"><caption><p>Click here for additional data file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="s6"><caption><title>Additional data file 6</title><p>A Zip archive containing plain text files (in Affymetrix CEL format), Affymetrix *.CEL files for the C chips in this dataset</p></caption><media xlink:href="gb-2005-6-2-r16-s6.zip" mimetype="application" mime-subtype="x-zip-compressed"><caption><p>Click here for additional data file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="s7"><caption><title>Additional data file 7</title><p>A Zip archive containing plain text files (in Affymetrix CEL format), Affymetrix *.CEL files for the S chips in this dataset</p></caption><media xlink:href="gb-2005-6-2-r16-s7.zip" mimetype="application" mime-subtype="x-zip-compressed"><caption><p>Click here for additional data file</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="s8"><caption><title>Additional data file 8</title><p>Detailed information for the individual DGC clones used in this study</p></caption><media xlink:href="gb-2005-6-2-r16-s8.xls" mimetype="application" mime-subtype="vnd.ms-excel"><caption><p>Click here for additional data file</p></caption></media></supplementary-material></sec></body><back><ack><sec><title>Acknowledgements</title><p>We thank M. Ramoni and M. Morrissey for helpful comments on the manuscript, K. Kerr and A. Wohlheuter for assistance with, and N. Perrimon for resources for, the PCR, the HMS Biopolymers facility for assistance with robotics and GeneChip hybridization, and B. Estrada and L. Raj for sharing the data depicted in Additional Data Files 1 and 4, respectively. S.E.C. was supported by a PhRMA Foundation CEIGI grant, a Brigham and Women's Research Council bioinformatics grant, and NIH fellowship F32 GM67483-01A1. A.M.M. is an Associate Investigator of the Howard Hughes Medical Institute. G.M.C. is supported by a PhRMA Foundation CEIGI grant. M.S.H. is supported by NIH grant K22-HG002489.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lockhart</surname><given-names>DJ</given-names></name><name><surname>Dong</surname><given-names>H</given-names></name><name><surname>Byrne</surname><given-names>MC</given-names></name><name><surname>Follettie</surname><given-names>MT</given-names></name><name><surname>Gallo</surname><given-names>MV</given-names></name><name><surname>Chee</surname><given-names>MS</given-names></name><name><surname>Mittmann</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Kobayashi</surname><given-names>M</given-names></name><name><surname>Horton</surname><given-names>H</given-names></name><etal></etal></person-group><article-title>Expression monitoring by hybridization to high-density oligonucleotide arrays.</article-title><source>Nat Biotechnol</source><year>1996</year><volume>14</volume><fpage>1675</fpage><lpage>1680</lpage><pub-id pub-id-type="pmid">9634850</pub-id><pub-id pub-id-type="doi">10.1038/nbt1296-1675</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schena</surname><given-names>M</given-names></name><name><surname>Shalon</surname><given-names>D</given-names></name><name><surname>Davis</surname><given-names>RW</given-names></name><name><surname>Brown</surname><given-names>PO</given-names></name></person-group><article-title>Quantitative monitoring of gene expression patterns with a complementary DNA microarray.</article-title><source>Science</source><year>1995</year><volume>270</volume><fpage>467</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">7569999</pub-id></citation></ref><ref id="B3"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Parmigiani</surname><given-names>G</given-names></name><name><surname>Garrett</surname><given-names>ES</given-names></name><name><surname>Irizarry</surname><given-names>RA</given-names></name><name><surname>Zeger</surname><given-names>SL</given-names></name></person-group><source>The analysis of gene expression data.</source><year>2003</year><publisher-name>New York: Springer Verlag</publisher-name></citation></ref><ref id="B4"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Barash</surname><given-names>Y</given-names></name><name><surname>Dehan</surname><given-names>E</given-names></name><name><surname>Krupsky</surname><given-names>M</given-names></name><name><surname>Franklin</surname><given-names>W</given-names></name><name><surname>Geraci</surname><given-names>M</given-names></name><name><surname>Friedman</surname><given-names>N</given-names></name><name><surname>Kaminski</surname><given-names>N</given-names></name></person-group><article-title>Comparative analysis of algorithms for signal quantitation from oligonucleotide microarrays.</article-title><source>Bioinformatics Adv Access</source><year>2004</year><volume>1</volume><fpage>1</fpage></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Irizarry</surname><given-names>RA</given-names></name><name><surname>Bolstad</surname><given-names>BM</given-names></name><name><surname>Collin</surname><given-names>F</given-names></name><name><surname>Cope</surname><given-names>LM</given-names></name><name><surname>Hobbs</surname><given-names>B</given-names></name><name><surname>Speed</surname><given-names>TP</given-names></name></person-group><article-title>Summaries of Affymetrix GeneChip probe level data.</article-title><source>Nucleic Acids Res</source><year>2003</year><volume>31</volume><fpage>e15</fpage><pub-id pub-id-type="pmid">12582260</pub-id><pub-id pub-id-type="doi">10.1093/nar/gng015</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rajagopalan</surname><given-names>D</given-names></name></person-group><article-title>A comparison of statistical methods for analysis of high density oligonucleotide array data.</article-title><source>Bioinformatics</source><year>2003</year><volume>19</volume><fpage>1469</fpage><lpage>1476</lpage><pub-id pub-id-type="pmid">12912826</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btg202</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lemon</surname><given-names>WJ</given-names></name><name><surname>Liyanarachchi</surname><given-names>S</given-names></name><name><surname>You</surname><given-names>M</given-names></name></person-group><article-title>A high-performance test of differential gene expression for oligonucleotide arrays.</article-title><source>Genome Biol</source><year>2003</year><volume>4</volume><fpage>R67</fpage><pub-id pub-id-type="pmid">14519202</pub-id><pub-id pub-id-type="doi">10.1186/gb-2003-4-10-r67</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>YD</given-names></name><name><surname>Dai</surname><given-names>H</given-names></name><name><surname>Schadt</surname><given-names>EE</given-names></name><name><surname>Cavet</surname><given-names>G</given-names></name><name><surname>Edwards</surname><given-names>SW</given-names></name><name><surname>Stepaniants</surname><given-names>SB</given-names></name><name><surname>Duenwald</surname><given-names>S</given-names></name><name><surname>Kleinhanz</surname><given-names>R</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Shoemaker</surname><given-names>DD</given-names></name><etal></etal></person-group><article-title>Microarray standard dataset and figures of merit for comparing data processing methods and experiment designs.</article-title><source>Bioinformatics</source><year>2003</year><volume>19</volume><fpage>956</fpage><lpage>965</lpage><pub-id pub-id-type="pmid">12761058</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btg126</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Broberg</surname><given-names>P</given-names></name></person-group><article-title>Statistical methods for ranking differentially expressed genes.</article-title><source>Genome Biol</source><year>2003</year><volume>4</volume><fpage>R41</fpage><pub-id pub-id-type="pmid">12801415</pub-id><pub-id pub-id-type="doi">10.1186/gb-2003-4-6-r41</pub-id></citation></ref><ref id="B10"><citation citation-type="other"><article-title>Affymetrix - Latin square data</article-title><ext-link ext-link-type="uri" xlink:href="http://www.affymetrix.com/support/technical/sample_data/datasets.affx"/></citation></ref><ref id="B11"><citation citation-type="other"><article-title>Scientific studies</article-title><ext-link ext-link-type="uri" xlink:href="http://www.genelogic.com/media/studies/index.cfm"/></citation></ref><ref id="B12"><citation citation-type="other"><article-title>Affymetrix: technical support documentation</article-title><ext-link ext-link-type="uri" xlink:href="http://www.affymetrix.com/support/technical/byproduct.affx?product=mas"/></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>YH</given-names></name><name><surname>Dudoit</surname><given-names>S</given-names></name><name><surname>Luu</surname><given-names>P</given-names></name><name><surname>Lin</surname><given-names>DM</given-names></name><name><surname>Peng</surname><given-names>V</given-names></name><name><surname>Ngai</surname><given-names>J</given-names></name><name><surname>Speed</surname><given-names>TP</given-names></name></person-group><article-title>Normalization for cDNA microarray data: a robust composite method addressing single and multiple slide systematic variation.</article-title><source>Nucleic Acids Res</source><year>2002</year><volume>30</volume><fpage>e15</fpage><pub-id pub-id-type="pmid">11842121</pub-id><pub-id pub-id-type="doi">10.1093/nar/30.4.e15</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Baldi</surname><given-names>P</given-names></name><name><surname>Long</surname><given-names>AD</given-names></name></person-group><article-title>A Bayesian framework for the analysis of microarray expression data: regularized <italic>t</italic>-test and statistical inferences of gene changes.</article-title><source>Bioinformatics</source><year>2001</year><volume>17</volume><fpage>509</fpage><lpage>519</lpage><pub-id pub-id-type="pmid">11395427</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/17.6.509</pub-id></citation></ref><ref id="B15"><citation citation-type="other"><article-title>Affymetrix - Drosophila genome array</article-title><ext-link ext-link-type="uri" xlink:href="http://www.affymetrix.com/products/arrays/specific/fly.affx"/></citation></ref><ref id="B16"><citation citation-type="other"><article-title>BDGP: Drosophila gene collection</article-title><ext-link ext-link-type="uri" xlink:href="http://www.fruitfly.org/DGC/index.html"/></citation></ref><ref id="B17"><citation citation-type="other"><article-title>Affymetrix - Statistical Algorithms Description Document</article-title><ext-link ext-link-type="uri" xlink:href="http://www.affymetrix.com/support/technical/whitepapers/sadd_whitepaper.pdf"/></citation></ref><ref id="B18"><citation citation-type="other"><article-title>Bioconductor</article-title><ext-link ext-link-type="uri" xlink:href="http://www.bioconductor.org"/></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Wong</surname><given-names>WH</given-names></name></person-group><article-title>Model-based analysis of oligonucleotide arrays: expression index computation and outlier detection.</article-title><source>Proc Natl Acad Sci USA</source><year>2001</year><volume>98</volume><fpage>31</fpage><lpage>36</lpage><pub-id pub-id-type="pmid">11134512</pub-id><pub-id pub-id-type="doi">10.1073/pnas.011404098</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Miles</surname><given-names>MF</given-names></name><name><surname>Aldape</surname><given-names>KD</given-names></name></person-group><article-title>A model of molecular interactions on short oligonucleotide microarrays.</article-title><source>Nat Biotechnol</source><year>2003</year><volume>21</volume><fpage>818</fpage><lpage>821</lpage><comment><bold>Corrigendum: </bold><italic>Nat Biotechnol </italic>2003, <bold>21:</bold>941.</comment><pub-id pub-id-type="pmid">12794640</pub-id><pub-id pub-id-type="doi">10.1038/nbt836</pub-id></citation></ref><ref id="B21"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Irizarry</surname><given-names>RA</given-names></name></person-group><article-title>Stochastic models inspired by hybridization theory for short oligonucleotide arrays.</article-title><source>Proc 8th Conf Res Comput Mol Biol</source><year>2004</year><publisher-name>New York: ACM Press</publisher-name><fpage>98</fpage><lpage>106</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biostat.jhsph.edu/~ririzarr/papers/p177-irizarry.pdf"/></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Irizarry</surname><given-names>RA</given-names></name><name><surname>Hobbs</surname><given-names>B</given-names></name><name><surname>Collin</surname><given-names>F</given-names></name><name><surname>Beazer-Barclay</surname><given-names>YD</given-names></name><name><surname>Antonellis</surname><given-names>KJ</given-names></name><name><surname>Scherf</surname><given-names>U</given-names></name><name><surname>Speed</surname><given-names>TP</given-names></name></person-group><article-title>Exploration, normalization, and summaries of high density oligonucleotide array probe level data.</article-title><source>Biostatistics</source><year>2003</year><volume>4</volume><fpage>249</fpage><lpage>264</lpage><pub-id pub-id-type="pmid">12925520</pub-id><pub-id pub-id-type="doi">10.1093/biostatistics/4.2.249</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Schadt</surname><given-names>EE</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Ellis</surname><given-names>B</given-names></name><name><surname>Wong</surname><given-names>WH</given-names></name></person-group><article-title>Feature extraction and normalization algorithms for high-density oligonucleotide gene expression array data.</article-title><source>J Cell Biochem Suppl</source><year>2001</year><issue>Suppl 37</issue><fpage>120</fpage><lpage>125</lpage><pub-id pub-id-type="pmid">11842437</pub-id><pub-id pub-id-type="doi">10.1002/jcb.10073</pub-id></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Bolstad</surname><given-names>BM</given-names></name><name><surname>Irizarry</surname><given-names>RA</given-names></name><name><surname>Astrand</surname><given-names>M</given-names></name><name><surname>Speed</surname><given-names>TP</given-names></name></person-group><article-title>A comparison of normalization methods for high density oligonucleotide array data based on variance and bias.</article-title><source>Bioinformatics</source><year>2003</year><volume>19</volume><fpage>185</fpage><lpage>193</lpage><pub-id pub-id-type="pmid">12538238</pub-id><pub-id pub-id-type="doi">10.1093/bioinformatics/19.2.185</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Chudin</surname><given-names>E</given-names></name><name><surname>Walker</surname><given-names>R</given-names></name><name><surname>Kosaka</surname><given-names>A</given-names></name><name><surname>Wu</surname><given-names>SX</given-names></name><name><surname>Rabert</surname><given-names>D</given-names></name><name><surname>Chang</surname><given-names>TK</given-names></name><name><surname>Kreder</surname><given-names>DE</given-names></name></person-group><article-title>Assessment of the relationship between signal intensities and transcript concentration for Affymetrix GeneChip arrays.</article-title><source>Genome Biol</source><year>2002</year><volume>3</volume><fpage>research0005.1</fpage><lpage>0005.10</lpage><pub-id pub-id-type="pmid">11806828</pub-id><pub-id pub-id-type="doi">10.1186/gb-2001-3-1-research0005</pub-id></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tusher</surname><given-names>VG</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Chu</surname><given-names>G</given-names></name></person-group><article-title>Significance analysis of microarrays applied to the ionizing radiation response.</article-title><source>Proc Natl Acad Sci USA</source><year>2001</year><volume>98</volume><fpage>5116</fpage><lpage>5121</lpage><pub-id pub-id-type="pmid">11309499</pub-id><pub-id pub-id-type="doi">10.1073/pnas.091062498</pub-id></citation></ref><ref id="B27"><citation citation-type="other"><article-title>The Golden Spike Experiment</article-title><ext-link ext-link-type="uri" xlink:href="http://www.elwood9.net/spike"/></citation></ref><ref id="B28"><citation citation-type="other"><article-title>Assessment of microarray analysis methods</article-title><ext-link ext-link-type="uri" xlink:href="http://www.bioinformatics.buffalo.edu/halfon/spike"/></citation></ref><ref id="B29"><citation citation-type="other"><article-title>BDGP Resources: PCR amplification of cDNAs from bacterial cultures: DGC/pOT2</article-title><ext-link ext-link-type="uri" xlink:href="http://www.fruitfly.org/about/methods/pOT2a.html"/></citation></ref><ref id="B30"><citation citation-type="other"><article-title>The R Project for statistical computing</article-title><ext-link ext-link-type="uri" xlink:href="http://www.r-project.org"/></citation></ref><ref id="B31"><citation citation-type="other"><article-title>Welcome to Cyber-T</article-title><ext-link ext-link-type="uri" xlink:href="http://visitor.ics.uci.edu/genex/cybert"/></citation></ref><ref id="B32"><citation citation-type="other"><article-title>Downloading and installing Cyber-T / hdarray (R code)</article-title><ext-link ext-link-type="uri" xlink:href="http://visitor.ics.uci.edu/genex/cybert/help/#install"/></citation></ref></ref-list><sec sec-type="display-objects"><title>Figures and Tables</title><fig position="float" id="F1"><label>Figure 1</label><caption><p>Schematic depiction of the experimental protocol.</p></caption><graphic xlink:href="gb-2005-6-2-r16-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p>Signal of individual probes and dependence on present versus absent RNA molecules. <bold>(a, b) </bold>Plot of probe-pair signals for the three C chips, highlighting (a) the empty probe pairs or (b) the present probe pairs in green. <bold>(c) </bold>Receiver-operator characteristic (ROC) curves at the probe-pair level for several absent/present metrics. The metric (PM - MM)/(PM + MM) gives the same result as the green curve. <bold>(d)</bold>Receiver-operator characteristic curves at the probe-set level for several absent/present metrics combined using the Wilcoxon rank sum test.</p></caption><graphic xlink:href="gb-2005-6-2-r16-2"/></fig><fig position="float" id="F3"><label>Figure 3</label><caption><p>The set of options that were investigated using Bioconductor's affy package. The choices that optimize the detection of DEGs are circled in red. Broken circles indicate choices that are slightly suboptimal but still rank within the top 10 datasets.</p></caption><graphic xlink:href="gb-2005-6-2-r16-3"/></fig><fig position="float" id="F4"><label>Figure 4</label><caption><p>The dependence of log fold change on signal intensity (M versus A plots). <bold>(a)</bold>M versus A plot before the second normalization step and <bold>(b) </bold>after a loess fit at the probe set level. FC in the key denotes the spiked-in fold change value.</p></caption><graphic xlink:href="gb-2005-6-2-r16-4"/></fig><fig position="float" id="F5"><label>Figure 5</label><caption><p>Correlation of observed with actual fold changes for a representative expression summary dataset (Additional data file 2, using dataset 9e.b). <bold>(a) </bold>The fold change for each probe set with spiked-in target RNA is depicted as a cross. Empty probe sets are not shown. For each actual fold-change level (on the <italic>x </italic>axis), a boxplot shows the distribution of the corresponding observed fold changes. A linear fit of the data is shown in cyan. Fit parameters: R<sup>2 </sup>= 0.508; slope = 0.505; y-intercept = -0.061. <bold>(b-d) </bold>Increasingly more of the low-intensity probe sets are filtered out of the plot. All probe sets are ranked according to average signal level, and those in the lowest 25th (b), 50th (c), or 75th (d) percentile of signal level are eliminated from (a). Fit parameters: (b) R<sup>2 </sup>= 0.870; slope = 0.546; y-intercept = -0.008; (c) R<sup>2 </sup>= 0.895; slope = 0.517; y-intercept = -0.015; (d) R<sup>2 </sup>= 0.906; slope = 0.457; y-intercept = -0.017.</p></caption><graphic xlink:href="gb-2005-6-2-r16-5"/></fig><fig position="float" id="F6"><label>Figure 6</label><caption><p>Comparison of three <italic>t</italic>-statistic variants. <bold>(a)</bold>ROC curves for a particular expression summary dataset, using the different <italic>t</italic>-statistics. Location of false positives and false negatives are shown for the <bold>(b) </bold>CyberT, <bold>(c) </bold>SAM, and <bold>(d) </bold>basic <italic>t</italic>-statistic when considering the top 1,000 probe sets as positive DEG calls.</p></caption><graphic xlink:href="gb-2005-6-2-r16-6"/></fig><fig position="float" id="F7"><label>Figure 7</label><caption><p>ROC curves for all expression summary datasets. The curves are color-coded to highlight how the ability to detect differential expression is dependent on the different options at each step of analysis, using the CyberT regularized <italic>t</italic>-statistic metric. <bold>(a) </bold>All 152 expression summary datasets are represented here, with the different colors depicting whether the second loess normalization step at the probe set level was performed. In general, the second loess normalization (blue) improves the detection of true DEGs. <bold>(b-f)</bold>To decrease clutter, only the 76 expression summary datasets involving the second normalization step are shown. (b) When comparing the two background correction methods, the MAS algorithm is superior to the RMA algorithm. (c) The various probe-level normalization methods do not show great differences between each other. (d) Among the different PM-correction options, using the method in MAS 5.0 clearly is the most successful. (e) Various robust estimators were examined, revealing that the median polish method is the most sensitive (with MAS 5.0's Tukey Biweight a close second). (f) Depiction (in blue and orange) of the 10 datasets which maximize detection of truly differentially expressed genes, while minimizing false positives. These datasets are generated using the options circled in Figure 3. MAS 5.0, with the inclusion of the second loess normalization step, falls within these top 10.</p></caption><graphic xlink:href="gb-2005-6-2-r16-7"/></fig><fig position="float" id="F8"><label>Figure 8</label><caption><p>The accuracy of false discovery rate estimates (<italic>q</italic>-values). The top 10 expression summary datasets (named 9a-9e, 10a-10e in Additional data file 2) were combined to generate a composite statistic, which was used to rank genes based on the robustness of their significance over the 10 datasets. <bold>(a) </bold>The composite statistic performs as well as the best summary dataset in terms of sensitivity and specificity. <bold>(b) </bold>In addition, permutation tests carried out using this composite statistic yield <italic>q</italic>-value estimates which are more accurate than any of the 10 component datasets, although still lower than the true false-discovery rate.</p></caption><graphic xlink:href="gb-2005-6-2-r16-8"/></fig><fig position="float" id="F9"><label>Figure 9</label><caption><p>DEG detection sensitivity and specificity as a function of spiked-in fold change level. <bold>(a, b)</bold>ROC curves using the composite statistic, and different definitions of the true-positive probe sets (criteria given in the legends; FC, spiked-in fold change). The true negatives remain the same for all curves (the probe sets which were not spiked in, or were spiked in at 1x).</p></caption><graphic xlink:href="gb-2005-6-2-r16-9"/></fig><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>The number of clones and assigned fold change for each pool of PCR products</p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left">Pool number</td><td align="center">Number of clones</td><td align="center">Number of assigned Affymetrix probe sets</td><td align="center">Assigned fold change (S vs C)</td><td align="center">Amount of RNA added to each C chip (&#x003bc;g)</td><td align="center">Amount of RNA added to S chip (&#x003bc;g)</td></tr></thead><tbody><tr><td align="left">1</td><td align="center">87</td><td align="center">84</td><td align="center">1.2</td><td align="center">0.47</td><td align="center">0.56</td></tr><tr><td align="left">2</td><td align="center">141</td><td align="center">143</td><td align="center">2</td><td align="center">0.43</td><td align="center">0.85</td></tr><tr><td align="left">3</td><td align="center">85</td><td align="center">83</td><td align="center">1.5</td><td align="center">0.35</td><td align="center">0.52</td></tr><tr><td align="left">4</td><td align="center">180</td><td align="center">185</td><td align="center">2.5</td><td align="center">0.73</td><td align="center">1.82</td></tr><tr><td align="left">5</td><td align="center">90</td><td align="center">89</td><td align="center">1.2</td><td align="center">0.29</td><td align="center">0.35</td></tr><tr><td align="left">6</td><td align="center">88</td><td align="center">96</td><td align="center">3</td><td align="center">0.65</td><td align="center">1.94</td></tr><tr><td align="left">7</td><td align="center">186</td><td align="center">188</td><td align="center">3.5</td><td align="center">0.76</td><td align="center">2.67</td></tr><tr><td align="left">8</td><td align="center">90</td><td align="center">95</td><td align="center">1.5</td><td align="center">0.44</td><td align="center">0.67</td></tr><tr><td align="left">9</td><td align="center">180</td><td align="center">190</td><td align="center">4</td><td align="center">0.78</td><td align="center">3.11</td></tr><tr><td align="left">10</td><td align="center">183</td><td align="center">191</td><td align="center">1.7</td><td align="center">0.48</td><td align="center">0.81</td></tr><tr><td align="left">13</td><td align="center">391</td><td align="center">385</td><td align="center">1</td><td align="center">0.37</td><td align="center">0.37</td></tr><tr><td align="left">14</td><td align="center">369</td><td align="center">355</td><td align="center">1</td><td align="center">1.23</td><td align="center">1.23</td></tr><tr><td align="left">15</td><td align="center">394</td><td align="center">404</td><td align="center">1</td><td align="center">0.40</td><td align="center">0.40</td></tr><tr><td align="left">16</td><td align="center">452</td><td align="center">453</td><td align="center">1</td><td align="center">0.57</td><td align="center">0.57</td></tr><tr><td align="left">17</td><td align="center">419</td><td align="center">434</td><td align="center">1</td><td align="center">0.44</td><td align="center">0.44</td></tr><tr><td align="left">18</td><td align="center">372</td><td align="center">407</td><td align="center">1</td><td align="center">0.31</td><td align="center">0.31</td></tr><tr><td align="left">19</td><td align="center">163</td><td align="center">191</td><td align="center">1</td><td align="center">0.27</td><td align="center">0.27</td></tr></tbody></table><table-wrap-foot><p>Also depicted is the total amount of cRNA for each pool that was placed on each chip, and the number of Affymetrix probe sets that are assigned to each pool. There were 10,131 probe sets not assigned to any spiked-in clone (called empty). Pools 11 and 12 were not included in this dataset.</p></table-wrap-foot></table-wrap></sec></back></article>



