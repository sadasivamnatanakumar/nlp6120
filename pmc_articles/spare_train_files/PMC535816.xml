<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Neurosci</journal-id><journal-title>BMC Neuroscience</journal-title><issn pub-type="epub">1471-2202</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15548329</article-id><article-id pub-id-type="pmc">PMC535816</article-id><article-id pub-id-type="publisher-id">1471-2202-5-45</article-id><article-id pub-id-type="doi">10.1186/1471-2202-5-45</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Elevated responses to constant facial emotions in different faces in the human amygdala: an fMRI study of facial identity and expression</article-title></title-group><contrib-group><contrib id="A1" equal-contrib="yes" corresp="yes" contrib-type="author"><name><surname>Gl&#x000e4;scher</surname><given-names>Jan</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>glaescher@uke.uni-hamburg.de</email></contrib><contrib id="A2" equal-contrib="yes" contrib-type="author"><name><surname>T&#x000fc;scher</surname><given-names>Oliver</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I2">2</xref><email>tuescher@uke.uni-hamburg.de</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Weiller</surname><given-names>Cornelius</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>weiller@uke.uni-hamburg.de</email></contrib><contrib id="A4" contrib-type="author"><name><surname>B&#x000fc;chel</surname><given-names>Christian</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>buechel@uke.uni-hamburg.de</email></contrib></contrib-group><aff id="I1"><label>1</label>Neuroimage Nord, Department of Neurology, University Hospital Hamburg-Eppendorf, Martinistrasse 52, 20246 Hamburg, Germany</aff><aff id="I2"><label>2</label>Functional Neuroimaging Laboratory, Department of Psychiatry, Weill Medical School of Cornell University, 1300 York Ave, New York, NY, 10021, USA</aff><pub-date pub-type="collection"><year>2004</year></pub-date><pub-date pub-type="epub"><day>17</day><month>11</month><year>2004</year></pub-date><volume>5</volume><fpage>45</fpage><lpage>45</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2202/5/45"/><history><date date-type="received"><day>12</day><month>7</month><year>2004</year></date><date date-type="accepted"><day>17</day><month>11</month><year>2004</year></date></history><copyright-statement>Copyright &#x000a9; 2004 Gl&#x000e4;scher et al; licensee BioMed Central Ltd.</copyright-statement><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p></license><abstract><sec><title>Background</title><p>Human faces provide important signals in social interactions by inferring two main types of information, individual identity and emotional expression. The ability to readily assess both, the variability and consistency among emotional expressions in different individuals, is central to one's own interpretation of the imminent environment. A factorial design was used to systematically test the interaction of either constant or variable emotional expressions with constant or variable facial identities in areas involved in face processing using functional magnetic resonance imaging.</p></sec><sec><title>Results</title><p>Previous studies suggest a predominant role of the amygdala in the assessment of emotional variability. Here we extend this view by showing that this structure activated to faces with changing identities that display constant emotional expressions. Within this condition, amygdala activation was dependent on the type and intensity of displayed emotion, with significant responses to fearful expressions and, to a lesser extent so to neutral and happy expressions. In contrast, the lateral fusiform gyrus showed a binary pattern of increased activation to changing stimulus features while it was also differentially responsive to the intensity of displayed emotion when processing different facial identities.</p></sec><sec><title>Conclusions</title><p>These results suggest that the amygdala might serve to detect constant facial emotions in different individuals, complementing its established role for detecting emotional variability.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Facial expressions and facial identities are important cues for the evaluation of social contexts [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>]. Two main types of information have to be processed while seeing other persons' faces: a face has to be identified as belonging to a unique individual, establishing facial identity, while facial expressions have to be interpreted for emotional context, which is crucial for the social interaction [<xref ref-type="bibr" rid="B3">3</xref>]. Facial expression itself conveys two levels of information: first, facial emotions of others signal information about the emotional state and the benevolence or hostility of that person towards oneself; second, they convey information about the person's evaluation of the environment. The same emotional expression on several other persons' faces often signals a high degree of consistency in their evaluation of the current environment; they are therefore a particularly valid cue for one's own situational appraisal of this environment. In particular, the existence of specialized brain systems for the perception of fear expressions as a form of threat related to physical attack [<xref ref-type="bibr" rid="B4">4</xref>], points to the importance the brain attaches to social signals of potential environmental threats [<xref ref-type="bibr" rid="B5">5</xref>,<xref ref-type="bibr" rid="B6">6</xref>].</p><p>Visual analysis of human faces has been suggested to be achieved by a core system comprising the fusiform gyrus together with the inferior occipital gyrus, the superior temporal sulcus, and the amygdala [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>]. The amygdala in particular has been shown to play a pivotal role in the processing and recognition of emotional facial expression, especially fear [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B10">10</xref>]. Since early functional imaging studies [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>] showed amygdala activation to fearful face stimuli, a variety of imaging studies have led to a more detailed understanding of amygdala function in facial expression. Temporal properties of amygdala responses to stimulus repetition (i.e. habituation, e.g. [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B13">13</xref>-<xref ref-type="bibr" rid="B15">15</xref>]), the influence of attentional state [<xref ref-type="bibr" rid="B16">16</xref>] and awareness (e.g. [<xref ref-type="bibr" rid="B17">17</xref>-<xref ref-type="bibr" rid="B19">19</xref>]), as well as the amygdala's response to different types of emotional expression (most recently e.g. [<xref ref-type="bibr" rid="B20">20</xref>]) have been explored. Despite many studies investigating facial affect, only few have addressed the interaction of facial affect and identity. Preceding experiments on face processing were not explicitly designed to investigate differences in processing of facial identity and facial expressions, rather they examined the effects of changes in appearance, viewing angle, selective features and physical stimulus properties on face processing (e.g. [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B21">21</xref>,<xref ref-type="bibr" rid="B22">22</xref>]).</p><p>Recent advances to assess the effects of facial identity and emotional expression include one report on increased left amygdala activation to blocks of multiple novel vs. single identical faces displaying neutral or emotionless expressions [<xref ref-type="bibr" rid="B23">23</xref>]. Animated emotional expressions or identities, morphing either from neutral to emotional expression or from one neutral face to another, have been shown to elicit stronger activations in bilateral amygdala than static displays of these same stimuli [<xref ref-type="bibr" rid="B24">24</xref>]. Notably, these studies were not designed to investigate the interaction of identity and emotional expression as identity was only varied within the neutral expression condition. Most recently, Winston and colleagues have employed a factorial design to explore fMRI-adaptation to repeated presentations of two facial expressions in the context of an event-related fMRI experiment [<xref ref-type="bibr" rid="B25">25</xref>]. In contrast to earlier findings (e.g. [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>]), the authors did not observe any significant signal changes in the amygdala in the context of their factorial design, suggesting that sparse stimulus presentations interleaved with a checkerboard might not be potent enough to evoke a task-related fMRI activation in this region.</p><p>Variability and constancy of identity and emotional expression are concepts that require stimulus integration over time, thus a sufficient number of stimulus presentations might be critical for a brain region such as the amygdala in order to detect stability or changes in the stimulus sequence. Therefore, we tested this interaction in a 2 &#x000d7; 2 factorial design (see Figure <xref ref-type="fig" rid="F1">1</xref>), with either constant or variable facial identity (factor 1), and either constant or variable emotional expression (factor 2), in a block design fMRI study. The conditions used were: (a) constant identity, constant expression (C<sub>I</sub>C<sub>E</sub>), (b) variable identity, constant expression (V<sub>I</sub>C<sub>E</sub>), (c) constant identity, variable expression (C<sub>I</sub>V<sub>E</sub>), (d) variable identity, variable expression (V<sub>I</sub>V<sub>E</sub>). To control for attentional effects during the procedure, an oddball task was included to avoid confounds by an emotional judgment or a gender differentiation task (the latter being a property of facial identity, [<xref ref-type="bibr" rid="B26">26</xref>]).</p><p>Given that numerous reports demonstrate amygdala activation in the processing of sequential facial expressions [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B27">27</xref>-<xref ref-type="bibr" rid="B29">29</xref>] and given the importance of different facial identities as a valid cue for making social inferences (see above), we hypothesized that constant emotional expressions displayed in different faces would elicit strong responses in the amygdala despite its well-described habituation to repeated stimuli [<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B15">15</xref>,<xref ref-type="bibr" rid="B23">23</xref>]. Furthermore, we expected that constant <italic>fearful </italic>expressions (shown in different identities) would elicit the strongest amygdala activation given the evidence from lesion and imaging studies that this expression is a particularly potent activator of the amygdala [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B17">17</xref>,<xref ref-type="bibr" rid="B30">30</xref>,<xref ref-type="bibr" rid="B31">31</xref>]. Because we expected to find a stimulus repetition effect in the fusiform gyrus [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B32">32</xref>] we systematically examined responses to changing versus constant stimulus features, i.e., facial expression and identity in this area.</p></sec><sec><title>Results</title><p>Analysis of the behavioral data showed that subjects maintained a high degree of task attention (98.03 % hits to oddball stimuli (facial stimuli at reduced luminance)). There was a trend of a main effect of identity in the reaction times (RTs) to the oddball stimuli (F<sub>1,10 </sub>= 4.859, p &#x0003c; 0.06), with longer RTs in the conditions of changing identities, but no significant effects of emotion or an interaction (emotion: F<sub>1,10 </sub>= 0.755, p &#x0003e; 0.40; interaction: F<sub>1,10 </sub>= 1.656, p &#x0003e; 0.20).</p><p>For the analysis of the imaging data we chose a statistical threshold of p &#x0003c; 0.05, corrected for a reduced search volume of interest for regions with a priori hypotheses (amygdala, fusiform gyrus). For other brain areas the threshold was set to a threshold of p &#x0003c; 0.05, corrected for the entire brain. Post-hoc contrasts of specific experimental conditions for detailed characterization of the experimental effects were carried out at an uncorrected significance threshold.</p><p>In the amygdala we expected to find higher responses to constant emotional expressions in different facial identities. Thus in our 2 &#x000d7; 2 factorial design, this can be formally tested by an interaction. Data for all experimental conditions in the peak activation voxels found in our masked interaction contrast (thresholded at p &#x0003c; 0.01, for the purpose of visualization) are shown in the top left and right panels of Figure <xref ref-type="fig" rid="F2">2</xref> with the corresponding significant voxels in the SPMs (arrows in middle panels). Applying a reduced search volume corresponding to an anatomical mask of the amygdala (see Methods) to these activations we found a highly significant peak in the right and another peak approaching significance in the left amygdala. We report the latter peak in light of bilateral amygdala activation in similar tasks shown previously [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B14">14</xref>]. Locations and statistics for this analysis for each peak are displayed in Table <xref ref-type="table" rid="T1">1</xref>.</p><p>Post-hoc contrasts of the experimental conditions revealed that amygdala responses to V<sub>I</sub>C<sub>E </sub>were only significantly more active than responses to C<sub>I</sub>C<sub>E </sub>(left amygdala (-15 0 -15): T = 3.75, p &#x0003c; 10<sup>-4</sup>; right amygdala (18 0 -18): T = 4.76, p &#x0003c; 10<sup>-4</sup>), and also more active than the other two experimental conditions (C<sub>I</sub>V<sub>E </sub>and V<sub>I</sub>V<sub>E</sub>): left amygdala (-15 0 -15): V<sub>I</sub>C<sub>E </sub>vs. C<sub>I</sub>V<sub>E</sub>: T = 1.77, p &#x0003c; 0.05; V<sub>I</sub>C<sub>E </sub>vs. V<sub>I</sub>V<sub>E</sub>: T = 2.40, p &#x0003c; 0.01; right amygdala (18 0 -18): V<sub>I</sub>C<sub>E </sub>vs. C<sub>I</sub>V<sub>E</sub>: T = 2.19, p &#x0003c; 0.01; V<sub>I</sub>C<sub>E </sub>vs. V<sub>I</sub>V<sub>E</sub>: T = 3.30, p &#x0003c; 0.001.</p><p>In a further post-hoc analysis of the response to V<sub>I</sub>C<sub>E </sub>we decomposed this condition with respect to different emotional expressions. This analysis revealed that the V<sub>I</sub>C<sub>E </sub>activation is primarily caused by the response to maximally fearful expressions and (to a lesser degree) to other emotional expressions, but only marginal to neutral expressions (Figure <xref ref-type="fig" rid="F2">2</xref>, bottom graphs). Post-hoc pair-wise comparisons between maximally fearful and the other emotional expressions exceeded statistical thresholding (left amygdala (-15 0 -15): Fear Max vs. Fear Min: T = 1.95, p &#x0003c; 0.05, Fear Max vs. Neutral: T = 2.45, p &#x0003c; 0.01, Fear Max vs. Happy Min: T = 2.53, p &#x0003c; 0.01, Fear Max vs. Happy Max: T = 1.91, p &#x0003c; 0.05; right amygdala (18 0 -18): Fear Max vs. Neutral: T = 1.85, p &#x0003c; 0.05, Fear Max vs. Happy Max: T = 2.17, p &#x0003c; 0.05).</p><p>In order to characterize the time-course of the amygdala responses to the emotion-specific responses in condition V<sub>I</sub>C<sub>E </sub>we calculated the fitted responses for the most intense and the neutral expressions by multiplying the parameter estimates (regression coefficients) for the respective boxcar and exponential decay regressor with the canonical response function created by SPM during design specification. Figure <xref ref-type="fig" rid="F3">3</xref> shows the time course for each emotion-specific response for each peak voxel in both amygdalae. While the overall height of the fitted responses parallel the parameter estimates of the boxcar regressors in Figure <xref ref-type="fig" rid="F3">3</xref>, we found a trend toward within-block habituation to fearful expressions, and an increase in the fitted responses for happy expressions (especially in the right amygdala) while neutral expression maintained the level of activation across the entire block.</p><p>Based on previous work [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B32">32</xref>] we expected activation in the fusiform gyrus to be dependent on stimulus changes irrespective of whether emotional expression, facial identity, or both were varied. We also expected to detect an influence of emotion type and intensity on fusiform activity [<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B22">22</xref>]. Accordingly, we compared conditions with at least one changing stimulus feature (identity, emotion) to the condition in which the same picture was repeated for the entire block. Here we found evidence for an effect of changing stimulus features. Figure <xref ref-type="fig" rid="F4">4</xref> depicts significantly activated voxels in the lateral fusiform gyrus for this contrast (thresholded at p &#x0003c; 0.001 for the purpose of visualization), with arrows pointing to the voxels of peak activation. Location and statistics corrected for a reduced search volume for this region reported by Vuilleumier and colleagues [<xref ref-type="bibr" rid="B33">33</xref>]; see Methods) are shown in Table <xref ref-type="table" rid="T1">1</xref>. These locations correspond well to previously reported regions linked to human face processing [<xref ref-type="bibr" rid="B34">34</xref>].</p><p>Pair-wise post-hoc contrasts of the four experimental conditions revealed that the lateral fusiform gyrus was significantly more activated by all experimental conditions with at least one changing stimulus feature (V<sub>I</sub>C<sub>E</sub>, C<sub>I</sub>V<sub>E</sub>, V<sub>I</sub>V<sub>E</sub>) than by the condition with repeated presentation of the same picture (C<sub>I</sub>C<sub>E</sub>): left lateral fusiform gyrus (-39 -54 -24): V<sub>I</sub>C<sub>E </sub>vs. C<sub>I</sub>C<sub>E</sub>: T = 2.75 p &#x0003c; 0.01, C<sub>I</sub>V<sub>E </sub>vs. C<sub>I</sub>C<sub>E</sub>: T = 3.09, p &#x0003c; 0.01, V<sub>I</sub>V<sub>E </sub>vs. C<sub>I</sub>C<sub>E</sub>: T = 3.77, p &#x0003c; 0.001; right lateral fusiform gyrus (36 -54 -24): V<sub>I</sub>C<sub>E </sub>vs. C<sub>I</sub>C<sub>E</sub>: T = 2.98, p &#x0003c; 0.01, C<sub>I</sub>V<sub>E </sub>vs. C<sub>I</sub>C<sub>E</sub>: T = 2.79, p &#x0003c; 0.01, V<sub>I</sub>V<sub>E </sub>vs. C<sub>I</sub>C<sub>E</sub>: T = 3.01, p &#x0003c; 0.01.</p><p>A further post-hoc analysis of the condition V<sub>I</sub>C<sub>E </sub>revealed an effect of emotion intensity with the maximal intensity expressions eliciting stronger activations than those with reduced intensities and the neutral expression. Pair-wise contrasts of the emotion-specific V<sub>I</sub>C<sub>E </sub>condition revealed that maximally fearful expressions elicited significantly larger activation than neutral and emotional expressions of minimal intensity (left lateral fusiform gyrus (-39 -54 -24): Fear Max vs. Fear Min: T = 2.6, p &#x0003c; 0.01; Fear Max vs. Neutral: T = 2.79, p &#x0003c; 0.001; Fear Max vs. Happy Min: T = 2.38, p &#x0003c; 0.01; right lateral fusiform gyrus (36 -54 -24): Fear Max vs. Fear Min: T = 1.72, p &#x0003c; 0.05; Fear Max vs. Neutral: T = 1.94, p &#x0003c; 0.05; Fear Max vs. Happy Min: T = 2.27, p &#x0003c; 0.01; indicated by asterisks (*) in the bottom panels of Figure <xref ref-type="fig" rid="F4">4</xref>). However, only in the left lateral fusiform gyrus the same post-hoc tests were significant when contrasting maximally happy expressions with all others (Happy Max vs. Happy Min: T = 1.84, p &#x0003c; 0.05; Happy Max vs. Neutral: T = 2.54, p &#x0003c; 0.01; Happy Max vs. Fear Min: T = 1.99, p &#x0003c; 0.05, indicated by pluses (+) in the bottom panels of Figure <xref ref-type="fig" rid="F4">4</xref>).</p></sec><sec><title>Discussion</title><p>We investigated the interaction of facial identity and expression in 2 &#x000d7; 2 factorial blocked fMRI study which uniquely enabled us to compare all combinations of facial identity and expression within the same experiment, therefore the results of the present study complement and extend the results of previous studies on facial identity and expression processing in the human brain. In support for our hypotheses we found distinct response patterns in bilateral amygdala and bilateral lateral fusiform gyrus. While the lateral fusiform gyri can be characterized by a binary response pattern corresponding to an effect of changing stimulus feature, the amygdala responded maximally to constant emotional facial expressions in combination with changing facial identity. In addition, in the V<sub>I</sub>C<sub>E </sub>experimental condition we found an effect of emotion intensity in the fusiform gyrus, with stronger activations to maximally intense expression irrespective of valence when compared with neutral or modestly intense expressions. While we found a (non-significant) trend for the same modulation of the V<sub>I</sub>C<sub>E </sub>activation by emotion intensity in the left amygdala the general pattern when including the right amygdala rather conforms to a specific sensitivity for maximally fearful expression which elicited the strongest activation.</p><sec><title>Fusiform gyrus activations</title><p>The binary response pattern conforming to sensitivity for changes in stimulus features in the lateral fusiform gyrus might be explained by reference to the proposed network of face processing in humans [<xref ref-type="bibr" rid="B7">7</xref>]. Haxby and colleagues hypothesize that this part of the distributed network is especially sensitive to facial stimulus configurations (and the variability of these configurations). Evidence supporting this conclusion has been reported in a study by Vuilleumier and colleagues who demonstrated a significant repetition suppression effect in the fusiform gyrus in response to the second compared to the first presentation of a given facial identity [<xref ref-type="bibr" rid="B22">22</xref>]. Similarly, Rotshtein and colleagues demonstrated stronger activation in face related voxels in the lateral occipital complex (LOC) for blocks with different identities (resembling the condition V<sub>I</sub>C<sub>E </sub>of the present study) compared to blocks of the repetition of the same identity (our condition C<sub>I</sub>C<sub>E</sub>) [<xref ref-type="bibr" rid="B14">14</xref>]. Another study investigating the influence of facial expression and identity on fusiform activation found reduced activation to facial identity but not to expression and no interaction of these two factors [<xref ref-type="bibr" rid="B25">25</xref>]. Our data support and extend these findings with respect to identity in the fusiform gyrus, as we found evidence for an effect of changing stimulus features in the lateral fusiform gyrus irrespective of the dimension of variation (facial identity, emotional expression collapsed over all emotions, or both).</p><p>Additionally, we found an effect of emotion intensity in the fusiform gyrus activity in condition V<sub>I</sub>C<sub>E </sub>with higher activation to maximally fearful and happy expressions relative to with neutral expressions, paralleling earlier findings which report stronger activation to fearful than to neutral expressions [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B27">27</xref>,<xref ref-type="bibr" rid="B33">33</xref>,<xref ref-type="bibr" rid="B35">35</xref>]. Rotshtein and colleagues show significantly larger activation for aversive versus happy expressions in repeated presentations (C<sub>I</sub>C<sub>E</sub>), suggesting an identity repetition &#x000d7; emotion interaction [<xref ref-type="bibr" rid="B14">14</xref>], while others fail to find an effect of negative (or positive) expression in the fusiform gyrus [<xref ref-type="bibr" rid="B25">25</xref>]. This apparent negativity bias might be a confound of stimulus selection as researchers use negative material more frequently than positive stimuli. In fact, the underlying mechanism might be an enhanced attentional processing of arousing facial expressions [<xref ref-type="bibr" rid="B36">36</xref>], which are usually also the most negative faces. Our finding of an effect of emotion intensity supports this notion more convincingly as we also show increased activation in the fusiform gyrus to happy expressions. An underlying arousal dimension that exerts a modulatory effect on the activation in this region might also explain the lack of an effect of expression in the findings of Winston and colleagues [<xref ref-type="bibr" rid="B25">25</xref>], as they did not include a neutral (low arousal) expression in their stimulus set.</p><p>Two recent studies suggest that the low frequency information of facial stimuli might drive the modulatory effect of arousal, which is thought to be a feedback influence of the amygdala, which also displays a preference for low frequency information [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B35">35</xref>].</p></sec><sec><title>Amygdala activations</title><p>Our 2 &#x000d7; 2 factorial blocked fMRI design allowed us to compare between the possible conditions of constant and variable facial identity and expression. We show for the first time a maximum of activation of the amygdala to variable facial identities displaying the same emotion (V<sub>I</sub>C<sub>E</sub>) compared to all three other main conditions (C<sub>I</sub>C<sub>E</sub>, C<sub>I</sub>V<sub>E </sub>and V<sub>I</sub>V<sub>E</sub>). Furthermore, within this condition (V<sub>I</sub>C<sub>E</sub>) maximally fearful expressions elicited the strongest amygdala activity. The result of the present study replicates and extends, in part, the earlier findings that also utilized blocked presentations of facial expression with stimulus configurations resembling one or more of our experimental conditions (V<sub>I</sub>C<sub>E </sub>blocks: [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B28">28</xref>,<xref ref-type="bibr" rid="B37">37</xref>,<xref ref-type="bibr" rid="B38">38</xref>]; C<sub>I</sub>C<sub>E </sub>and V<sub>I</sub>C<sub>E </sub>blocks: [<xref ref-type="bibr" rid="B14">14</xref>]; V<sub>I</sub>C<sub>E </sub>and V<sub>I</sub>V<sub>E </sub>blocks: [<xref ref-type="bibr" rid="B39">39</xref>]). In light of our findings, the significant amygdala activation to fearful expression in the aforementioned studies might have been obtained because they employed a stimulus presentation conforming to our condition V<sub>I</sub>C<sub>E</sub>. Interestingly, in a study comparing dynamically morphed and static presentations of facial stimuli, LaBar and colleagues [<xref ref-type="bibr" rid="B24">24</xref>] also report amygdala activation when neutral faces are morphed into each other (a dynamic version of our condition V<sub>I</sub>C<sub>E</sub>) as compared to static and repeated presentation of the same facial stimuli (the condition C<sub>I</sub>C<sub>E </sub>in the present study). A closer inspection of our findings in Figure <xref ref-type="fig" rid="F2">2</xref> reveals a similar trend, as the neutral expression in the V<sub>I</sub>C<sub>E </sub>condition still elicited a larger signal change than the condition C<sub>I</sub>C<sub>E</sub>. Thus, our comprehensive factorial design can relate these earlier findings in the broader context of constancy and variability of identity and expression.</p><p>Many imaging and lesion studies have documented activations or behavioral impairments following the presentation of fear-related stimuli (for review see [<xref ref-type="bibr" rid="B9">9</xref>]). Our decomposition of the amygdala activation in condition V<sub>I</sub>C<sub>E </sub>supports this claim. However, recent studies, which used different sensory modalities and carefully controlled for the often confounded dimensions of valence and intensity, argued for an effect of emotion intensity (arousal) in the amygdala [<xref ref-type="bibr" rid="B40">40</xref>-<xref ref-type="bibr" rid="B42">42</xref>]. Further support for this interpretation comes from a comprehensive study investigating the effects of different expressions of basic emotions during direct and incidental stimulus processing [<xref ref-type="bibr" rid="B20">20</xref>]. The authors found no specific effect for a particular emotional expression; they rather report amygdala activations when comparing high vs. low intensity exemplars of the facial stimuli. Although we also find trends for an effect of emotion intensity (Figure <xref ref-type="fig" rid="F2">2</xref>, bottom left panel), the question of specific amygdalar fear sensitivity or a more general arousal sensitivity remains equivocal based on our findings.</p><p>Interestingly, Winston and colleagues [<xref ref-type="bibr" rid="B25">25</xref>], employing a similar design as in the present study, failed to observe significant signal changes in the amygdala. The divergent findings might be explained by the difference between our blocked and their event-related design, in which they sequentially presented pairs of facial stimuli. Sparse stimulus presentations in that study might not be sufficient to trigger activation in the amygdala, as this structure might decode a more sustained stimulus train for assessing the biological relevance of the current situation (see below). Furthermore, in their study, the pairs of faces presented were separated by an face-outlined checkerboard [<xref ref-type="bibr" rid="B25">25</xref>] which might have prevented the induction of an emotional state that would be encoded by the amygdala.</p><p>The temporal properties of amygdala responses to facial expressions are crucial. Many studies show habituation of the amygdala response to blocks of directly adjacent fearful vs. neutral or happy expressions with constant identities over the course of 30 to 80 sec [<xref ref-type="bibr" rid="B13">13</xref>,<xref ref-type="bibr" rid="B15">15</xref>,<xref ref-type="bibr" rid="B38">38</xref>]. This is comparable to the C<sub>I</sub>C<sub>E </sub>condition in the present study in terms of presented stimuli but not with respect to block length and block order. Interestingly, when the C<sub>I</sub>C<sub>E </sub>condition in the present study is analyzed for the comparison of maximum fear vs. neutral blocks a non-significant trend for left ventro-lateral amygdala activity (data not shown) is seen, indirectly supporting those findings.</p><p>Other studies used fearful and neutral V<sub>I</sub>C<sub>E </sub>conditions showing within-block and across-block habituation with fixed alternating block order [<xref ref-type="bibr" rid="B11">11</xref>] or in the comparison of V<sub>I</sub>C<sub>E </sub>vs. C<sub>I</sub>C<sub>E </sub>blocks [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B23">23</xref>] in designs with pseudo-randomized block order. Likewise, we also show a highly significant difference between the V<sub>I</sub>C<sub>E </sub>and C<sub>I</sub>C<sub>E </sub>conditions in the amygdala. The response profile of the amygdala for maximal fearful expressions in the V<sub>I</sub>C<sub>E </sub>condition trends toward a within-block habituation effect (Figure <xref ref-type="fig" rid="F3">3</xref>). In contrast, the response profile for neutral expressions exhibits a sustained response during the entire block albeit at a much lower overall level. This aspect parallels findings by Breiter and colleagues [<xref ref-type="bibr" rid="B11">11</xref>], although direct comparison is limited because that study showed habituation on a larger timescale (between blocks). The within-block increase of amygdala activation to happy expressions, however, suggests that the temporal nature of signal changes in the amygdala might be more complex. This delayed onset of activation to happy faces is in accordance with an evolutionary interpretation of our findings. The amygdala is located in a critical position on the efferent pathway that is involved in the preparation of autonomic responses to threatening situations [<xref ref-type="bibr" rid="B43">43</xref>]. Because happy expressions are usually a valid signal for non-threatening situations that do not require fight or flight responses, amygdala activation is not needed at an early stage. The explanation also holds for the early but overall attenuated response to neutral expressions that are inherently ambiguous, which thus prompt for sustained perceptual processing and, potentially, for preparation of defensive behavior [<xref ref-type="bibr" rid="B44">44</xref>]. Additionally, Wright and colleagues [<xref ref-type="bibr" rid="B23">23</xref>] showed greater amygdala activation to neutral V<sub>I</sub>C<sub>E </sub>blocks compared with neutral C<sub>I</sub>C<sub>E </sub>blocks. Clearly, further research is needed to characterize the temporal evolution of amygdala activation during this type of blocked stimulus presentation in more detail.</p><p>One might argue that the responses in the conditions with variable emotional expression (C<sub>I</sub>V<sub>E</sub>, V<sub>I</sub>V<sub>E</sub>) were reduced because within those blocks variable emotional and neutral expressions were intermixed, possibly leading to smaller signal changes within those blocks. However, subjects were presented with the same number of stimuli of each emotional expression in every experimental condition. Therefore, differences cannot be attributed to a varying number of emotional expressions seen in different conditions. Thus, if the conditions with variable emotions elicit a smaller signal change because of the neutral faces within them, this effect should also apply to the blocks of constant neutral expressions in different faces (V<sub>I</sub>C<sub>E </sub>condition). This effect is in fact shown in the lower bar graphs in Figure <xref ref-type="fig" rid="F2">2</xref>, especially in comparison to the other emotional V<sub>I</sub>C<sub>E </sub>conditions. Because we found an overall elevated response in the amygdala to the condition with constant emotions in changing identities (V<sub>I</sub>C<sub>E</sub>) compared to conditions with variable emotions (C<sub>I</sub>V<sub>E</sub>, V<sub>I</sub>V<sub>E</sub>; see Figure <xref ref-type="fig" rid="F2">2</xref> upper bar graphs), we argue that the observed differences between our experimental conditions represent a true effect of the sequential stimulus configuration within this experimental design. Although we can not ultimately exclude the possibility of confounding order effects within the categories of variable emotion conditions (C<sub>I</sub>V<sub>E</sub>, V<sub>I</sub>V<sub>E</sub>), this does not diminish the main point of this study, namely that the human amygdala is most responsive to the sequential presentation of faces with constant emotion (fearful) and varying identity. To further confirm and generalize this finding future studies are needed using additional emotions (e.g. anger, sadness, etc.).</p><p>Novelty effects of changing facial identity and stimulus order of the different conditions might also be claimed as an explanation for the strong responses to the condition V<sub>I</sub>C<sub>E </sub>[<xref ref-type="bibr" rid="B23">23</xref>]. But in contrast to the latter study, subjects in our study were familiarized with the stimuli before the experiment and the same facial identities were presented repeatedly throughout the experiment, thus minimizing stimulus novelty. Furthermore, if novelty detection were the main factor driving the amygdala response, the condition V<sub>I</sub>V<sub>E </sub>should have also elicited a strong amygdala response which it did not (see Figure <xref ref-type="fig" rid="F2">2</xref>). There was also no systematic sequence of blocks of constant facial identities followed by variable facial identities in the present study which has been shown to relatively increase the activation to the multiple identity condition presented secondly [<xref ref-type="bibr" rid="B23">23</xref>].</p><p>It is interesting to note that the peak activation within the amygdala is located in the medio-dorsal part of this structure. Previous imaging studies of the processing of facial affect have predominantly reported their activations in the dorsal amygdala (for review see [<xref ref-type="bibr" rid="B10">10</xref>], Figure <xref ref-type="fig" rid="F3">3</xref>). The dorsal amygdala has also been associated with the representation of ambiguous stimuli, such as fearful expressions that do not signal a potential threat directly [<xref ref-type="bibr" rid="B10">10</xref>,<xref ref-type="bibr" rid="B29">29</xref>,<xref ref-type="bibr" rid="B44">44</xref>]. However, given the resolution and post scan smoothing of the functional images in this and other functional imaging studies, the localization of amygdala activity should be discussed with caution.</p></sec><sec><title>The potential biological relevance of constant facial emotion</title><p>Sensitivity for constant facial emotions in different identities can be seen as a process that integrates stimuli with respect to the conveyed emotion over a certain amount of time. Thus, environmental stimuli (such as facial expressions) are compared to each other to detect changes to stability in the emotion, a concept that can be described as <italic>emotion constancy</italic>. In this context, constant facial emotions in different individuals signal a high degree of consistency in others' appraisals of the environment, and constitute a more valid cue for one's own appraisal.</p><p>Furthermore, facial expressions differ in their degree of saliency which often reflects the biological relevance of the stimulus that evoked the expression [<xref ref-type="bibr" rid="B18">18</xref>,<xref ref-type="bibr" rid="B44">44</xref>]. For example, a fearful face as a reaction to a threatening stimulus is more salient and calls more immediately for appropriate action than a neutral facial expression. We found elevated response in the amygdala especially to these salient (fearful) expressions because these constant salient facial emotions call for an immediate situational appraisal and subsequent action.</p><p>Our findings gain support and extend the findings of earlier imaging studies on the processing of human facial emotions which employed an experimental design similar to our condition V<sub>I</sub>C<sub>E </sub>and found significant activation in the left dorsal amygdala with constant fearful expressions [<xref ref-type="bibr" rid="B11">11</xref>,<xref ref-type="bibr" rid="B12">12</xref>]. Taken together, these results, as well as our own findings in this experiment, suggest that the same emotional expressions displayed in many different faces are potent stimuli that activate the amygdala and might serve the detection of emotion constancy. Conceptually, conditions with variable emotionality (C<sub>I</sub>V<sub>E</sub>, V<sub>I</sub>V<sub>E</sub>) can be seen as noise in the context of the detection of constant emotions among others and thus, it is not surprising that the amygdala shows less signal change in these conditions.</p><p>The perception of emotional facial expressions in others yields insights into their evaluations of the environment and guides one's own emotional and behavioral reactions. Encountering the same emotional expression in many different people (emotion constancy) is an especially valid and readily available cue for making subsequent inferences about the potential harmfulness of an environmental situation. These inferences would have direct implications for evolutionary survival and must have been a central feature of human ancestral cognitive abilities [<xref ref-type="bibr" rid="B45">45</xref>]. They also remain essential for safe locomotion in our current complex environment as they reduce the time spent in a potentially threatening situation, because the perceiving subject can avoid energy-intensive and time-consuming search for potential threats in the environment [<xref ref-type="bibr" rid="B46">46</xref>]. For example, encountering the same fearful expression in several different people (emotion constancy) strongly implies an activation of the fear system [<xref ref-type="bibr" rid="B45">45</xref>,<xref ref-type="bibr" rid="B47">47</xref>] and that precaution and avoidance behavior are adequate reactions in this situation. Our data, in particular the large response to constant maximally fearful expressions in different individuals, suggest that the amygdala plays a central role in the neurobiological realization of this environmental evaluation.</p></sec></sec><sec><title>Conclusions</title><p>Emotional facial expressions are an important cue for the appraisal of an environmental situation. Our study has demonstrated a new perspective on the functional characterization of the amygdala involved in the perceptual processing of human faces by incorporating the dimensions of constancy and variability detection in these stimuli. These are essential for the assessment of the temporal dynamics of social situations.</p></sec><sec sec-type="methods"><title>Methods</title><sec><title>Experimental design</title><p>A 2 &#x000d7; 2 factorial design (identity &#x000d7; emotional expression) across 4 different block types was used: (a) constant identity, constant expression (C<sub>I</sub>C<sub>E</sub>), (b) variable identity, constant expression (V<sub>I</sub>C<sub>E</sub>), (c) constant identity, variable expression (C<sub>I</sub>V<sub>E</sub>), (d) variable identity, variable expression (V<sub>I</sub>V<sub>E</sub>). Figure <xref ref-type="fig" rid="F1">1</xref> schematically displays our experimental design showing three consecutive stimuli from one block within each cell of the factor table.</p></sec><sec><title>Subjects</title><p>13 Subjects (8 females, 10 right-handed) participated in this fMRI study. The mean age was 25.6 (SD 7.8). The data sets of two subjects were excluded from further image analysis because of radio frequency artifacts caused by the scanner leaving a total of 11. All subjects were fully informed about the experimental procedure and signed a consent statement which was approved by the local ethics committee.</p></sec><sec sec-type="methods"><title>Experimental procedure</title><p>The procedure was completed in one imaging session with 4 runs each containing 20 blocks of stimulus presentation. Within one run the blocks were interleaved with 15 s of central fixation (rest period). Each run started with a rest period of 20 s. 20 stimuli were presented per block at a rate of 1 Hz. Stimuli were shown for 900 ms interposed with a 100 ms gray blank of mean luminance to make transitions between stimuli less abrupt. Numbers and types of both facial expressions and facial identities were counterbalanced across the entire experiment. Conditions varied only in terms of the sequential configuration of the stimuli within the blocks. Stimulus order within each block was pseudo-randomized and fixed. The sequence of blocks within each run was counterbalanced, pseudo-randomized and fixed to minimize stimulus order effects. Additionally, the sequence of the four runs was pseudo-randomized across subjects assuring different orders of runs in each subject.</p><p>Stimuli consisted of 4 different faces (facial identities) drawn from the Ekman series of facial affect [<xref ref-type="bibr" rid="B48">48</xref>] with 5 different emotional expressions ranging from fearful to happy expressions, including neutral. Two intermediate expressions displayed fearful and happy emotions at reduced (50 %) intensities. Those face pictures were interpolations using computer morphing procedures [<xref ref-type="bibr" rid="B49">49</xref>] similar to those in other studies. Subjects were instructed to fixate on a small red fixation dot presented in the middle of the viewing monitor while simultaneously attending to the entire stimulus presentation.</p><p>In order to maintain and control for attentional effects during the procedure we included an oddball task as we were seeking to avoid confounds by an emotional judgment or a gender differentiation task (latter being a property of facial identity, [<xref ref-type="bibr" rid="B26">26</xref>]). As oddball stimulus we occasionally presented the facial stimuli with reduced luminance of the entire face while leaving the stimulus visible which was not expected to affect activation in high-order visual areas [<xref ref-type="bibr" rid="B50">50</xref>]. We chose to manipulate the entire facial stimulus for the oddball task in order to keep the subjects attention on the entire stimulus rather than on some small feature. Subjects were instructed to respond with a button press whenever an oddball target appeared. The number of oddball targets per block ranged from 2 to 4 to avoid subjects' expectancy effects. In order to prevent a systematic effect of the number of oddballs in the data analysis, the number of oddball stimuli was counterbalanced across blocks and conditions. Subjects were familiarized with the oddball task in a practice session prior to the first scanning run.</p></sec><sec><title>Image acquisition</title><p>Imaging was performed on a 1.5 T Magnetom Vision (Siemens, Erlangen, Germany) scanner. 43 transversal slices of echo-planar (EPI) T2* weighted images in each volume with a slice thickness of 2 mm and 1 mm gap (TR = 3.5 s, TE = 40 ms, flip angle 90&#x000b0;, FoV 192 &#x000d7; 192 mm<sup>2</sup>, matrix 64 &#x000d7; 64) were acquired. A total of 204 volumes were collected per run.</p></sec><sec><title>Image processing</title><p>Image processing and statistical analysis were carried out using SPM99 for the single subject analysis and SPM2 for the group analysis [<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/"/>] All volumes were realigned to the first volume, spatially normalized to a standard EPI template [<xref ref-type="bibr" rid="B51">51</xref>] using sinc interpolation and finally smoothed with a 11 mm isotropic full width at half maximum (FWHM) Gaussian filter to account for anatomical differences between subjects and to allow statistical inference using Gaussian Random Field theory.</p></sec><sec><title>Statistical analysis</title><p>The data of 11 subjects were included in the statistical analysis. Data analysis was performed using the mass univariate general linear model as implemented in SPM99 and commenced by specifying the design matrix for each subject using a boxcar and an exponential decay regressor for modeling the hemodynamic response to each experimental condition. The boxcar regressor models the mean activation within the block while the exponential decay regressor (time constant 4 s) models decreases and increases (through negative contrast weights) within the block. The conditions with constant emotional expressions (C<sub>I</sub>C<sub>E</sub>, V<sub>I</sub>C<sub>E</sub>) allowed a decomposition into emotion-specific components. Thus each of these two conditions involved 10 regressors (boxcar and exponential decay for 5 different expression), while each of the other conditions (C<sub>I</sub>V<sub>E</sub>, V<sub>I</sub>V<sub>E</sub>) were specified with two regressors. Data were high-pass filtered at 1/120 Hz. Serial autocorrelation was controlled by superimposing a known autocorrelation in form of temporal smoothing using a low-pass filter at 4 sec filter width. Successively, contrasts for each experimental condition were computed by averaging the same block type across runs and multiplying the design matrix with the contrast vectors.</p><p>These single-subject contrast images were then taken to the second level oneway ANOVA [<xref ref-type="bibr" rid="B52">52</xref>,<xref ref-type="bibr" rid="B53">53</xref>] in SPM2 allowing for an appropriate non-sphericity correction [<xref ref-type="bibr" rid="B54">54</xref>]. This correction is equivalent to the Greenhouse-Geisser procedure in multivariate ANOVA analyses and allows for correct assessment of the error covariance matrix, hence securing valid inference in the group comparisons.</p><p>In order to detect voxels that show elevated responses to the same expression displayed in different individuals we constructed the interaction contrast of our 2 &#x000d7; 2 design. Hence, we created the contrast [(V<sub>I</sub>C<sub>E </sub>&#x0003e; C<sub>I</sub>C<sub>E</sub>) &#x0003e; (V<sub>I</sub>V<sub>E </sub>&#x0003e; C<sub>I</sub>V<sub>E</sub>), p &#x0003c; .01 for the purpose of visualization] for the amygdala and masked it with the contrast [(V<sub>I</sub>C<sub>E </sub>&#x0003e; C<sub>I</sub>V<sub>E</sub>), p &#x0003c; .05] to exclude regions showing higher activations to C<sub>I</sub>V<sub>E </sub>than to V<sub>I</sub>C<sub>E</sub>. For our hypothesis in the fusiform gyrus we used a contrast that compared conditions with at least one changing stimulus feature (facial identity, emotional expression, or both) with the condition in which the same stimulus was shown for the entire block [(V<sub>I</sub>C<sub>E </sub>+ C<sub>I</sub>V<sub>E</sub>+ V<sub>I</sub>V<sub>E</sub>) &#x0003e; 3 &#x000d7; C<sub>I</sub>C<sub>E</sub>].</p><p>T-statistics for the assessment of significant regional activation were assembled into Statistical Parametric Maps (SPMs) which refer to the probabilistic behavior of Gaussian random fields [<xref ref-type="bibr" rid="B55">55</xref>]. Our threshold was set at p &#x0003c; .05 (corrected). Because we had region-specific hypotheses for the amygdala and the lateral fusiform gyrus, we applied a reduced search volume to our amygdala activation which was derived by an anatomical mask created with MRIcro [<xref ref-type="bibr" rid="B56">56</xref>] on the template brain of the Montreal Neurological Institute (MNI, [<xref ref-type="bibr" rid="B57">57</xref>]). With additional visual reference to a high-resolution anatomical atlas [<xref ref-type="bibr" rid="B58">58</xref>] we outlined the amygdala on each slice of the MNI template brain. Thus, the amygdala search volume comprised 77 voxels, or 2071 mm<sup>3 </sup>on the right side and 74 voxels, or 2005 mm<sup>3 </sup>on the left side. Similarly, we applied a 10 mm radius sphere to our activation peaks in the lateral fusiform gyrus centered on coordinates reported by Vuilleumier and colleagues when contrasting faces vs. houses in a functional localizer task [<xref ref-type="bibr" rid="B33">33</xref>]; see Table <xref ref-type="table" rid="T1">1</xref>). For additional brain areas not included in our volumes of interest we corrected for the entire brain volume.</p><p>For the emotion-specific analyses of condition V<sub>I</sub>C<sub>E </sub>(Figure <xref ref-type="fig" rid="F2">2</xref> and <xref ref-type="fig" rid="F4">4</xref>, bottom panels) we referred to specific contrasts for each emotional expression created at the single-subject level. These contrast images were raised to another second level one-way ANOVA to test, for example, for significant activations to maximally fearful faces within this condition. These statistical comparisons were carried out at an uncorrected significance threshold.</p></sec></sec><sec><title>List of abbreviations</title><p>EPI: echo-planar imaging</p><p>fMRI: functional magnetic resonance imaging</p><p>LOC: lateral occipital complex</p><p>RT: reaction time</p><p>SPM: statistical parametric map</p><p>V<sub>I</sub>V<sub>E</sub>: variable identity, variable emotion</p><p>V<sub>I</sub>C<sub>E</sub>: variable identity, constant emotion</p><p>C<sub>I</sub>C<sub>E</sub>: constant identity, constant emotion</p><p>C<sub>I</sub>V<sub>E</sub>: constant identity. variable emotion</p><p>Fear/Happy Max: maximally fearful/happy expression</p><p>Fear/Happy Min: minimal fearful/happy expression.</p></sec><sec><title>Authors' contributions</title><p>J.G. and O.T. designed, coordinated, and conducted data collection, analysis, and interpretation. C.B. and C.W. conceived of the study and participated in its design, analysis and interpretation. All authors read and approved the final manuscript.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>This research was supported by grants from the BMBF and the Volkswagenstiftung to C. B., and a doctoral fellowship by the Studienstiftung des Deutschen Volkes to J. G. We thank Dr. James Root for helpful comments on the manuscript.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>Social cognition and the human brain</article-title><source>Trends Cogn Sci</source><year>1999</year><volume>3</volume><fpage>469</fpage><lpage>479</lpage><pub-id pub-id-type="pmid">10562726</pub-id><pub-id pub-id-type="doi">10.1016/S1364-6613(99)01399-6</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>The neurobiology of social cognition</article-title><source>Curr Opin Neurobiol</source><year>2001</year><volume>11</volume><fpage>231</fpage><lpage>239</lpage><pub-id pub-id-type="pmid">11301245</pub-id><pub-id pub-id-type="doi">10.1016/S0959-4388(00)00202-6</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Posamentier</surname><given-names>MT</given-names></name><name><surname>Abdi</surname><given-names>H</given-names></name></person-group><article-title>Processing faces and facial expressions</article-title><source>Neuropsychol Rev</source><year>2003</year><volume>13</volume><fpage>113</fpage><lpage>143</lpage><pub-id pub-id-type="pmid">14584908</pub-id><pub-id pub-id-type="doi">10.1023/A:1025519712569</pub-id></citation></ref><ref id="B4"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>JA</given-names></name></person-group><article-title>The psychology of fear and stress</article-title><source>Problems in the Behavioral Sciences Series</source><year>1987</year><volume>5</volume><publisher-name>Cambridge, Cambridge University Press</publisher-name><fpage>432</fpage></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>AK</given-names></name><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Panitz</surname><given-names>D</given-names></name><name><surname>De Rosa</surname><given-names>E</given-names></name><name><surname>Gabrieli</surname><given-names>JD</given-names></name></person-group><article-title>Neural correlates of the automatic processing of threat facial signals</article-title><source>J Neurosci</source><year>2003</year><volume>23</volume><fpage>5627</fpage><lpage>5633</lpage><pub-id pub-id-type="pmid">12843265</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hadjikhani</surname><given-names>N</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><article-title>Seeing fearful body expressions activates the fusiform cortex and amygdala</article-title><source>Curr Biol</source><year>2003</year><volume>13</volume><fpage>2201</fpage><lpage>2205</lpage><pub-id pub-id-type="pmid">14680638</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2003.11.049</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Hoffman</surname><given-names>EA</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name></person-group><article-title>The distributed human neural system for face perception</article-title><source>Trends Cogn Sci</source><year>2000</year><volume>4</volume><fpage>223</fpage><lpage>233</lpage><pub-id pub-id-type="pmid">10827445</pub-id><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01482-0</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Perrett</surname><given-names>DI</given-names></name><name><surname>Oram</surname><given-names>MW</given-names></name><name><surname>Ashbridge</surname><given-names>E</given-names></name></person-group><article-title>Evidence accumulation in cell populations responsive to faces: an account of generalisation of recognition without mental transformations</article-title><source>Cognition</source><year>1998</year><volume>67</volume><fpage>111</fpage><lpage>145</lpage><pub-id pub-id-type="pmid">9735538</pub-id><pub-id pub-id-type="doi">10.1016/S0010-0277(98)00015-8</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>Recognizing Emotion From Facial Expressions: Psychological and Neurological Mechanisms</article-title><source>Behavioral and Cognitive Neuroscience Reviews</source><year>2002</year><volume>1</volume><fpage>21</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1177/1534582302001001003</pub-id></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Lawrence</surname><given-names>AD</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name></person-group><article-title>Neuropsychology of fear and loathing</article-title><source>Nat Rev Neurosci</source><year>2001</year><volume>2</volume><fpage>352</fpage><lpage>363</lpage><pub-id pub-id-type="pmid">11331919</pub-id><pub-id pub-id-type="doi">10.1038/35072584</pub-id></citation></ref><ref id="B11"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Breiter</surname><given-names>HC</given-names></name><name><surname>Etcoff</surname><given-names>NL</given-names></name><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>Kennedy</surname><given-names>WA</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Strauss</surname><given-names>MM</given-names></name><name><surname>Hyman</surname><given-names>SE</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name></person-group><article-title>Response and habituation of the human amygdala during visual processing of facial expression</article-title><source>Neuron</source><year>1996</year><volume>17</volume><fpage>875</fpage><lpage>887</lpage><pub-id pub-id-type="pmid">8938120</pub-id><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80219-6</pub-id></citation></ref><ref id="B12"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name><name><surname>Perrett</surname><given-names>DI</given-names></name><name><surname>Rowland</surname><given-names>D</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>A differential neural response in the human amygdala to fearful and happy facial expressions</article-title><source>Nature</source><year>1996</year><volume>383</volume><fpage>812</fpage><lpage>815</lpage><pub-id pub-id-type="pmid">8893004</pub-id><pub-id pub-id-type="doi">10.1038/383812a0</pub-id></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>H</given-names></name><name><surname>Wright</surname><given-names>CI</given-names></name><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>McInerney</surname><given-names>SC</given-names></name><name><surname>Shin</surname><given-names>LM</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name></person-group><article-title>Brain habituation during repeated exposure to fearful and neutral faces: a functional MRI study</article-title><source>Brain Res Bull</source><year>2003</year><volume>59</volume><fpage>387</fpage><lpage>392</lpage><pub-id pub-id-type="pmid">12507690</pub-id><pub-id pub-id-type="doi">10.1016/S0361-9230(02)00940-1</pub-id></citation></ref><ref id="B14"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rotshtein</surname><given-names>P</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name><name><surname>Hadar</surname><given-names>U</given-names></name><name><surname>Graif</surname><given-names>M</given-names></name><name><surname>Hendler</surname><given-names>T</given-names></name></person-group><article-title>Feeling or features: different sensitivity to emotion in high-order visual cortex and amygdala</article-title><source>Neuron</source><year>2001</year><volume>32</volume><fpage>747</fpage><lpage>757</lpage><pub-id pub-id-type="pmid">11719213</pub-id><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00513-X</pub-id></citation></ref><ref id="B15"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>CI</given-names></name><name><surname>Fischer</surname><given-names>H</given-names></name><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>McInerney</surname><given-names>SC</given-names></name><name><surname>Shin</surname><given-names>LM</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name></person-group><article-title>Differential prefrontal cortex and amygdala habituation to repeatedly presented emotional stimuli</article-title><source>Neuroreport</source><year>2001</year><volume>12</volume><fpage>379</fpage><lpage>383</lpage><pub-id pub-id-type="pmid">11209954</pub-id><pub-id pub-id-type="doi">10.1097/00001756-200102120-00039</pub-id></citation></ref><ref id="B16"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pessoa</surname><given-names>L</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><article-title>Neuroimaging studies of attention and the processing of emotion-laden stimuli</article-title><source>Prog Brain Res</source><year>2004</year><volume>144</volume><fpage>171</fpage><lpage>182</lpage><pub-id pub-id-type="pmid">14650848</pub-id></citation></ref><ref id="B17"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>Ohman</surname><given-names>A</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Conscious and unconscious emotional learning in the human amygdala</article-title><source>Nature</source><year>1998</year><volume>393</volume><fpage>467</fpage><lpage>470</lpage><pub-id pub-id-type="pmid">9624001</pub-id><pub-id pub-id-type="doi">10.1038/30976</pub-id></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Whalen</surname><given-names>PJ</given-names></name></person-group><article-title>Fear, vigilance, and ambiguity: Initial neuroimaging studies of the human amygdala</article-title><source>Curr Dir Psychol Sci</source><year>1998</year><volume>7</volume><fpage>177</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1111/1467-8721.ep10836912</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>ML</given-names></name><name><surname>Williams</surname><given-names>LM</given-names></name><name><surname>Heining</surname><given-names>M</given-names></name><name><surname>Herba</surname><given-names>CM</given-names></name><name><surname>Russell</surname><given-names>T</given-names></name><name><surname>Andrew</surname><given-names>C</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Brammer</surname><given-names>MJ</given-names></name><name><surname>Williams</surname><given-names>SC</given-names></name><name><surname>Morgan</surname><given-names>M</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Gray</surname><given-names>JA</given-names></name></person-group><article-title>Differential neural responses to overt and covert presentations of facial expressions of fear and disgust</article-title><source>Neuroimage</source><year>2004</year><volume>21</volume><fpage>1484</fpage><lpage>1496</lpage><pub-id pub-id-type="pmid">15050573</pub-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2003.12.013</pub-id></citation></ref><ref id="B20"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Winston</surname><given-names>JS</given-names></name><name><surname>O'Doherty</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Common and distinct neural responses during direct and incidental processing of multiple facial emotions</article-title><source>Neuroimage</source><year>2003</year><volume>20</volume><fpage>84</fpage><lpage>97</lpage><pub-id pub-id-type="pmid">14527572</pub-id><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00303-3</pub-id></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>deBonis</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Human amygdala responses to fearful eyes</article-title><source>Neuroimage</source><year>2002</year><volume>17</volume><fpage>214</fpage><lpage>222</lpage><pub-id pub-id-type="pmid">12482078</pub-id><pub-id pub-id-type="doi">10.1006/nimg.2002.1220</pub-id></citation></ref><ref id="B22"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Armony</surname><given-names>JL</given-names></name><name><surname>Driver</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Distinct spatial frequency sensitivities for processing faces and emotional expressions</article-title><source>Nat Neurosci</source><year>2003</year><volume>6</volume><fpage>624</fpage><lpage>631</lpage><pub-id pub-id-type="pmid">12740580</pub-id><pub-id pub-id-type="doi">10.1038/nn1057</pub-id></citation></ref><ref id="B23"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname><given-names>CI</given-names></name><name><surname>Martis</surname><given-names>B</given-names></name><name><surname>Schwartz</surname><given-names>CE</given-names></name><name><surname>Shin</surname><given-names>LM</given-names></name><name><surname>Fischer</surname><given-names>HH</given-names></name><name><surname>McMullin</surname><given-names>K</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name></person-group><article-title>Novelty responses and differential effects of order in the amygdala, substantia innominata, and inferior temporal cortex</article-title><source>Neuroimage</source><year>2003</year><volume>18</volume><fpage>660</fpage><lpage>669</lpage><pub-id pub-id-type="pmid">12667843</pub-id><pub-id pub-id-type="doi">10.1016/S1053-8119(02)00037-X</pub-id></citation></ref><ref id="B24"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>LaBar</surname><given-names>KS</given-names></name><name><surname>Crupain</surname><given-names>MJ</given-names></name><name><surname>Voyvodic</surname><given-names>JT</given-names></name><name><surname>McCarthy</surname><given-names>G</given-names></name></person-group><article-title>Dynamic perception of facial affect and identity in the human brain</article-title><source>Cereb Cortex</source><year>2003</year><volume>13</volume><fpage>1023</fpage><lpage>1033</lpage><pub-id pub-id-type="pmid">12967919</pub-id><pub-id pub-id-type="doi">10.1093/cercor/13.10.1023</pub-id></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Winston</surname><given-names>JS</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><name><surname>Fine-Goulden</surname><given-names>MR</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>fMRI-Adaptation Reveals Dissociable Neural Representations of Identity and Expression in Face Perception</article-title><source>J Neurophysiol</source><year>2004</year><volume>92</volume><fpage>1830</fpage><lpage>1839</lpage><pub-id pub-id-type="pmid">15115795</pub-id><pub-id pub-id-type="doi">10.1152/jn.00155.2004</pub-id></citation></ref><ref id="B26"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ganel</surname><given-names>T</given-names></name><name><surname>Goshen-Gottstein</surname><given-names>Y</given-names></name></person-group><article-title>Perceptual integrality of sex and identity of faces: further evidence for the single-route hypothesis</article-title><source>J Exp Psychol Hum Percept Perform</source><year>2002</year><volume>28</volume><fpage>854</fpage><lpage>867</lpage><pub-id pub-id-type="pmid">12190254</pub-id><pub-id pub-id-type="doi">10.1037//0096-1523.28.4.854</pub-id></citation></ref><ref id="B27"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>JS</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Buchel</surname><given-names>C</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>A neuromodulatory role for the human amygdala in processing emotional facial expressions</article-title><source>Brain</source><year>1998</year><volume>121</volume><fpage>47</fpage><lpage>57</lpage><pub-id pub-id-type="pmid">9549487</pub-id><pub-id pub-id-type="doi">10.1093/brain/121.1.47</pub-id></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>ML</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Scott</surname><given-names>SK</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Andrew</surname><given-names>C</given-names></name><name><surname>Giampietro</surname><given-names>V</given-names></name><name><surname>Williams</surname><given-names>SC</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Brammer</surname><given-names>M</given-names></name><name><surname>Gray</surname><given-names>JA</given-names></name></person-group><article-title>Neural responses to facial and vocal expressions of fear and disgust</article-title><source>Proc R Soc Lond B Biol Sci</source><year>1998</year><volume>265</volume><fpage>1809</fpage><lpage>1817</lpage><pub-id pub-id-type="pmid">9802236</pub-id><pub-id pub-id-type="doi">10.1098/rspb.1998.0506</pub-id></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Whalen</surname><given-names>PJ</given-names></name><name><surname>Shin</surname><given-names>LM</given-names></name><name><surname>McInerney</surname><given-names>SC</given-names></name><name><surname>Fischer</surname><given-names>H</given-names></name><name><surname>Wright</surname><given-names>CI</given-names></name><name><surname>Rauch</surname><given-names>SL</given-names></name></person-group><article-title>A functional MRI study of human amygdala responses to facial expressions of fear versus anger</article-title><source>Emotion</source><year>2001</year><volume>1</volume><fpage>70</fpage><lpage>83</lpage><pub-id pub-id-type="pmid">12894812</pub-id><pub-id pub-id-type="doi">10.1037//1528-3542.1.1.70</pub-id></citation></ref><ref id="B30"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Damasio</surname><given-names>H</given-names></name><name><surname>Damasio</surname><given-names>A</given-names></name></person-group><article-title>Impaired recognition of emotion in facial expressions following bilateral damage to the human amygdala</article-title><source>Nature</source><year>1994</year><volume>372</volume><fpage>669</fpage><lpage>672</lpage><pub-id pub-id-type="pmid">7990957</pub-id><pub-id pub-id-type="doi">10.1038/372669a0</pub-id></citation></ref><ref id="B31"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Yound</surname><given-names>AW</given-names></name><name><surname>Rowland</surname><given-names>D</given-names></name><name><surname>Perrett</surname><given-names>DI</given-names></name><name><surname>Hodges</surname><given-names>JR</given-names></name><name><surname>Etcoff</surname><given-names>NL</given-names></name></person-group><article-title>Facial Emotion Recognition after Bilateral Amygdala Damage: Differentially Severe Impairment of Fear</article-title><source>Cognitive Neuropsychology</source><year>1996</year><volume>13</volume><fpage>699</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1080/026432996381890</pub-id></citation></ref><ref id="B32"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><name><surname>Driver</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Multiple levels of visual object constancy revealed by event-related fMRI of repetition priming</article-title><source>Nat Neurosci</source><year>2002</year><volume>5</volume><fpage>491</fpage><lpage>499</lpage><pub-id pub-id-type="pmid">11967545</pub-id><pub-id pub-id-type="doi">10.1038/nn839</pub-id></citation></ref><ref id="B33"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Armony</surname><given-names>JL</given-names></name><name><surname>Driver</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Effects of attention and emotion on face processing in the human brain: an event-related fMRI study</article-title><source>Neuron</source><year>2001</year><volume>30</volume><fpage>829</fpage><lpage>841</lpage><pub-id pub-id-type="pmid">11430815</pub-id><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00328-2</pub-id></citation></ref><ref id="B34"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>McDermott</surname><given-names>J</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title><source>J Neurosci</source><year>1997</year><volume>17</volume><fpage>4302</fpage><lpage>4311</lpage><pub-id pub-id-type="pmid">9151747</pub-id></citation></ref><ref id="B35"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Winston</surname><given-names>JS</given-names></name><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Effects of low-spatial frequency components of fearful faces on fusiform cortex activity</article-title><source>Curr Biol</source><year>2003</year><volume>13</volume><fpage>1824</fpage><lpage>1829</lpage><pub-id pub-id-type="pmid">14561410</pub-id><pub-id pub-id-type="doi">10.1016/j.cub.2003.09.038</pub-id></citation></ref><ref id="B36"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><article-title>Emotion, cognition, and behavior</article-title><source>Science</source><year>2002</year><volume>298</volume><fpage>1191</fpage><lpage>1194</lpage><pub-id pub-id-type="pmid">12424363</pub-id><pub-id pub-id-type="doi">10.1126/science.1076358</pub-id></citation></ref><ref id="B37"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>ML</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Senior</surname><given-names>C</given-names></name><name><surname>Brammer</surname><given-names>M</given-names></name><name><surname>Andrew</surname><given-names>C</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Perrett</surname><given-names>DI</given-names></name><name><surname>Rowland</surname><given-names>D</given-names></name><name><surname>Williams</surname><given-names>SC</given-names></name><name><surname>Gray</surname><given-names>JA</given-names></name><name><surname>David</surname><given-names>AS</given-names></name></person-group><article-title>A specific neural substrate for perceiving facial expressions of disgust</article-title><source>Nature</source><year>1997</year><volume>389</volume><fpage>495</fpage><lpage>498</lpage><pub-id pub-id-type="pmid">9333238</pub-id><pub-id pub-id-type="doi">10.1038/39051</pub-id></citation></ref><ref id="B38"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname><given-names>ML</given-names></name><name><surname>Medford</surname><given-names>N</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Williams</surname><given-names>L</given-names></name><name><surname>Williams</surname><given-names>SC</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Gray</surname><given-names>JA</given-names></name><name><surname>Brammer</surname><given-names>MJ</given-names></name></person-group><article-title>Time courses of left and right amygdalar responses to fearful facial expressions</article-title><source>Hum Brain Mapp</source><year>2001</year><volume>12</volume><fpage>193</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">11241871</pub-id><pub-id pub-id-type="doi">10.1002/1097-0193(200104)12:4&#x0003c;193::AID-HBM1015&#x0003e;3.0.CO;2-A</pub-id></citation></ref><ref id="B39"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Critchley</surname><given-names>H</given-names></name><name><surname>Daly</surname><given-names>E</given-names></name><name><surname>Phillips</surname><given-names>M</given-names></name><name><surname>Brammer</surname><given-names>M</given-names></name><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Williams</surname><given-names>S</given-names></name><name><surname>Van Amelsvoort</surname><given-names>T</given-names></name><name><surname>Robertson</surname><given-names>D</given-names></name><name><surname>David</surname><given-names>A</given-names></name><name><surname>Murphy</surname><given-names>D</given-names></name></person-group><article-title>Explicit and implicit neural mechanisms for processing of social information from facial expressions: a functional magnetic resonance imaging study</article-title><source>Hum Brain Mapp</source><year>2000</year><volume>9</volume><fpage>93</fpage><lpage>105</lpage><pub-id pub-id-type="pmid">10680766</pub-id></citation></ref><ref id="B40"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Russel</surname><given-names>JA</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name></person-group><article-title>A role for the human amygdala in recognizing emotional arousal from unpleasant stimuli.</article-title><source>Psychol Sci</source><year>1999</year><volume>10</volume><fpage>157</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00126</pub-id></citation></ref><ref id="B41"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>AK</given-names></name><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Stappen</surname><given-names>I</given-names></name><name><surname>Panitz</surname><given-names>D</given-names></name><name><surname>Ghahremani</surname><given-names>DG</given-names></name><name><surname>Glover</surname><given-names>G</given-names></name><name><surname>Gabrieli</surname><given-names>JD</given-names></name><name><surname>Sobel</surname><given-names>N</given-names></name></person-group><article-title>Dissociated neural representations of intensity and valence in human olfaction</article-title><source>Nat Neurosci</source><year>2003</year><volume>6</volume><fpage>196</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">12536208</pub-id><pub-id pub-id-type="doi">10.1038/nn1001</pub-id></citation></ref><ref id="B42"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Small</surname><given-names>DM</given-names></name><name><surname>Gregory</surname><given-names>MD</given-names></name><name><surname>Mak</surname><given-names>YE</given-names></name><name><surname>Gitelman</surname><given-names>D</given-names></name><name><surname>Mesulam</surname><given-names>MM</given-names></name><name><surname>Parrish</surname><given-names>T</given-names></name></person-group><article-title>Dissociation of neural representation of intensity and affective valuation in human gustation</article-title><source>Neuron</source><year>2003</year><volume>39</volume><fpage>701</fpage><lpage>711</lpage><pub-id pub-id-type="pmid">12925283</pub-id><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00467-7</pub-id></citation></ref><ref id="B43"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lang</surname><given-names>PJ</given-names></name><name><surname>Davis</surname><given-names>M</given-names></name><name><surname>Ohman</surname><given-names>A</given-names></name></person-group><article-title>Fear and anxiety: animal models and human cognitive psychophysiology</article-title><source>J Affect Disord</source><year>2000</year><volume>61</volume><fpage>137</fpage><lpage>159</lpage><pub-id pub-id-type="pmid">11163418</pub-id><pub-id pub-id-type="doi">10.1016/S0165-0327(00)00343-8</pub-id></citation></ref><ref id="B44"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>M</given-names></name><name><surname>Whalen</surname><given-names>PJ</given-names></name></person-group><article-title>The amygdala: vigilance and emotion</article-title><source>Mol Psychiatry</source><year>2001</year><volume>6</volume><fpage>13</fpage><lpage>34</lpage><pub-id pub-id-type="pmid">11244481</pub-id><pub-id pub-id-type="doi">10.1038/sj.mp.4000812</pub-id></citation></ref><ref id="B45"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Cosmides</surname><given-names>L</given-names></name><name><surname>Tooby</surname><given-names>J</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Lewis M and Haviland-Jones JM</surname></name></person-group><article-title>Evolutionary Psychology and the Emotions</article-title><source>Handbook of Emotions</source><year>2000</year><publisher-name>New York, Guilford Publications</publisher-name><fpage>91</fpage><lpage>115</lpage></citation></ref><ref id="B46"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kameda</surname><given-names>T</given-names></name><name><surname>Nakanishi</surname><given-names>D</given-names></name></person-group><article-title>Cost&#x02013;benefit analysis of social/cultural learning in a nonstationary uncertain environment: An evolutionary simulation and an experiment with human subjects</article-title><source>Evol Hum Behav</source><year>2002</year><volume>23</volume><fpage>373</fpage><lpage>393</lpage><pub-id pub-id-type="doi">10.1016/S1090-5138(02)00101-0</pub-id></citation></ref><ref id="B47"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ohman</surname><given-names>A</given-names></name><name><surname>Mineka</surname><given-names>S</given-names></name></person-group><article-title>Fears, phobias, and preparedness: toward an evolved module of fear and fear learning</article-title><source>Psychol Rev</source><year>2001</year><volume>108</volume><fpage>483</fpage><lpage>522</lpage><pub-id pub-id-type="pmid">11488376</pub-id><pub-id pub-id-type="doi">10.1037//0033-295X.108.3.483</pub-id></citation></ref><ref id="B48"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>P</given-names></name><name><surname>Frieser</surname><given-names>W</given-names></name></person-group><source>Pictures of facial affects</source><year>1976</year><publisher-name>Palo Alto, CA, Consulting Psychologists Press</publisher-name></citation></ref><ref id="B49"><citation citation-type="other"><person-group person-group-type="author"><collab>WinMorph</collab></person-group><article-title>[http://www.debugmode.com/winmorph]</article-title></citation></ref><ref id="B50"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Kushnir</surname><given-names>T</given-names></name><name><surname>Edelman</surname><given-names>S</given-names></name><name><surname>Itzchak</surname><given-names>Y</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><article-title>Cue-invariant activation in object-related areas of the human occipital lobe</article-title><source>Neuron</source><year>1998</year><volume>21</volume><fpage>191</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">9697863</pub-id><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80526-7</pub-id></citation></ref><ref id="B51"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Worsley</surname><given-names>KJ</given-names></name><name><surname>Poline</surname><given-names>JP</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><article-title>Spatial registration and normalization of images</article-title><source>Hum Brain Mapp</source><year>1995</year><volume>2</volume><fpage>165</fpage><lpage>189</lpage></citation></ref><ref id="B52"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Holmes</surname><given-names>AP</given-names></name><name><surname>Price</surname><given-names>CJ</given-names></name><name><surname>Buchel</surname><given-names>C</given-names></name><name><surname>Worsley</surname><given-names>KJ</given-names></name></person-group><article-title>Multisubject fMRI studies and conjunction analyses</article-title><source>Neuroimage</source><year>1999</year><volume>10</volume><fpage>385</fpage><lpage>396</lpage><pub-id pub-id-type="pmid">10493897</pub-id><pub-id pub-id-type="doi">10.1006/nimg.1999.0484</pub-id></citation></ref><ref id="B53"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Holmes</surname><given-names>AP</given-names></name><name><surname>Worsley</surname><given-names>KJ</given-names></name></person-group><article-title>How many subjects constitute a study?</article-title><source>Neuroimage</source><year>1999</year><volume>10</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="pmid">10385576</pub-id><pub-id pub-id-type="doi">10.1006/nimg.1999.0439</pub-id></citation></ref><ref id="B54"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Glaser</surname><given-names>D</given-names></name><name><surname>Penny</surname><given-names>W</given-names></name><name><surname>Henson</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><article-title>Coping with the variance structure of neuroimaging data [abstract]</article-title><source>J Cogn Neurosci</source><year>2002</year><fpage>Suppl 2002:E92</fpage></citation></ref><ref id="B55"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Worsley</surname><given-names>KJ</given-names></name></person-group><article-title>Local maxima and the expected euler characteristic of excursion set of  chi&#x000b2;, F, and t fields</article-title><source>Adv Appl Probab</source><year>1994</year><volume>26</volume><fpage>13</fpage><lpage>42</lpage></citation></ref><ref id="B56"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Rorden</surname><given-names>C</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name></person-group><article-title>Stereotaxic display of brain lesions</article-title><source>Behav Neurol</source><year>2000</year><volume>12</volume><fpage>191</fpage><lpage>200</lpage><pub-id pub-id-type="pmid">11568431</pub-id></citation></ref><ref id="B57"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>AC</given-names></name><name><surname>Collins</surname><given-names>DL</given-names></name><name><surname>Mills</surname><given-names>DR</given-names></name><name><surname>Brown</surname><given-names>ED</given-names></name><name><surname>Kelly</surname><given-names>RL</given-names></name><name><surname>Peters</surname><given-names>TM</given-names></name></person-group><article-title>3D statistical neuroanatomical model from 205 MRI volumes</article-title><source>Proc IEEE Nucl Sci Symp Med Imaging</source><year>1993</year><volume>1</volume><fpage>1813</fpage><lpage>1817</lpage></citation></ref><ref id="B58"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mai</surname><given-names>JK</given-names></name><name><surname>Assheuer</surname><given-names>JK</given-names></name><name><surname>Paxinos</surname><given-names>G</given-names></name></person-group><source>Atlas of the Human Brain</source><year>1998</year><edition>1</edition><publisher-name>San Diego, CA, Academic Press</publisher-name></citation></ref></ref-list><sec sec-type="display-objects"><title>Figures and Tables</title><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>Schematic display of the experimental design </bold>We used a 2 &#x000d7; 2 (facial identity &#x000d7; facial expression) factorial design with either constant/variable identity or constant/variable expression as factor levels. Each cell represents one condition in the experiment. Facial identity varied between 4 faces (2 male, 2 female), expressions varied between 5 facial emotions ranging from maximally fearful over neutral to maximally happy with moderately fearful and happy in between. Pictures were presented sequentially at 1 Hz (900 ms stimulus duration, 100 ms blank screen).</p></caption><graphic xlink:href="1471-2202-5-45-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>Responses to different experimental conditions in both amygdalae </bold>Coronal and transversal views of the activation foci in both amygdalae. These SPMs are derived from the interaction contrast identity &#x000d7; emotion (see Methods) and are superimposed on an averaged T<sub>1</sub>-weighted MR image of all our subjects. Arrows are pointing to the maximally activated voxel in the region. We report left amygdala activation in the light of bilateral activation shown previously in similar tasks [11,14]. <bold>Top left and right panels. </bold>Group mean parameter estimates (regression coefficients &#x000b1; s.e.m.) to each of the experimental conditions for bilateral amygdala are shown. Condition V<sub>I</sub>C<sub>E </sub>elicits the largest activation of the peak voxels in both amygdalae and is significantly larger than all other experimental conditions. Asterisks (*) indicate significant difference of respective condition compared with condition V<sub>I</sub>C<sub>E </sub>at the specified uncorrected significance level. <bold>Bottom left and right panels. </bold>Detailed (emotion-specific) analysis of condition V<sub>I</sub>C<sub>E</sub>. Category labels refer to maximally fearful, neutral, and maximally happy facial expression. Intermediate categories are minimally fearful and minimally happy facial expression. Largest activations are elicited by maximally fearful faces. Asterisks (*) indicate significant differences between the respective emotion compared with maximally fearful faces at the specified uncorrected significance level.</p></caption><graphic xlink:href="1471-2202-5-45-2"/></fig><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>Fitted time curves of BOLD-responses of the emotion-specific analysis of condition V<sub>I</sub>C<sub>E </sub></bold>Category labels refer to maximally fearful, neutral, and maximally happy facial expression, respectively. The fitted time courses from the peak voxels of SPMs derived from the interaction contrast identity &#x000d7; emotion (see Methods) are presented.</p></caption><graphic xlink:href="1471-2202-5-45-3"/></fig><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>Responses to different experimental conditions in left and right lateral fusiform gyri Middle panels. </bold>Coronal view of the activation foci in the lateral fusiform gyri bilaterally. These SPMs are derived from the contrast that tested for a simple effect of changing stimulus features (see Methods) and are superimposed on an averaged T<sub>1</sub>-weighted MR image of all our subjects. Arrows are pointing to the maximally activated voxels in the region. <bold>Left and right panels. </bold>Group mean parameter estimates (regression coefficients &#x000b1; s.e.m.) to each of the experimental conditions for bilateral lateral fusiform gyrus are shown. All conditions with changing stimulus features (identity, emotion; V<sub>I</sub>C<sub>E</sub>, C<sub>I</sub>V<sub>E</sub>, V<sub>I</sub>V<sub>E</sub>) elicit significantly larger activation of the peak voxels in both fusiform gyri than condition C<sub>I</sub>C<sub>E </sub>in which the same pictures were shown for the entire block. Asterisks (*) indicate significant differences of respective condition compared with condition C<sub>I</sub>C<sub>E </sub>at the specified uncorrected significance level. <bold>Bottom left and right panels. </bold>Detailed (emotion-specific) analysis of condition V<sub>I</sub>C<sub>E</sub>. Category labels refer to maximally fearful, neutral, and maximally happy facial expression. Intermediate categories are minimally fearful and minimally happy facial expression. Largest activations are elicited by maximally fearful faces. Asterisks (*) indicate significant differences between the respective emotion compared with maximally fearful faces at the specified significance level, pluses (+) indicate significant differences between the respective emotion compared with maximally happy faces at the specified uncorrected significance level.</p></caption><graphic xlink:href="1471-2202-5-45-4"/></fig><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Location of significant voxels in amygdala and lateral fusiform gyrus. </p></caption><table frame="hsides" rules="groups"><thead><tr><td align="left"><bold>Region</bold></td><td align="left"><bold>x</bold></td><td align="left"><bold>y</bold></td><td align="left"><bold>z</bold></td><td align="left"><bold>Z-value</bold></td></tr></thead><tbody><tr><td align="left">Left Amygdala</td><td align="left">&#x000a0;-15</td><td align="left">&#x000a0;&#x000a0;&#x000a0;0</td><td align="left">-15</td><td align="left">2.65</td></tr><tr><td align="left">Right Amygdala</td><td align="left">&#x000a0;&#x000a0;18</td><td align="left">&#x000a0;&#x000a0;&#x000a0;0</td><td align="left">-18</td><td align="left">3.55**</td></tr><tr><td align="left">Left Fusiform Gyrus</td><td align="left">&#x000a0;-39</td><td align="left">-54</td><td align="left">-24</td><td align="left">3.43*</td></tr><tr><td align="left">Right Fusiform Gyrus</td><td align="left">&#x000a0;&#x000a0;36</td><td align="left">-54</td><td align="left">-24</td><td align="left">3.19*</td></tr></tbody></table><table-wrap-foot><p>Statistics in the amygdala are based on a reduced search volume based on an anatomical mask (see Methods). In the fusiform gyri we employed a search volume with a 10 mm radius sphere centered on coordinates reported by Vuilleumier and colleagues [33] which derived from a comparison between face and house stimuli in a functional localizer [&#x000b1; 45 -54 -21]. All reported activations are corrected for the volume of interest. MNI coordinates. * p &#x0003c; .05 (corrected); ** p &#x0003c; .01 (corrected).</p></table-wrap-foot></table-wrap></sec></back></article>



