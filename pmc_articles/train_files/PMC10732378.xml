<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmc">PMC10732378</article-id><article-id pub-id-type="publisher-id">PONE-D-23-07266</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0295925</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision Making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability Theory</subject><subj-group><subject>Statistical Distributions</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Natural Language Processing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Languages</subject><subj-group><subject>Natural Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Grammar</subject><subj-group><subject>Syntax</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Programming Languages</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Programming Languages</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability Theory</subject><subj-group><subject>Probability Distribution</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Quantifying confidence shifts in a BERT-based question answering system evaluated on perturbed instances</article-title><alt-title alt-title-type="running-head">Quantifying confidence shifts in RoBERTa</alt-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Shen</surname><given-names>Ke</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="aff001" ref-type="aff"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5988-8305</contrib-id><name><surname>Kejriwal</surname><given-names>Mayank</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff"/><xref rid="cor001" ref-type="corresp">*</xref></contrib></contrib-group><aff id="aff001">
<addr-line>Information Sciences Institute, University of Southern California, Marina del Rey, California, United States of America</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Barros</surname><given-names>Rodrigo Coelho</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>PUCRS: Pontificia Universidade Catolica do Rio Grande do Sul, BRAZIL</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>kejriwal@isi.edu</email></corresp></author-notes><pub-date pub-type="collection"><year>2023</year></pub-date><pub-date pub-type="epub"><day>20</day><month>12</month><year>2023</year></pub-date><volume>18</volume><issue>12</issue><elocation-id>e0295925</elocation-id><history><date date-type="received"><day>11</day><month>3</month><year>2023</year></date><date date-type="accepted"><day>28</day><month>11</month><year>2023</year></date></history><permissions><copyright-statement>&#x000a9; 2023 Shen, Kejriwal</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Shen, Kejriwal</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0295925.pdf"/><abstract><p>Recent work on transformer-based neural networks has led to impressive advances on multiple-choice natural language processing (NLP) problems, such as Question Answering (QA) and abductive reasoning. Despite these advances, there is limited work still on systematically evaluating such models in <italic toggle="yes">ambiguous</italic> situations where (for example) no correct answer exists for a given prompt among the provided set of choices. Such ambiguous situations are not infrequent in real world applications. We design and conduct an experimental study of this phenomenon using three probes that aim to &#x02018;confuse&#x02019; the model by perturbing QA instances in a consistent and well-defined manner. Using a detailed set of results based on an established transformer-based multiple-choice QA system on two established benchmark datasets, we show that the model&#x02019;s confidence in its results is very different from that of an expected model that is &#x02018;agnostic&#x02019; to all choices that are incorrect. Our results suggest that high performance on idealized QA instances should not be used to infer or extrapolate similarly high performance on more ambiguous instances. Auxiliary results suggest that the model may not be able to distinguish between these two situations with sufficient certainty. Stronger testing protocols and benchmarking may hence be necessary before such models are deployed in front-facing systems or ambiguous decision making with significant human impact.</p></abstract><funding-group><award-group id="award001"><funding-source>
<institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100006502</institution-id><institution>Defense Sciences Office, DARPA</institution></institution-wrap>
</funding-source><award-id>N660011924033</award-id><principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5988-8305</contrib-id>
<name><surname>Kejriwal</surname><given-names>Mayank</given-names></name>
</principal-award-recipient></award-group><funding-statement>MK received funding for this work as a principal investigator of MOWGLI, a project in the Defense Advanced Research Projects Agency (DARPA) Machine Common Sense program, supported by the United States Office Of Naval Research under Contract No. N660011924033. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="7"/><page-count count="21"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All files and data used in this study are available from the Kaggle platform (doi: <ext-link xlink:href="https://doi.org/10.34740/kaggle/dsv/5130107" ext-link-type="uri">10.34740/kaggle/dsv/5130107</ext-link>).</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All files and data used in this study are available from the Kaggle platform (doi: <ext-link xlink:href="https://doi.org/10.34740/kaggle/dsv/5130107" ext-link-type="uri">10.34740/kaggle/dsv/5130107</ext-link>).</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Question Answering (QA) [<xref rid="pone.0295925.ref001" ref-type="bibr">1</xref>] and inference are important tasks in natural language processing (NLP) and applied AI, and fundamental to the development of conversational &#x02018;chatbot&#x02019; agents [<xref rid="pone.0295925.ref002" ref-type="bibr">2</xref>]. Advancements in the last five years in deep neural transformer-based models have led to significant improvements in QA performance, especially in the multiple-choice setting. Bidirectional Encoder Representations from Transformers (BERT) [<xref rid="pone.0295925.ref003" ref-type="bibr">3</xref>] was a pivotal model that ushered in a wave of transformer-based architectures that consequently achieved state-of-the-art performance in a range of NLP tasks, including QA and Web search. BERT achieved state-of-the-art performance due to its self-attention mechanism, novel bidirectional encoding capability, masked language modeling, and next sentence prediction functions.</p><p>While generative models such as ChatGPT and GPT-3 have recently captured much of the general public&#x02019;s attention [<xref rid="pone.0295925.ref004" ref-type="bibr">4</xref>], BERT-based models continue to be important in many applications, especially those that rely on fine-tuned domain-specific data (often of a proprietary or specialized nature) and open-source architecture that can be efficiently executed on private servers. Examples of such specialized BERT-based models include Patentbert [<xref rid="pone.0295925.ref005" ref-type="bibr">5</xref>], Docbert [<xref rid="pone.0295925.ref006" ref-type="bibr">6</xref>], SciBERT [<xref rid="pone.0295925.ref007" ref-type="bibr">7</xref>], DistilBERT [<xref rid="pone.0295925.ref008" ref-type="bibr">8</xref>] and K-bert [<xref rid="pone.0295925.ref009" ref-type="bibr">9</xref>], all of which have achieved groundbreaking results in diverse language understanding tasks, including QA [<xref rid="pone.0295925.ref010" ref-type="bibr">10</xref>&#x02013;<xref rid="pone.0295925.ref012" ref-type="bibr">12</xref>], text summarization [<xref rid="pone.0295925.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0295925.ref014" ref-type="bibr">14</xref>], sentence prediction [<xref rid="pone.0295925.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0295925.ref016" ref-type="bibr">16</xref>], dialogue response generation [<xref rid="pone.0295925.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0295925.ref018" ref-type="bibr">18</xref>], natural language inference [<xref rid="pone.0295925.ref019" ref-type="bibr">19</xref>, <xref rid="pone.0295925.ref020" ref-type="bibr">20</xref>], and sentiment classification [<xref rid="pone.0295925.ref021" ref-type="bibr">21</xref>&#x02013;<xref rid="pone.0295925.ref023" ref-type="bibr">23</xref>]. Because BERT-based models, and their many applications, continue to be important in real-world settings, understanding its performance in unexpected and ambiguous situations has also become important, especially in broad domains such as commonsense multiple-choice QA.</p><p>Although a growing body of research continues to be published on so-called BERTology [<xref rid="pone.0295925.ref024" ref-type="bibr">24</xref>], which aims to understand the psycholinguistic properties, and knowledge content, of models like BERT, there is considerable less work on systematically evaluating such models in <italic toggle="yes">ambiguous</italic> situations where (for example) no correct answer exists for a given prompt among the provided set of choices. Such ambiguous situations are not infrequent in real world applications [<xref rid="pone.0295925.ref025" ref-type="bibr">25</xref>].</p><p>Given real-world usage and relevance of language representation models like BERT, this article aims to systematically study their behavior in such ambiguous situations. We design and implement a novel set of three <italic toggle="yes">confusion probes</italic> to observe how the confidence distribution shifts, when faced with ambiguity, of an established multiple-choice QA system based on the RoBERTa model, an evolution of BERT. Derived from the original BERT model, RoBERTa modified its pre-training objectives, adopted larger batch sizes and longer sequences, and used dynamic masking techniques during training. These enhancements have demonstrated RoBERTa&#x02019;s robustness and its ability to achieve superior performance across various NLP tasks when compared to BERT. The confusion probes, which are conceptually simple to design and hence replicate, are illustrated in <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>, which also introduces some important terminology that we subsequently define in the <italic toggle="yes">Formalism</italic> section. Each probe operates at the level of an <italic toggle="yes">instance</italic>, which comprises a <italic toggle="yes">prompt</italic> and a <italic toggle="yes">candidate set of answers</italic> or choices. While a prompt can be a question, in practice, it tends to be more complex, and may be a statement, paragraph, or even a contextualized question, as demonstrated in <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>. Based on the specific commonsense task that the QA benchmark is seeking to evaluate, exactly one of the candidate choices is considered correct for that prompt. However, once a confusion probe is applied, there is no correct choice. Probes may perturb the instance at the level of the prompt, or at the level of the candidate choice-set.</p><fig position="float" id="pone.0295925.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.g001</object-id><label>Fig 1</label><caption><title>An example (from the real-world Social Interaction QA benchmark) of the three confusion probes used in this paper as perturbation-based functions.</title><p>Two prompt-based perturbations are shown at the top, and a choice-based perturbation is shown at the bottom. In Social IQA, the <italic toggle="yes">prompt</italic> in an <italic toggle="yes">instance</italic> comprises both a context and question, and a set of three candidate choices, of which exactly one is considered correct in the original unperturbed instance. A fine-tuned QA system is able to assign a <italic toggle="yes">confidence score</italic> to every potential choice for a given instance (shown on the bottom right), with confidences across choices summing up to 1. The model will choose the candidate choice with the highest confidence as its predicted correct choice.</p></caption><graphic xlink:href="pone.0295925.g001" position="float"/></fig><p>Without any perturbation, a sufficiently powerful QA system would assign a high confidence score to the correct choice, and low scores to the incorrect ones. This behavior is illustrated on the left side of <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>. The question that we aim to investigate in this article is what happens to the confidence distribution of the model after the probes are applied. Theoretically, an &#x02018;agnostic&#x02019; model that is equally indifferent to all incorrect choices would pick an arbitrary choice with uniform probability, leading to a confidence score per choice of 1/<italic toggle="yes">n</italic> where <italic toggle="yes">n</italic> is the (fixed) <italic toggle="yes">number</italic> of candidate choices that the model has to select from when prompted, and near-zero variance in the confidence distribution. Alternatively, it may well be that the model actually ends up shifting its high confidence in the (previously) correct choice in some non-random, but statistically distinguishable, fashion.</p><p>To resolve between these possibilities, we conduct a statistical analysis of the confidence behavior of a fine-tuned, high-performance language model across widely used commonsense multiple-choice QA benchmarks. In the vein of <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>, we systematically perturb instances in these benchmark such that no correct choice exists in response to a given prompt. Because the <italic toggle="yes">manner</italic> in which the question or candidate choices are perturbed might make a difference to the statistical distribution of confidences, we enumerate two related research questions:</p><list list-type="order"><list-item><p><bold>Research Question (RQ) 1</bold>: How does the confidence distribution of a sufficiently powerful (i.e., fine-tuned) ROBERTa-based QA system change when the prompt of an instance is modified, such that the original correct choice is no longer correct?</p></list-item><list-item><p><bold>Research Question (RQ) 2</bold>: How does the confidence distribution of a sufficiently powerful (i.e., fine-tuned) ROBERTa-based QA system change when the original correct choice in an instance is substituted with a new incorrect choice, again rendering the instance without a correct response to the (unmodified) prompt?</p></list-item></list><p>Unlike much of the prior work on this subject (further discussed in <italic toggle="yes">Related Work</italic>), we are not seeking to understand the layers of a specific network or how it encodes knowledge, but rather, to understand how these models behave when they are presented with challenging instances without correct solutions (even if such solutions exist). A clear understanding of this behavior, at least in the multiple-choice QA setting, allows us to test whether such language models, which are continuing to be rolled out in commercial products, exhibit statistical behavior that is reasonably predictable when faced with such instances.</p></sec><sec id="sec002"><title>Related work</title><p>BERT&#x02019;s original success on discriminative NLP tasks (following a fine-tuning step) has also motivated researchers to adapt it for multi-modal language representation [<xref rid="pone.0295925.ref026" ref-type="bibr">26</xref>, <xref rid="pone.0295925.ref027" ref-type="bibr">27</xref>], cross-lingual language models [<xref rid="pone.0295925.ref028" ref-type="bibr">28</xref>], and domain-specific language models, including in the legal- [<xref rid="pone.0295925.ref029" ref-type="bibr">29</xref>], finance- [<xref rid="pone.0295925.ref030" ref-type="bibr">30</xref>], patent- [<xref rid="pone.0295925.ref005" ref-type="bibr">5</xref>], medicine- [<xref rid="pone.0295925.ref031" ref-type="bibr">31</xref>&#x02013;<xref rid="pone.0295925.ref033" ref-type="bibr">33</xref>] and biology-related domains [<xref rid="pone.0295925.ref034" ref-type="bibr">34</xref>]. Due to this widespread use of BERT and the more advanced models based on similar transformer-based networks, it has become important to systematically study the linguistic-cognitive properties of BERT. In prior work, for example, several proposed approaches aimed to study the knowledge encoded within BERT, including fill-in-the-gap probes of MLM [<xref rid="pone.0295925.ref035" ref-type="bibr">35</xref>, <xref rid="pone.0295925.ref036" ref-type="bibr">36</xref>], analysis of self-attention weights [<xref rid="pone.0295925.ref037" ref-type="bibr">37</xref>, <xref rid="pone.0295925.ref038" ref-type="bibr">38</xref>], the probing of classifiers with different BERT representations as inputs [<xref rid="pone.0295925.ref039" ref-type="bibr">39</xref>, <xref rid="pone.0295925.ref040" ref-type="bibr">40</xref>], and a &#x02018;CheckList&#x02019; style approach to systematically evaluate the linguistic capability of a BERT-based model [<xref rid="pone.0295925.ref041" ref-type="bibr">41</xref>]. Evidence from this line of research suggests that BERT encodes a hierarchy of linguistic information, with surface features in the bottom, syntactic features in the middle, and semantic features in the top layers [<xref rid="pone.0295925.ref042" ref-type="bibr">42</xref>]. BERT &#x02018;naturally&#x02019; seems to learn syntactic information from pre-training text without explicit labeling of syntactic structures.</p><p>However, it has been found that while information can be recovered from its token representation [<xref rid="pone.0295925.ref043" ref-type="bibr">43</xref>], it does not fully &#x02018;understand&#x02019; naturalistic concepts like negation, and is insensitive to malformed input [<xref rid="pone.0295925.ref035" ref-type="bibr">35</xref>]. The latter is similar to <italic toggle="yes">adversarial</italic> experiments (not dissimilar to adversarial experiments in the computer vision community) that researchers have conducted to test BERT&#x02019;s robustness. Some of these experiments have shown that, even though BERT encodes information about entity types, relations, semantic roles, and proto-roles well, it struggles with the representations of numbers [<xref rid="pone.0295925.ref044" ref-type="bibr">44</xref>] and is also brittle to named entity replacements [<xref rid="pone.0295925.ref045" ref-type="bibr">45</xref>].</p><p>The model studied in this paper, RoBERTa [<xref rid="pone.0295925.ref046" ref-type="bibr">46</xref>], is a highly optimized version of the original BERT architecture that was first published in 2019 and improved over BERT on various benchmarks by margins of 0.9 [on the Quora Question Pairs dataset [<xref rid="pone.0295925.ref047" ref-type="bibr">47</xref>]]&#x02014;16.2 percent [on the Recognizing Textual Entailment dataset [<xref rid="pone.0295925.ref048" ref-type="bibr">48</xref>&#x02013;<xref rid="pone.0295925.ref051" ref-type="bibr">51</xref>]]. Compared to the original BERT model, RoBERTa implemented several key modifications in its training strategies. First, RoBERTa replaced the original random static masking strategy in BERT&#x02019;s implementation with dynamic masking, a change that offers particular advantages when dealing with larger training datasets or conducting more pertaining steps. Second, BERT used two objectives during pre-training, masked language modeling (MLM) and next sentence prediction (NSP). RoBERTa removed the NSP from the training objective, resulting in a slight improvement in its performance in downstream tasks as compared to BERT. Lastly, the original BERT model was trained with a batch size of 256 sequences, and a character-level byte-pair encoding (BPE) vocabulary of size 30K. RoBERTa&#x02019;s training process involved the use of larger batches (8K sequences) and larger BPE vocabulary (containing 50K subword units). These refinements have further bolstered RoBERTa&#x02019;s performance, particularly in tasks such as Multi-Genre Natural Language Inference [<xref rid="pone.0295925.ref052" ref-type="bibr">52</xref>] and Question-Based Natural Language Inference [<xref rid="pone.0295925.ref053" ref-type="bibr">53</xref>]. RoBERTa-based models have approached near-human performance on various (subsequently described) commonsense NLP benchmarks.</p></sec><sec id="sec003"><title>Formalism</title><p>We begin by defining an <italic toggle="yes">instance</italic>
<italic toggle="yes">I</italic> = (<italic toggle="yes">p</italic>, <italic toggle="yes">A</italic>) as a pair composed of a <italic toggle="yes">prompt</italic>
<italic toggle="yes">p</italic>, and a set <italic toggle="yes">A</italic> = {<italic toggle="yes">a</italic><sub>1</sub>, <italic toggle="yes">a</italic><sub>2</sub>, &#x02026;, <italic toggle="yes">a</italic><sub><italic toggle="yes">n</italic></sub>} of <italic toggle="yes">n</italic> candidate <italic toggle="yes">choices</italic>. The value <italic toggle="yes">n</italic> depends on the benchmark, and is fixed for the benchmark. For example, as shown in <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>, <italic toggle="yes">n</italic> = 3 for the Social IQA benchmark. Intuitively, the term <italic toggle="yes">prompt</italic> (rather than <italic toggle="yes">question</italic>) is more appropriate for these problems because the input may not be a proper question. In general, commonsense benchmarks are considered to be natural language <italic toggle="yes">inference</italic> (NLI) benchmarks, which <italic toggle="yes">may</italic> involve QA, but do not have to. Examples of NLI tasks that obey the definition above (and are hence applicable to the study) but are not strictly QA include abductive reasoning and goal satisfaction. Typically, both prompts and choices in these problem domains are represented as statements or paragraphs. We provide examples subsequently when we describe the benchmarks in more detail. In benchmarks like Social IQA, both a statement and question can be part of the prompt, as shown in <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>.</p><p>Given an instance <italic toggle="yes">I</italic> = (<italic toggle="yes">p</italic>, <italic toggle="yes">A</italic>), we assume that exactly one of the choices <inline-formula id="pone.0295925.e001"><alternatives><graphic xlink:href="pone.0295925.e001.jpg" id="pone.0295925.e001g" position="anchor"/><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is <italic toggle="yes">correct</italic>. Given a language representation model <italic toggle="yes">f</italic> that is designed to handle multi-choice NLI instances (such as the one used in this article), we assume the output of <italic toggle="yes">f</italic>, given <italic toggle="yes">I</italic>, to be the map <italic toggle="yes">C</italic> = {<italic toggle="yes">a</italic><sub>1</sub> = <italic toggle="yes">c</italic><sub>1</sub>, <italic toggle="yes">a</italic><sub>2</sub> = <italic toggle="yes">c</italic><sub>2</sub>, &#x02026;, <italic toggle="yes">a</italic><sub><italic toggle="yes">n</italic></sub> = <italic toggle="yes">c</italic><sub><italic toggle="yes">n</italic></sub>} with exactly <italic toggle="yes">n</italic> key-value pairs. Each value in the map is a real value in [0, 1]. We refer to the values in <italic toggle="yes">C</italic> as the <italic toggle="yes">confidence set</italic> that includes the model&#x02019;s confidence <italic toggle="yes">c</italic><sub><italic toggle="yes">i</italic></sub> per candidate choice <italic toggle="yes">a</italic><sub><italic toggle="yes">i</italic></sub> &#x02208; <italic toggle="yes">A</italic>. The sum of the confidences in the confidence set must add to 1.0. The choice <italic toggle="yes">a</italic>&#x02032; &#x02208; <italic toggle="yes">A</italic> that is associated with the highest confidence in <italic toggle="yes">C</italic> is typically considered to have been &#x02018;selected&#x02019; by the model as its response to the originally posed prompt.</p><p>We say that <italic toggle="yes">I</italic> is <italic toggle="yes">perturbed</italic> either if <italic toggle="yes">p</italic> is changed in some manner (including being assigned the &#x02018;empty string&#x02019;) or if <italic toggle="yes">A</italic> is modified through addition, deletion, substitution, or any other modification of candidate choices. If a perturbation <italic toggle="yes">P</italic> applied on <italic toggle="yes">I</italic> results in the perturbed instance <italic toggle="yes">I</italic><sub><italic toggle="yes">P</italic></sub> not having any <italic toggle="yes">theoretically correct</italic> choice in response to the prompt, but <inline-formula id="pone.0295925.e002"><alternatives><graphic xlink:href="pone.0295925.e002.jpg" id="pone.0295925.e002g" position="anchor"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is still a candidate choice, we refer to <inline-formula id="pone.0295925.e003"><alternatives><graphic xlink:href="pone.0295925.e003.jpg" id="pone.0295925.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> as the <italic toggle="yes">pseudo-correct choice</italic>.</p><p>An obvious example of when this occurs is a perturbation that &#x02018;deleted&#x02019; the prompt by assigning it the empty string. Since there is no prompt, none of the candidate choices is theoretically correct or incorrect. Assuming that <italic toggle="yes">A</italic> was not modified, the pseudo-correct choice would be <inline-formula id="pone.0295925.e004"><alternatives><graphic xlink:href="pone.0295925.e004.jpg" id="pone.0295925.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p><p>Finally, for the set of incorrect choices <inline-formula id="pone.0295925.e005"><alternatives><graphic xlink:href="pone.0295925.e005.jpg" id="pone.0295925.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x02254;</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> in an original (unperturbed) instance <italic toggle="yes">I</italic>, we can denote the set of their confidences as <inline-formula id="pone.0295925.e006"><alternatives><graphic xlink:href="pone.0295925.e006.jpg" id="pone.0295925.e006g" position="anchor"/><mml:math id="M6" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. Similarly, in a perturbed instance <italic toggle="yes">I</italic><sub><italic toggle="yes">P</italic></sub>, the set of confidences for all incorrect choices except the pseudo-correct choice (which we emphasize is also technically incorrect in a perturbed instance) is denoted as <inline-formula id="pone.0295925.e007"><alternatives><graphic xlink:href="pone.0295925.e007.jpg" id="pone.0295925.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. Making this terminological distinction will allow us to study the statistical shifting of the confidence distribution between <inline-formula id="pone.0295925.e008"><alternatives><graphic xlink:href="pone.0295925.e008.jpg" id="pone.0295925.e008g" position="anchor"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:math></alternatives></inline-formula> in the original and perturbed instance, and the change in confidence in the pseudo-correct choice <inline-formula id="pone.0295925.e009"><alternatives><graphic xlink:href="pone.0295925.e009.jpg" id="pone.0295925.e009g" position="anchor"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> in the perturbed instance compared to the original instance.</p><p>It bears emphasizing that <inline-formula id="pone.0295925.e010"><alternatives><graphic xlink:href="pone.0295925.e010.jpg" id="pone.0295925.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is not changed (although its confidence could be significantly changed) when the perturbation is prompt-based, but is necessarily substituted with a different choice when the perturbation is choice-based. The way in which this substitution occurs is subsequently discussed in <italic toggle="yes">Materials and methods</italic>. In contrast, the set <inline-formula id="pone.0295925.e011"><alternatives><graphic xlink:href="pone.0295925.e011.jpg" id="pone.0295925.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, comprising the &#x02018;originally incorrect&#x02019; choices, is always unchanged regardless of the perturbation applied. Furthermore, although we use the three probes that are visually illustrated in <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref> in this work, this formalism would apply to any perturbation function, as long as (i) the perturbation did not occur both at the level of prompt and choices, (ii) resulted in no choice being theoretically correct, and (iii) did not modify the parameter <italic toggle="yes">n</italic> that is local to the benchmark on which the perturbations are being applied.</p></sec><sec sec-type="materials|methods" id="sec004"><title>Materials and methods</title><sec id="sec005"><title>Evaluation datasets</title><p>The two benchmarks used in the experimental study are described below, with references for further reading. We also provide a representative example in <xref rid="pone.0295925.g002" ref-type="fig">Fig 2</xref>. We emphasize that an instance is the combination of the prompt and the candidate choice-set, and only if the prompt is an actual question, should the instance technically be thought of as a QA instance. In the general case, each instance should be thought of broadly as testing natural language inference. In the rest of the discussion, we continue using the proper terms &#x02018;instance&#x02019;, &#x02018;choice&#x02019; and &#x02018;prompt&#x02019; (rather than the somewhat inaccurate terms &#x02018;QA instance&#x02019;, &#x02018;question&#x02019; and &#x02018;answer&#x02019;, respectively) to refer to these concepts.</p><list list-type="order"><list-item><p><bold>HellaSwag</bold>: HellaSWAG [<xref rid="pone.0295925.ref054" ref-type="bibr">54</xref>, <xref rid="pone.0295925.ref055" ref-type="bibr">55</xref>] is a dataset for studying grounded commonsense inference. It consists of 49,947 multiple-choice instances about &#x02018;grounded situations&#x02019; (with 39,905 instances in the training set and 10,042 instances in a held-out set). Each prompt comes from one of two domains&#x02013;Activity Net or wikiHow&#x02013;with four candidate choices about what might happen next in the scene. The correct choice is the (real) sentence for the next event; the three incorrect choices are adversarially generated and human-verified, ensuring a non-trivial probability of &#x02018;fooling&#x02019; machines but not (most) humans. Each HellaSwag instance provides two <italic toggle="yes">contexts</italic> as the prompt. UNICORN [<xref rid="pone.0295925.ref056" ref-type="bibr">56</xref>], a model based on the T5 language model, achieves the current highest performance (0.94) of models on this benchmark, which approaches human performance (0.96).</p></list-item><list-item><p><bold>Social IQA</bold>: Social Interaction QA [<xref rid="pone.0295925.ref057" ref-type="bibr">57</xref>, <xref rid="pone.0295925.ref058" ref-type="bibr">58</xref>] is a QA benchmark for testing social common sense. In contrast with prior benchmarks focusing primarily on physical or taxonomic knowledge, Social IQA is mainly concerned with testing a machine&#x02019;s reasoning capabilities about people&#x02019;s actions and their social implications. Actions in Social IQA span many social situations, and candidate choices comprise of both human-curated answers and &#x02018;adversarially-filtered&#x02019; machine-generated choices. Social IQA contains 33,410 instances in its training set, and 1,954 instances in its held-out set. While Social IQA separates the context from the question, the two collectively constitute the prompt, in keeping with the terminology mentioned earlier. We note that both human- and machine-performance on Social IQA are slightly lower than other benchmarks. Specifically, human accuracy on Social IQA is 0.88, with UNICORN achieving an accuracy of 0.83.</p></list-item></list><fig position="float" id="pone.0295925.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.g002</object-id><label>Fig 2</label><caption><title>Instances (prompt and candidate choice-set) from the two commonsense benchmark datasets used for the experimental study herein.</title><p>The prompt is highlighted in yellow, and the correct choice is in blue.</p></caption><graphic xlink:href="pone.0295925.g002" position="float"/></fig></sec><sec id="sec006"><title>RoBERTa-based model</title><p>RoBERTa is a more optimized re-training of BERT that removes the <italic toggle="yes">Next Sentence Prediction</italic> task from BERT&#x02019;s pre-training, while introducing dynamic masking so that the masked token changes during the training epochs. Larger batch-training sizes were also found to be more useful in the training procedure. Unlike a more recent model like GPT-3 or even ChatGPT, a pre-trained version of RoBERTa is fully available for researchers to use and can be fine-tuned for specific tasks [<xref rid="pone.0295925.ref046" ref-type="bibr">46</xref>].</p><p>Unsurprisingly, many of the systems occupying a significant fraction of top leaderboard positions (hosted by the Allen Institute) for the commonsense reasoning benchmarks described earlier are based on RoBERTa (or some other optimized BERT-based model) in some significant manner. All experiments in this paper use a publicly available <italic toggle="yes">RoBERTa Ensemble</italic> model [<xref rid="pone.0295925.ref059" ref-type="bibr">59</xref>], which is a pre-trained RoBERTa-large model and was not developed by any the authors, either in principle or practice, and that can be downloaded and replicated very precisely. It is also worth noting that even recent models that have superseded RoBERTa (such as T5) on the benchmarks are based on transformers as well.</p><p>The RoBERTa Ensemble model (henceforth called the <italic toggle="yes">RoBERTa-based Model</italic> for the purposes of this paper) is fine-tuned on each benchmark&#x02019;s respective training set and evaluated on its held-out set to test the model&#x02019;s performance. As mentioned, the fine-tuning of the RoBERTa-based model is conducted using a RoBERTa-large model with specific parameter settings, including a gradient batch accumulation of 3, a maximum of 4 epochs, a learning rate set at 5e-6, 300 warm-up steps, a batch size of 3, and a maximum sequence length of 128. Because there are two benchmarks used in this study, there are two such fine-tuned models. We use the appropriate fine-tuned model when obtaining the confidence distributions of instances (both perturbed and unperturbed) for a given benchmark. Each such trained model was verified to achieve competitive performance over 80% accuracy (on average) over the two benchmarks. Note that the fine-tuned models are not &#x02018;aware&#x02019; of the perturbation, as these are not used during the fine-tuning (in other words, we never apply the perturbation functions to any of the training instances), as our experimental goal is to understand the behavior of the model precisely when it is faced with ambiguous instances that it has not been taught to expect in advance.</p></sec><sec id="sec007"><title>Perturbation methodology</title><p>To explore the change in confidence distribution of RoBERTa when the original prompt or candidate choice in an instance is modified in a manner that there is no theoretically correct choice, we designed two prompt-based perturbation functions (<italic toggle="yes">No-Question</italic> probe and <italic toggle="yes">Wrong-Question</italic> probe) for investigating <italic toggle="yes">RQ1</italic>, and one choice-based perturbation function (<italic toggle="yes">No-Right-Answer</italic> probe) for investigating <italic toggle="yes">RQ2</italic>. These functions, named intuitively and defined below, operate by systematically transforming multiple-choice NLI instances in the two publicly available benchmarks discussed earlier:</p><p>The prompt-based perturbation functions that are designed for <italic toggle="yes">RQ1</italic> are:</p><list list-type="bullet"><list-item><p><bold>No-Question probe</bold>: This perturbation function modifies an instance by removing the prompt altogether and only retaining the candidate choice-set. For each instance, we replace the prompt with an empty string while still making the RoBERTa-based QA model select a choice from its original choice-set. Note that the RoBERTa-based model is syntactically capable of accepting an empty string as prompt.</p></list-item><list-item><p><bold>Wrong-Question probe</bold>: Similar to the No-Question probe, this probe retains the original candidate choice-set for an instance, but &#x02018;swaps&#x02019; the original prompt in an instance with a prompt from another instance (in the same benchmark) that is not relevant to any of the answers. For each instance, we replace the original prompt with a <italic toggle="yes">mismatched</italic> prompt (called the &#x02018;pseudo-prompt&#x02019;). The pseudo-prompt for a given instance is an actual prompt from another randomly selected instance in that benchmark. No change is made to the choice-set. While there is a very small probability that the pseudo-prompt may be correctly answered by a choice from the unmodified choice-set, in practice, we could find no such cases when we randomly sampled and manually checked 25 perturbed instances from each benchmark. As a further robustness check, we conducted another experiment where, instead of randomly sampling an instance from which the pseudo-prompt was selected, we only considered sampling from instances where the prompt did not share any words with the original prompt. The experimental results were not found to change appreciably compared to the simpler replacement protocol described above. Hence, we only report those results for that protocol. Furthermore, to account for randomness, we repeat the experiment five times (per benchmark), and report average performance.</p></list-item></list><p>There is precedent for using the <italic toggle="yes">No-Question</italic> perturbation in other natural language tasks. For example, [<xref rid="pone.0295925.ref060" ref-type="bibr">60</xref>] used this probe to test the difficulty of reading comprehension benchmarks. The examples in these benchmarks are tuples consisting of questions, passages, and answers. In their experiments, they analyzed the model&#x02019;s performance on various benchmarks when the test examples were provided with question-only or passage-only information (but not both). Similarly, in an NLI task, [<xref rid="pone.0295925.ref061" ref-type="bibr">61</xref>, <xref rid="pone.0295925.ref062" ref-type="bibr">62</xref>] re-evaluated high-performing models on hypothesis-only examples. In their experiments, models predicted the label (&#x02018;entailment&#x02019;, &#x02018;neutral&#x02019; or &#x02018;contradict&#x02019;) of a given hypothesis without seeing the premise. The <italic toggle="yes">No-Question</italic> probe in our experiment is similar to the hypothesis-only model, which only provides models with multiple-choice answer-sets but without any associated prompt.</p><p>The choice-based perturbation function is designed to explore <italic toggle="yes">RQ2</italic>:</p><list list-type="bullet"><list-item><p><bold>No-Right-Answer probe</bold>: This probe retains the prompt and all <italic toggle="yes">incorrect</italic> choices in an instance, but replaces the correct choice with a choice from another instance&#x02019;s choice-set. The model is thus presented with a prompt but no correct choice in response to the prompt (among the presented choices). Note that, in the Wrong-Question probe, the candidate choices are completely unrelated to the corresponding prompt whereas in the No-Right-Answer probe, the non-substituted choices are often found to be semantically related to the prompt. For example, in <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>, the original prompt was regarding the Kendall-related context. Following the Wrong-Question intervention, the instance is given a new context and question, which are completely unrelated to the three original Kendall-related answers. In contrast, following the No-Right-Answer perturbation, the context and question remain the same, but the original choice is substituted. Semantically speaking, the substituted choice is less related to the prompt than the non-substituted (but still incorrect) choices. In the experiments, we substitute each instance&#x02019;s correct choice with a mismatched choice. Similar to the <italic toggle="yes">Wrong-Question</italic> replacement protocol, we randomly sample an instance and substitute the &#x02018;correct&#x02019; choice of the given instance with the correct choice of the randomly sampled instance. We conduct similar robustness checks (and also manual checks) as with the <italic toggle="yes">Wrong-Question</italic> protocol, but again found the results to be similar to that of the described protocol. Hence, only those results are reported. We also account for randomness through five experimental trials.</p></list-item></list><p>Earlier, all of these probes were visualized using an actual instance from the Social IQA benchmark in <xref rid="pone.0295925.g001" ref-type="fig">Fig 1</xref>. We have publicly made available both the original instances and the perturbed instances, which were obtained by applying the three probes [<xref rid="pone.0295925.ref063" ref-type="bibr">63</xref>]. In the results, we specifically investigate how the confidence distribution of the RoBERTa-based model statistically changes (and whether these changes are consistent across each benchmark) after each perturbation is applied. The confidence of an &#x02018;agnostic&#x02019; model that does not get confused by incorrect choices (even if they are non-trivially related to the prompt or to each other in their surface forms) after perturbation is expected to be randomly distributed, although it can be expected that the language models will prefer the semantically related, non-substituted wrong choices following application of the <italic toggle="yes">No-Right-Answer</italic> probe.</p></sec><sec id="sec008"><title>Metrics</title><p>We systematically investigate the change in confidence distribution of RoBERTa (for both research questions) using relatively simple and interpretable metrics. Recall that, in the <italic toggle="yes">Formalism</italic> section, we stated that an unperturbed instance <italic toggle="yes">I</italic> = (<italic toggle="yes">p</italic>, <italic toggle="yes">A</italic>) has exactly one correct choice <inline-formula id="pone.0295925.e012"><alternatives><graphic xlink:href="pone.0295925.e012.jpg" id="pone.0295925.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>&#x02208;</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, with the set of its incorrect choices denoted as <inline-formula id="pone.0295925.e013"><alternatives><graphic xlink:href="pone.0295925.e013.jpg" id="pone.0295925.e013g" position="anchor"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x02254;</mml:mo><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Given <italic toggle="yes">I</italic>, RoBERTa (or a similar such language model) can yield a confidence map <italic toggle="yes">C</italic> where a value <italic toggle="yes">c</italic><sub><italic toggle="yes">i</italic></sub> corresponds to the model&#x02019;s confidence for each candidate choice <italic toggle="yes">a</italic><sub><italic toggle="yes">i</italic></sub> &#x02208; <italic toggle="yes">A</italic>. We denote the confidence set of incorrect choices as <inline-formula id="pone.0295925.e014"><alternatives><graphic xlink:href="pone.0295925.e014.jpg" id="pone.0295925.e014g" position="anchor"/><mml:math id="M14" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. Generally speaking, for high-performing models like RoBERTa <inline-formula id="pone.0295925.e015"><alternatives><graphic xlink:href="pone.0295925.e015.jpg" id="pone.0295925.e015g" position="anchor"/><mml:math id="M15" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> tends to empirically follow a uniform distribution i.e., the model places relatively high confidence (at least on average) on the correct choice, and the rest of its confidence (since all confidence values must add to 1.0) tend to be distributed equally among the incorrect choices.</p><p>When <italic toggle="yes">I</italic> is perturbed by a probe <italic toggle="yes">P</italic>, at either the prompt or the choice level, RoBERTa will generally produce an &#x02018;updated&#x02019; confidence map given the perturbed instance <italic toggle="yes">I</italic><sub><italic toggle="yes">P</italic></sub>. We denote <inline-formula id="pone.0295925.e016"><alternatives><graphic xlink:href="pone.0295925.e016.jpg" id="pone.0295925.e016g" position="anchor"/><mml:math id="M16" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> as the set which contains the model&#x02019;s updated confidence for the original incorrect answers. Post-perturbation, our expectation of an &#x02018;agnostic&#x02019; model that does not get &#x02018;confused&#x02019; by the prompt or choices is that the confidence of the original incorrect answers <inline-formula id="pone.0295925.e017"><alternatives><graphic xlink:href="pone.0295925.e017.jpg" id="pone.0295925.e017g" position="anchor"/><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> should continue to be randomly distributed, even though the absolute values might now be different following the perturbation. We denote such a random confidence distribution of <inline-formula id="pone.0295925.e018"><alternatives><graphic xlink:href="pone.0295925.e018.jpg" id="pone.0295925.e018g" position="anchor"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:math></alternatives></inline-formula> as <inline-formula id="pone.0295925.e019"><alternatives><graphic xlink:href="pone.0295925.e019.jpg" id="pone.0295925.e019g" position="anchor"/><mml:math id="M19" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>.</p><p>By comparing (in aggregate) the confidence distribution of a perturbed instance <inline-formula id="pone.0295925.e020"><alternatives><graphic xlink:href="pone.0295925.e020.jpg" id="pone.0295925.e020g" position="anchor"/><mml:math id="M20" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> with that of its unperturbed equivalent <inline-formula id="pone.0295925.e021"><alternatives><graphic xlink:href="pone.0295925.e021.jpg" id="pone.0295925.e021g" position="anchor"/><mml:math id="M21" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, as well as that of a random distribution <inline-formula id="pone.0295925.e022"><alternatives><graphic xlink:href="pone.0295925.e022.jpg" id="pone.0295925.e022g" position="anchor"/><mml:math id="M22" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, we can categorize four types of post-perturbation shifts in the distribution. These shifts are discussed below. In all descriptions below, statistical significance (which always occurs between means of two distributions) is determined using a paired t-test test and at the 90% confidence level.</p><list list-type="order"><list-item><p><bold>Random-like shift</bold>: This shift is determined to occur if: (i) the mean of <inline-formula id="pone.0295925.e023"><alternatives><graphic xlink:href="pone.0295925.e023.jpg" id="pone.0295925.e023g" position="anchor"/><mml:math id="M23" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is found to be significantly different from the mean of the original confidence distribution <inline-formula id="pone.0295925.e024"><alternatives><graphic xlink:href="pone.0295925.e024.jpg" id="pone.0295925.e024g" position="anchor"/><mml:math id="M24" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, and (ii) the mean of <inline-formula id="pone.0295925.e025"><alternatives><graphic xlink:href="pone.0295925.e025.jpg" id="pone.0295925.e025g" position="anchor"/><mml:math id="M25" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is <italic toggle="yes">not</italic> found to be significantly different from the mean of <inline-formula id="pone.0295925.e026"><alternatives><graphic xlink:href="pone.0295925.e026.jpg" id="pone.0295925.e026g" position="anchor"/><mml:math id="M26" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. This kind of shift would be expected from the &#x02018;agnostic&#x02019; system after a perturbation because, even though the confidence distribution for the original incorrect answers has changed, the system still does not exhibit any explicit preference toward any of the original incorrect answers. We note here that these comparison are well-defined because they compare means over the confidences of the same choice-subset (the set of original incorrect choices).</p></list-item><list-item><p><bold>Hybrid shift</bold>: This shift is determined to occur if: (i) no significant difference is found between the mean of <inline-formula id="pone.0295925.e027"><alternatives><graphic xlink:href="pone.0295925.e027.jpg" id="pone.0295925.e027g" position="anchor"/><mml:math id="M27" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and the mean of <inline-formula id="pone.0295925.e028"><alternatives><graphic xlink:href="pone.0295925.e028.jpg" id="pone.0295925.e028g" position="anchor"/><mml:math id="M28" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, and (ii) no significant difference is also found between the mean of <inline-formula id="pone.0295925.e029"><alternatives><graphic xlink:href="pone.0295925.e029.jpg" id="pone.0295925.e029g" position="anchor"/><mml:math id="M29" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and the mean of its original distribution <inline-formula id="pone.0295925.e030"><alternatives><graphic xlink:href="pone.0295925.e030.jpg" id="pone.0295925.e030g" position="anchor"/><mml:math id="M30" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. This shift suggests that, even if the system has a slight preference for the correct answer in an unperturbed instance, the preference may be almost arbitrary and not statistically significant. When either the prompt or the choice-set is altered and the correct answer is no longer correct, <inline-formula id="pone.0295925.e031"><alternatives><graphic xlink:href="pone.0295925.e031.jpg" id="pone.0295925.e031g" position="anchor"/><mml:math id="M31" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> tends to be randomly distributed but is still similar to its original distribution <inline-formula id="pone.0295925.e032"><alternatives><graphic xlink:href="pone.0295925.e032.jpg" id="pone.0295925.e032g" position="anchor"/><mml:math id="M32" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>.</p></list-item><list-item><p><bold>Conservative shift</bold>: This shift is determined to occur if: (i) the mean of <inline-formula id="pone.0295925.e033"><alternatives><graphic xlink:href="pone.0295925.e033.jpg" id="pone.0295925.e033g" position="anchor"/><mml:math id="M33" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is found to be significantly different from the mean of random distribution <inline-formula id="pone.0295925.e034"><alternatives><graphic xlink:href="pone.0295925.e034.jpg" id="pone.0295925.e034g" position="anchor"/><mml:math id="M34" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, and (ii) no significant difference is found between <inline-formula id="pone.0295925.e035"><alternatives><graphic xlink:href="pone.0295925.e035.jpg" id="pone.0295925.e035g" position="anchor"/><mml:math id="M35" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and the original confidence distribution <inline-formula id="pone.0295925.e036"><alternatives><graphic xlink:href="pone.0295925.e036.jpg" id="pone.0295925.e036g" position="anchor"/><mml:math id="M36" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. Such a change in the confidence distribution suggests that, while the model&#x02019;s confidence may be slightly impacted by the perturbation, its performance remains consistent with that of the original, unperturbed instances. The comparable confidence distribution observed for the same set of incorrect answers even following the perturbation may indicate the presence of a <italic toggle="yes">prior bias</italic>, perhaps learned during either the pre-training phase of the system, or from subtle patterns in the training partition of the benchmark on which it was fine-tuned).</p></list-item><list-item><p><bold>Deviated shift</bold>: This shift is determined to occur if: (i) the mean of <inline-formula id="pone.0295925.e037"><alternatives><graphic xlink:href="pone.0295925.e037.jpg" id="pone.0295925.e037g" position="anchor"/><mml:math id="M37" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is found to be significantly different from the mean of the original confidence distribution <inline-formula id="pone.0295925.e038"><alternatives><graphic xlink:href="pone.0295925.e038.jpg" id="pone.0295925.e038g" position="anchor"/><mml:math id="M38" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, and (ii) the mean of <inline-formula id="pone.0295925.e039"><alternatives><graphic xlink:href="pone.0295925.e039.jpg" id="pone.0295925.e039g" position="anchor"/><mml:math id="M39" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is also found to be significantly different from the mean of the random distribution <inline-formula id="pone.0295925.e040"><alternatives><graphic xlink:href="pone.0295925.e040.jpg" id="pone.0295925.e040g" position="anchor"/><mml:math id="M40" display="inline" overflow="scroll"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. <italic toggle="yes">A priori</italic>, we expect that instances perturbed by the <italic toggle="yes">No-Right-Answer</italic> probe exhibit such behavior because the non-substituted (or original) incorrect answers tend to have higher &#x02018;surface&#x02019; (semantic) similarity to the prompt because of the way in which such benchmarks were originally constructed (with the goal of making the questions more challenging to answer than would be the case if obviously wrong or unrelated choices had been provided as candidates, along with the correct choice).</p></list-item></list><p>We keep track of the prevalence of these four types of shifts in instances perturbed by the different probes to empirically investigate both RQs. An additional metric for prompt-based perturbations (RQ1) that we report is the <italic toggle="yes">pseudo-accuracy</italic>, which we define as the fraction of instances in the held-out set where the model ended up selecting the <italic toggle="yes">pseudo-correct</italic> choice (even though it is not correct anymore) to measure the &#x02018;performance&#x02019; of the system on instances perturbed specifically by the prompt-based perturbations. Note that the pseudo-correct choice can only be selected by the model if that choice had the highest confidence among all the choices. Similarly, to further contextualize RQ2, we report additional statistics measurements of RoBERTa&#x02019;s confidence distribution, including the <italic toggle="yes">variance</italic> of confidences in perturbed instances. These measurements are expected to provide additional insights on how the system responds to choice-based perturbations. Such an analysis may lead to more nuanced understanding of the system&#x02019;s behavior when such situations arise.</p></sec></sec><sec sec-type="results" id="sec009"><title>Results</title><sec id="sec010"><title>RQ1: Changes in RoBERTa&#x02019;s confidence distribution for prompt-based perturbations</title><sec id="sec011"><title>No-Question probe</title><p>In <xref rid="pone.0295925.t001" ref-type="table">Table 1</xref>, we report the counts of different shifts in the instances when the <italic toggle="yes">No-Question</italic> probe was applied i.e., the prompt was replaced with an empty string. If the model was equally indifferent between all (incorrect) choices, <italic toggle="yes">random-like</italic> shift counts would dominate the others. In other words, a system that is truly agnostic would sample a choice (at least on average) from the uniform probability distribution over all the available choices when the prompt is the empty string. However, the results show that the random-like shift is rarely observed in either one of the two benchmarks. We find fewer than 200 such instances in both Social IQA and HellaSwag dataset.</p><table-wrap position="float" id="pone.0295925.t001"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.t001</object-id><label>Table 1</label><caption><title>The occurrences (absolute counts / percentage of total instances) of the four different confidence shifts observed in RoBERTa responses when confronted with instances following application of the <italic toggle="yes">No-Question</italic> perturbation.</title></caption><alternatives><graphic xlink:href="pone.0295925.t001" id="pone.0295925.t001g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Random-like</th><th align="left" rowspan="1" colspan="1">Hybrid</th><th align="left" rowspan="1" colspan="1">Conservative</th><th align="left" rowspan="1" colspan="1">Deviated</th><th align="left" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">HellaSwag</td><td align="left" rowspan="1" colspan="1">181 / 1.8%</td><td align="left" rowspan="1" colspan="1">4,828 / 48.2%</td><td align="left" rowspan="1" colspan="1">4,749 / 47.4%</td><td align="left" rowspan="1" colspan="1">254 / 2.5%</td><td align="left" rowspan="1" colspan="1">10,012 / 100%</td></tr><tr><td align="left" rowspan="1" colspan="1">SociaIQA</td><td align="left" rowspan="1" colspan="1">147 / 7.9%</td><td align="left" rowspan="1" colspan="1">1,473 / 78.7%</td><td align="left" rowspan="1" colspan="1">196 / 10.5%</td><td align="left" rowspan="1" colspan="1">56 / 3.0%</td><td align="left" rowspan="1" colspan="1">1,872 / 100%</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p>Descriptions of these confidence shifts were described earlier in the <italic toggle="yes">Metrics</italic> section. The number of instances in the last column is the size of the held-out set, because the different shifts form a partition, by definition).</p></fn></table-wrap-foot></table-wrap><p>We also expect a robust system to have a clear preference for the actual correct answer, in which case there should be a significant difference between the mean confidence of original incorrect choices before and after perturbation. Recall that the confidence of all candidate answers per instance sums to 1. In the original instance (before removing the prompt), the confidence of the actual correct answer yielded by the system should be higher than the reciprocal of the number of candidate choices (which would be expected from a system that is randomly selecting choices, even though there is a correct choice). For the same reason, the mean confidence of the original incorrect choices would then be observed to be <italic toggle="yes">lower</italic> than the reciprocal of the number of candidate choices. If the mean confidence of the incorrect choices following perturbation indeed follows this expectation, it would be significantly different from the mean confidence of these choices prior to perturbation. However, the results in <xref rid="pone.0295925.t001" ref-type="table">Table 1</xref> show that the model does not fulfill this expectation.</p><p>The occurrence of other shifts seems to depend on the benchmark, although the hybrid shift is fairly dominant in both benchmarks. This implies that, when the original incorrect choices are processed by the model after the prompt is removed, the confidence distribution does resemble a random distribution; however, the mean value is not significantly different from the reciprocal of the number of candidate choices. We find 1,473 (out of 1,872) such instances in Social IQA. For HellaSwag, RoBERTa is observed to exhibit similar amounts of <italic toggle="yes">hybrid</italic> (4,828 out of 10,012) and <italic toggle="yes">conservative</italic> (4,749 out of 10,012) shift. The results suggest that RoBERTa is more likely to randomly choose an option for the SocialIQA benchmark after the prompt is removed, compared to HellaSwag.</p><p>While the original accuracy of the RoBERTa model used in this paper was reported to be over 80% on both Social IQA and HellaSwag (a result that we also replicated), the pseudo-accuracy data in <xref rid="pone.0295925.t002" ref-type="table">Table 2</xref> shows that the model may be affected by some type of dataset bias either in the pre-training data, or training partition used for fine-tuning. Clearly, the original &#x02018;correct&#x02019; or pseudo-correct choice is statistically distinguishable even without the prompts. We find no significant difference between the mean confidence of incorrect choices before and after perturbation for 89.2% Social IQA instances and 95.7% HellaSwag instances. In the absence of the prompts, the confidence distribution of incorrect choices is shown not to be significantly different from that before perturbation. Put together, while the prompts are instructive, when RoBERTa does not see them, it may still yield similar but near-random confidence distributions for the original incorrect choices based on what it learned during pre-training.</p><table-wrap position="float" id="pone.0295925.t002"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.t002</object-id><label>Table 2</label><caption><title>The <italic toggle="yes">pseudo-accuracy</italic> results following each of the two prompt-based perturbations relevant for RQ1.</title></caption><alternatives><graphic xlink:href="pone.0295925.t002" id="pone.0295925.t002g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Dataset</th><th align="left" rowspan="1" colspan="1">Agnostic pseudo-accuracy</th><th align="left" rowspan="1" colspan="1">No-Question pseudo-accuracy (+/- std. err.)</th><th align="left" rowspan="1" colspan="1">Wrong-Question pseudo-accuracy (+/- std. err.)</th><th align="left" rowspan="1" colspan="1">Average confidence difference</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">HellaSwag</td><td align="char" char="." rowspan="1" colspan="1">0.25</td><td align="left" rowspan="1" colspan="1">0.66 (+/- 0.004)</td><td align="left" rowspan="1" colspan="1">0.61 (+/- 0.005)</td><td align="char" char="." rowspan="1" colspan="1">0.060</td></tr><tr><td align="left" rowspan="1" colspan="1">SocialIQA</td><td align="char" char="." rowspan="1" colspan="1">0.33</td><td align="left" rowspan="1" colspan="1">0.46 (+/- 0.011)</td><td align="left" rowspan="1" colspan="1">0.40 (+/- 0.011)</td><td align="char" char="." rowspan="1" colspan="1">0.022</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t002fn001"><p>For both prompt-based perturbations, the observed pseudo-accuracy is significantly higher than what should be expected for an agnostic system that is equally indifferent to all incorrect answers following perturbation.</p></fn></table-wrap-foot></table-wrap><p>The pseudo-accuracy results of RoBERTa (using the &#x02018;pseudo-correct&#x02019; choice as the correct label for accuracy calculations, as discussed earlier) for instances perturbed by the No-Question probe are shown in the third column of <xref rid="pone.0295925.t002" ref-type="table">Table 2</xref>. For reference, we show in Column 2 the &#x02018;agnostic&#x02019; pseudo-accuracy, which by definition, equals the reciprocal of the (benchmark-specific) number of choices per instance as it is equally indifferent to all incorrect answers. The table shows that RoBERTa achieves a high pseudo-accuracy on post-perturbation HellaSwag instances, and closer-to-ideal pseudo-accuracy on Social IQA. The standard error on Social IQA is higher than on HellaSwag, which is a direct consequence of the confidence of pseudo-correct options on Social IQA being more variable (than HellaSwag). Therefore, on HellaSwag the model is clearly more susceptible to dataset bias.</p><p>On the other hand, the model does show a marked decrease in pseudo-accuracy on the HellaSwag and Social IQA benchmarks, compared to the original pre-perturbation accuracy. This implies that the prompt plays an important role when present, and the model is using it for answering questions prior to perturbation. However, the results following perturbation also shows that the model does not &#x02018;need&#x02019; the prompt for selecting the originally correct (but now incorrect) answer. This should be an obvious source of concern for common sense evaluations conducting using such benchmarks and models (which is the predominant form of such evaluations in the machine common sense community, as discussed earlier in <italic toggle="yes">Related Work</italic>).</p><p>In all cases, the pseudo-accuracy results are significantly different, at a 99 percent confidence level or higher, compared to both the agnostic pseudo-accuracy and the pre-perturbation (or actual) accuracy. The latter is encouraging, but expected, and supports the intuition that the prompt <italic toggle="yes">matters</italic> for the model but the former suggests that it matters less than it should, which future evaluators must bear in mind when interpreting the reasoning capabilities of such models.</p></sec><sec id="sec012"><title>Wrong-Question probe</title><p>We tabulate the changes in RoBERTa&#x02019;s confidence distribution following the application of the <italic toggle="yes">Wrong-Question</italic> probe in <xref rid="pone.0295925.t003" ref-type="table">Table 3</xref>. Consistent with the findings in <xref rid="pone.0295925.t001" ref-type="table">Table 1</xref>, the occurrence of all shifts other than <italic toggle="yes">Hybrid</italic> depends on the benchmark, whereas the hybrid shift is still fairly dominant in both benchmarks, and is observed in more than half of the instances after applying the perturbation. The results suggest that the mean confidence of the incorrect choices for most instances after applying the perturbation is not significantly different from the reciprocal of the (benchmark-specific) number of choices per instance. Although we still observe few occurrences of the agnostic <italic toggle="yes">random-like</italic> shift in both HellaSwag and Social IQA, there are slightly more <italic toggle="yes">random-like</italic> shifts (254 out of 10,012) and fewer <italic toggle="yes">conservative</italic> shifts (3,915 out of 10,012) in HellaSwag, compared to the <italic toggle="yes">No-Question</italic> perturbation.</p><table-wrap position="float" id="pone.0295925.t003"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.t003</object-id><label>Table 3</label><caption><title>The occurrences (absolute counts / percentage of total instances) of the four different confidence shifts observed in RoBERTa responses when confronted with instances following application of the Wrong-Question perturbation.</title></caption><alternatives><graphic xlink:href="pone.0295925.t003" id="pone.0295925.t003g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Random-like</th><th align="left" rowspan="1" colspan="1">Hybrid</th><th align="left" rowspan="1" colspan="1">Conservative</th><th align="left" rowspan="1" colspan="1">Deviated</th><th align="left" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">HellaSwag</td><td align="left" rowspan="1" colspan="1">254 / 2.5%</td><td align="left" rowspan="1" colspan="1">5,466 / 54.6%</td><td align="left" rowspan="1" colspan="1">3,915 / 39.1%</td><td align="left" rowspan="1" colspan="1">377 / 3.8%</td><td align="left" rowspan="1" colspan="1">10,012 / 100%</td></tr><tr><td align="left" rowspan="1" colspan="1">SociaIQA</td><td align="left" rowspan="1" colspan="1">112 / 6.0%</td><td align="left" rowspan="1" colspan="1">1,471 / 78.6%</td><td align="left" rowspan="1" colspan="1">233 / 12.4%</td><td align="left" rowspan="1" colspan="1">56 / 3.0%</td><td align="left" rowspan="1" colspan="1">1,872 / 100%</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t003fn001"><p>Descriptions of confidence shifts are provided in the <italic toggle="yes">Metrics</italic> section.</p></fn></table-wrap-foot></table-wrap><p>The pseudo-accuracy of RoBERTa on the <italic toggle="yes">Wrong-Question</italic> perturbed instances (in Column 4 in <xref rid="pone.0295925.t002" ref-type="table">Table 2</xref>) is similar to that observed for the <italic toggle="yes">No-Question</italic> perturbed instances (in Column 3), and more aligned to the agnostic performance (in Column 2). Additionally, the average confidence difference between the two probes (Column 5 in <xref rid="pone.0295925.t002" ref-type="table">Table 2</xref>) for each benchmark is not only positive, but also significantly greater than 0 with at least 99 percent confidence. The result implies that the appearance of the wrong prompt introduces more &#x02018;doubt&#x02019; into the model concerning the pseudo-correct choice compared to when the prompt is removed altogether.</p><p>We note that the pseudo-accuracy on HellaSwag is still far from the agnostic random performance compared to Social IQA. Therefore, the assumption, commonly made by practitioners using the model, that it needs to be presented with an actually correct option is a powerful one that should not be underestimated. When the options are all incorrect (or sufficiently ambiguous), the model does <italic toggle="yes">not</italic> just randomly or uniformly pick one out as its choice. In other words, there is evidence of dataset bias, which is consistent with the results from the previous section.</p></sec></sec><sec id="sec013"><title>RQ2: Changes in RoBERTa&#x02019;s confidence distribution for the choice-based perturbation</title><p>In investigating RQ2, our initial expectation of the changes in RoBERTa&#x02019;s confidence distribution on the <italic toggle="yes">No-Right-Answer</italic>-perturbed instances is similar to that on the prompt-based perturbed instances (RQ1). Specifically, we anticipate a <italic toggle="yes">random-like</italic> shift in RoBERTa&#x02019;s confidence distribution on the perturbed instances, resulting in a nearly uniform probability distribution of original incorrect candidate choices. However, considering the semantic relationship between candidate choices and their corresponding prompt, it appears that the unsubstituted, original incorrect choices were superficially more relevant to the corresponding prompt than the substituted incorrect choice, even though they are all incorrect. Hence, it is possible that the <italic toggle="yes">deviated</italic> shift in RoBERTa&#x02019;s confidence distribution increases following the <italic toggle="yes">No-Right-Answer</italic> perturbation.</p><p>
<xref rid="pone.0295925.t004" ref-type="table">Table 4</xref> reports the counts of different shifts in the instances after applying the <italic toggle="yes">No-Right-Answer</italic> probe. The results suggest that RoBERTa exhibited a greater number of random-like shifts when the <italic toggle="yes">No-Right-Answer</italic> probe was applied, compared to the prompt-based perturbations, but the extent of this increase may vary depending on the benchmark. For example, on Hellaswag, RoBERTa showed twice as many random-like shifts on the <italic toggle="yes">No-Right-Answer</italic> perturbed instances as compared to the <italic toggle="yes">Wrong-Question</italic> perturbed instances; while on Social IQA, there is only a slight 0.4% increase in the counts of random-like shifts. Besides, the hybrid shift remained dominant in both benchmarks. RoBERTa exhibited the hybrid shift on 82.2% of the instances after applying the <italic toggle="yes">No-Right-Answer</italic> perturbation. This also led to a decrease in the frequency of conservative shifts, indicating that the confidence distribution of RoBERTa becomes closer to a random distribution following the perturbation.</p><table-wrap position="float" id="pone.0295925.t004"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.t004</object-id><label>Table 4</label><caption><title>The occurrences (absolute counts / percentage of total instances) of the four different confidence shifts observed in RoBERTa responses when confronted with instances following application of the No-Right-Answer perturbation.</title></caption><alternatives><graphic xlink:href="pone.0295925.t004" id="pone.0295925.t004g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Random-like</th><th align="left" rowspan="1" colspan="1">Hybrid</th><th align="left" rowspan="1" colspan="1">Conservative</th><th align="left" rowspan="1" colspan="1">Deviated</th><th align="left" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">HellaSwag</td><td align="left" rowspan="1" colspan="1">571 / 5.7%</td><td align="left" rowspan="1" colspan="1">8,233 / 82.2%</td><td align="left" rowspan="1" colspan="1">1,047 / 10.5%</td><td align="left" rowspan="1" colspan="1">171 / 1.7%</td><td align="left" rowspan="1" colspan="1">10,012 / 100%</td></tr><tr><td align="left" rowspan="1" colspan="1">SociaIQA</td><td align="left" rowspan="1" colspan="1">121 / 6.4%</td><td align="left" rowspan="1" colspan="1">1,671 / 89.3%</td><td align="left" rowspan="1" colspan="1">59 / 3.2%</td><td align="left" rowspan="1" colspan="1">21 / 1.1%</td><td align="left" rowspan="1" colspan="1">1,872 / 100%</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t004fn001"><p>Descriptions of confidence shifts are described in the <italic toggle="yes">Metrics</italic> section.</p></fn></table-wrap-foot></table-wrap><p>In <xref rid="pone.0295925.t005" ref-type="table">Table 5</xref>, we tabulate the confidence variance among all candidate choices, and the mean confidence of correct (or pseudo-correct) answers yielded by RoBERTa before and after applying the <italic toggle="yes">No-Right-Answer</italic> perturbation. If the system were agnostic, we would expect that the mean confidence variances of candidate choices in the original instances will be substantially higher than that in perturbed instances (which would be close to zero if the system had agnostic performance). Meanwhile, the mean confidence of the correct answer before perturbation should be significantly higher than the reciprocal of the number of candidate choices, while the mean confidence of the substituted pseudo-correct answer should be close to or lower than the reciprocal.</p><table-wrap position="float" id="pone.0295925.t005"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.t005</object-id><label>Table 5</label><caption><title>A statistical summary of confidence variances observed across candidate choices, on average, before and after the <italic toggle="yes">No-Right-Answer</italic> perturbation was applied.</title><p>
<inline-formula id="pone.0295925.e041">
<alternatives><graphic xlink:href="pone.0295925.e041" id="pone.0295925.e041g" position="anchor"/><mml:math id="M41" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>&#x003c3;</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub></mml:math></alternatives>
</inline-formula> and <inline-formula id="pone.0295925.e042"><alternatives><graphic xlink:href="pone.0295925.e042" id="pone.0295925.e042g" position="anchor"/><mml:math id="M42" display="inline" overflow="scroll"><mml:msubsup><mml:mover accent="true"><mml:mi>&#x003c3;</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>c</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> represent the mean of the variances of confidence in instances before and after perturbation, respectively. The means of <inline-formula id="pone.0295925.e043"><alternatives><graphic xlink:href="pone.0295925.e043" id="pone.0295925.e043g" position="anchor"/><mml:math id="M43" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0295925.e044"><alternatives><graphic xlink:href="pone.0295925.e044" id="pone.0295925.e044g" position="anchor"/><mml:math id="M44" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> represent the mean confidence of correct (or pseudo-correct) answers yielded by RoBERTa before and after perturbation, respectively.</p></caption><alternatives><graphic xlink:href="pone.0295925.t005" id="pone.0295925.t005g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Benchmark</th><th align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0295925.e045">
<alternatives><graphic xlink:href="pone.0295925.e045" id="pone.0295925.e045g" position="anchor"/><mml:math id="M45" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>&#x003c3;</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub></mml:math></alternatives>
</inline-formula>
</th><th align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0295925.e046">
<alternatives><graphic xlink:href="pone.0295925.e046" id="pone.0295925.e046g" position="anchor"/><mml:math id="M46" display="inline" overflow="scroll"><mml:msubsup><mml:mover accent="true"><mml:mi>&#x003c3;</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>c</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msubsup></mml:math></alternatives>
</inline-formula>
</th><th align="center" rowspan="1" colspan="1">Mean <inline-formula id="pone.0295925.e047"><alternatives><graphic xlink:href="pone.0295925.e047" id="pone.0295925.e047g" position="anchor"/><mml:math id="M47" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula></th><th align="center" rowspan="1" colspan="1">Mean <inline-formula id="pone.0295925.e048"><alternatives><graphic xlink:href="pone.0295925.e048" id="pone.0295925.e048g" position="anchor"/><mml:math id="M48" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Hellaswag</td><td align="char" char="." rowspan="1" colspan="1">0.36</td><td align="char" char="." rowspan="1" colspan="1">0.31</td><td align="char" char="." rowspan="1" colspan="1">0.78</td><td align="char" char="." rowspan="1" colspan="1">0.20</td></tr><tr><td align="left" rowspan="1" colspan="1">SocialIQA</td><td align="char" char="." rowspan="1" colspan="1">0.33</td><td align="char" char="." rowspan="1" colspan="1">0.30</td><td align="char" char="." rowspan="1" colspan="1">0.69</td><td align="char" char="." rowspan="1" colspan="1">0.17</td></tr></tbody></table></alternatives></table-wrap><p>
<xref rid="pone.0295925.t005" ref-type="table">Table 5</xref> indicates that the confidence variance (in Column 2) of candidate choices yielded by RoBERTa before perturbation is much higher than zero, implying that it is not equally agnostic to all incorrect choices. Meanwhile, RoBERTa attains close to, or even higher than, 0.7 confidence with respect to the correct answers before perturbation (in Column 4). After applying the <italic toggle="yes">No-Right-Answer</italic> perturbation, RoBERTa is observed to have a similar confidence variance of all candidate choices (in Column 3), while the confidence of the substituted choice (in Column 5) is far below the agnostic performance. The changes in the confidence distribution suggest that the confidence of the correct answer prior to perturbation primarily &#x02018;shifts&#x02019; towards one of the unsubstituted incorrect choices that may have the highest surface semantic similarity to the prompt. Perhaps the most interesting qualitative takeaway from the results is that surface similarity between the prompt and choice can clearly matter a lot, even when the choice is incorrect. For difficult questions or particularly creative (but still correct) answers to such questions, such bias may prove to be problematic.</p></sec></sec><sec sec-type="conclusions" id="sec014"><title>Discussion</title><p>While the results described in the previous section clearly indicate the non-arbitrary changes induced by the perturbation functions in the RoBERTa-based model&#x02019;s confidence distribution, they do not shed much light on the potential <italic toggle="yes">causes</italic> of these phenomena. For example, is fine-tuning a major driver of the changes that we do observe? In this section, we first provide a discussion using auxiliary analyses to see if syntactic properties or &#x02018;irregularities&#x02019; in the benchmarks themselves may have contributed to the phenomena. However, there may also be other possible impacts, such as the fine-tuning process of RoBERTa (or other similar transformer-based architectures).</p><p>Meanwhile, it remains uncertain whether a system such as RoBERTa can be trained to detect the ambiguity effectively. In other words, it is necessary to determine if the system can already recognize the perturbed instances as &#x02018;difficult&#x02019; or &#x02018;ambiguous&#x02019; cases (to refuse to answer) based on the confidence distribution, or if there is still a need to develop a system to allow the system to do this. Hence, in the second part of the Discussion section, we employ MaxProb [<xref rid="pone.0295925.ref064" ref-type="bibr">64</xref>&#x02013;<xref rid="pone.0295925.ref066" ref-type="bibr">66</xref>], a popular calibration technique that has been used to investigate the capability of models to detect uncertainty in previous research, to explore whether the changes in confidence distribution induced by the perturbations can be easily detected by the system.</p><p>Moreover, while our study has primarily focused on the RoBERTa-based model, it is important to consider the potential generalizability of our findings to other cutting-edge language models, especially high-performing generative models within the GPT family. Despite variations in specific architectural designs and training methodologies between RoBERTa and GPT models, they share fundamental similarities as large-scale transformer-based models. To deepen our insights into the confidence shift phenomenon in transformer-based language models, we also explore, in the latter part of the Discussion section, whether GPT-3.5-Turbo exhibits comparable confidence shifts when exposed to diverse perturbations.</p><sec id="sec015"><title>Analysis of irregularities in benchmarks</title><p>As mentioned, it is possible that the specific benchmarks (or the training sets thereof) used to fine-tune the model led to the observed changes in confidence distribution; hence, we begin by conducting an &#x02018;analysis of irregularities&#x02019; whereby we assess the (possibly unusual) prevalence of label imbalance, the distribution of prompt-lengths, and the words-overlap between the prompt and the candidate answers, to include or exclude such phenomena as being indirectly responsible for some of the statistics we observed in the previous section.</p><p>Specifically, the label imbalance analysis aims at testing whether the <italic toggle="yes">first</italic> listed choice is labeled in a benchmark&#x02019;s held-out set as correct with a higher-than-random probability. Statistically, we found that the labels tended to be evenly distributed in both benchmarks&#x02019; held-out sets, and hence, there is no label imbalance or &#x02018;choice ordering&#x02019; bias of any kind. In the three-option Social IQA benchmark, 33.4% and 33.6% of the instances are labeled with &#x02018;answerA&#x02019; and &#x02018;answerB&#x02019; as the correct answer, respectively, which again suggests near-random label distribution of answers A, B and C. Similarly, in the four-option HellaSwag, the frequencies of the four options labeled as the correct answers are 25% (each).</p><p>Similarly, we also calculated the average <italic toggle="yes">prompt lengths</italic> (in terms of the number of words) in the two sets comprising the selected and non-selected candidate choices (by the RoBERTa-based system) to determine if there is some kind of a length bias. While we did find that the selected choices tended to be longer than the non-selected choices over all benchmarks, the difference was slight and not statistically significant. For example, in Social IQA, the average length of selected candidate answer is 3.72 words, (with 95% confidence interval of [3.62, 3.82]), while the average length of non-selected candidate answers is 3.69 words. This difference is not significant at the 95% confidence level.</p><p>Finally, we analyzed the words-overlap between the candidate choices and the prompt, by grouping all candidate choices into two sets (selected and non-selected), similar to the grouping employed in the analysis above. We found that most of the overlapping words between the prompts and choices (in either set) were <italic toggle="yes">stop-words</italic>. Indeed, when we calculated the Pearson&#x02019;s correlation between the word frequency distributions over the selected and non-selected sets, the correlation was found to be close to 1.0. Social IQA achieved the lowest correlation value (0.982) between the two sets, while HellaSwag achieved the highest value (0.997).</p><p>Taken together, these results suggest that surface irregularities in benchmarks likely cannot serve as an explanation for the experimental results. While a full causal analysis is difficult to conduct experimentally without a larger set of controls (comprising both carefully constructed benchmarks and a broader range of perturbation functions and confusion probes), at least one potential cause could be the <italic toggle="yes">hidden</italic> patterns in the datasets used for fine-tuning. For example, some researchers have found that &#x02018;annotation artifacts&#x02019; [<xref rid="pone.0295925.ref061" ref-type="bibr">61</xref>] can be introduced unintentionally by crowd workers constructing the benchmark (by devising hypotheses and candidate choices). Another hypothetical cause is that models may have picked up the bias during pre-training (e.g., due to increased frequency of some terms). A complete analysis of these hypothetical causes for the systematic changes in confidence distribution that we observed is left for future research.</p></sec><sec id="sec016"><title>Can RoBERTa&#x02019;s confidence distribution be used to &#x02018;automatically&#x02019; detect perturbation?</title><p>Given the observed results, the question arises as to whether we can semi-automatically detect perturbations and ambiguities in multiple-choice instances (or RoBERTa&#x02019;s response to it) by automatically classifying or &#x02018;calibrating&#x02019; the confidence distribution. Ideally, such a technique would be able to calibrate the original confidence distribution to yield a new distribution that there is more reflective of the model&#x02019;s uncertainty in the responses. There is some precedent for such calibration in the literature. For instance, MaxProb [<xref rid="pone.0295925.ref064" ref-type="bibr">64</xref>&#x02013;<xref rid="pone.0295925.ref066" ref-type="bibr">66</xref>] has been utilized as an effective calibration technique to detect uncertainty in neural network models. It does so by using the probability assigned by the underlying multiple-choice NLI system to the most likely prediction (i.e., highest probability) among the candidate choices. Previously, MaxProb was found to give good confidence estimates on multiple-choice benchmarks. Here, we use MaxProb to assess whether the system can distinguish <italic toggle="yes">between</italic> perturbed and unperturbed instances on its own, given the corresponding confidence distribution by RoBERTa. If MaxProb can make such a distinction, then it opens the door to other possibilities in a full decision-making architecture (e.g., the overall system may abstain from answering if it determines that an instance is perturbed, or resembles a perturbed instance sufficiently strongly).</p><p>To train MaxProb, we first (randomly) split the instances in the held-out set in half. We then perturb these instances using one of the three perturbation functions presented earlier, and use both the original and perturbed instances as a &#x02018;binary&#x02019; training set for MaxProb. Specifically, the average MaxProb (as defined above) over this set is treated as a threshold. As in prior usage of the method, when the MaxProb of an instance is higher than the learned threshold, the instance is predicted as the original (i.e., non-perturbed) instance. Otherwise, it is considered to be perturbed. The accuracy of MaxProb is defined as the proportion of instances correctly predicted (as perturbed or unperturbed). For evaluation, we use the other half of the held-out set, using the same methodology as we used for the training set (i.e., all instances in the set are first perturbed using the same probe as used for training, followed by &#x02018;adding&#x02019; these perturbed instances back to the original unperturbed set to create an equally balanced mixture of perturbed and unperturbed instances). By construction, the random accuracy is 50 percent.</p><p>
<xref rid="pone.0295925.t006" ref-type="table">Table 6</xref> shows both the per-benchmark learned thresholds using the three different confusion probes, as well as the corresponding accuracy achieved by MaxProb. Social IQA had the lowest thresholds (among all benchmarks) on all three confusion probes; however, its average learned MaxProb threshold is still 0.7 or higher. Note that RoBERTa should be equally confident about each of its candidate choices on a perturbed instance. Hence, agnostically, the MaxProb on a given benchmark should be the reciprocal of the number of candidate choices (per instance, in that benchmark). Because of the high threshold, MaxProb should help RoBERTa more easily abstain from answering post-intervention instances. However, when we used MaxProb to distinguish perturbed instances in the evaluation set, we found its accuracy to only be slightly higher than random in most cases.</p><table-wrap position="float" id="pone.0295925.t006"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.t006</object-id><label>Table 6</label><caption><title>The learned MaxProb thresholds of different confusion probes on both benchmarks.</title></caption><alternatives><graphic xlink:href="pone.0295925.t006" id="pone.0295925.t006g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="right" rowspan="1" colspan="1"/><th align="right" rowspan="1" colspan="1">No-Question</th><th align="right" rowspan="1" colspan="1">Wrong-Question</th><th align="right" rowspan="1" colspan="1">No-Right-Answer</th></tr></thead><tbody><tr><td align="right" rowspan="1" colspan="1">HellaSwag</td><td align="right" rowspan="1" colspan="1">0.82 (0.58)</td><td align="right" rowspan="1" colspan="1">0.8 (0.61)</td><td align="right" rowspan="1" colspan="1">0.8 (0.62)</td></tr><tr><td align="right" rowspan="1" colspan="1">SocialIQA</td><td align="right" rowspan="1" colspan="1">0.70 (0.70)</td><td align="right" rowspan="1" colspan="1">0.74 (0.60)</td><td align="right" rowspan="1" colspan="1">0.76 (0.55)</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t006fn001"><p>The accuracy of MaxProb to distinguish pre- and post-intervention instances in each evaluation set is shown in brackets. For reference, the random accuracy would be 50% or 0.5 in all cases.</p></fn></table-wrap-foot></table-wrap><p>The evidence also suggests that the <italic toggle="yes">No-Right-Answer</italic> instances are the hardest cases for MaxProb, with the <italic toggle="yes">Wrong-Question</italic> instances being the easiest. Hence, not all perturbations are equally difficult for a calibration method. Finally, it bears noting that, while we have exclusively explored the use of MaxProb in these additional experiments, some other selective prediction (or calibration) methods have been proposed more recently [<xref rid="pone.0295925.ref065" ref-type="bibr">65</xref>, <xref rid="pone.0295925.ref066" ref-type="bibr">66</xref>], and further investigation is warranted as future research to determine the relative effectiveness of these different methods in addressing the ambiguity issue in NLP tasks.</p></sec><sec id="sec017"><title>Additional experiments using GPT-3.5-Turbo</title><p>For these additional experiments, we begin by randomly selecting 200 instances from the HellaSwag and SocialIQA held-out sets, respectively. We then applied three proposed perturbations to these instances. For each instance, we presented GPT-3.5-Turbo with both the original unperturbed version and the perturbed version, capturing the model&#x02019;s predictions and the corresponding confidence scores for each candidate answer. <xref rid="pone.0295925.t007" ref-type="table">Table 7</xref> reports how GPT-3.5 Turbo&#x02019;s confidence changes when exposed to these prompt-based and choice-based perturbations.</p><table-wrap position="float" id="pone.0295925.t007"><object-id pub-id-type="doi">10.1371/journal.pone.0295925.t007</object-id><label>Table 7</label><caption><title>The occurrences (absolute counts / percentage of total instances) of the four different confidence shifts observed in GPT-3.5 Turbo&#x02019;s responses when confronted with instances perturbed by three perturbations.</title></caption><alternatives><graphic xlink:href="pone.0295925.t007" id="pone.0295925.t007g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1"><italic toggle="yes">Pertub</italic>.</th><th align="left" rowspan="1" colspan="1">Random-like</th><th align="left" rowspan="1" colspan="1">Hybrid</th><th align="left" rowspan="1" colspan="1">Conservative</th><th align="left" rowspan="1" colspan="1">Deviated</th><th align="left" rowspan="1" colspan="1">Total</th></tr></thead><tbody><tr><td align="center" rowspan="3" colspan="1">HellaSwag</td><td align="left" rowspan="1" colspan="1">NQ</td><td align="left" rowspan="1" colspan="1">1 / 0.5%</td><td align="left" rowspan="1" colspan="1">84 / 42.0%</td><td align="left" rowspan="1" colspan="1">4 / 2.0%</td><td align="left" rowspan="1" colspan="1">3 / 1.5%</td><td align="left" rowspan="1" colspan="1">92 / 46.0%</td></tr><tr><td align="left" rowspan="1" colspan="1">WQ</td><td align="left" rowspan="1" colspan="1">2 / 1.0%</td><td align="left" rowspan="1" colspan="1">81 / 40.5%</td><td align="left" rowspan="1" colspan="1">73 / 36.5%</td><td align="left" rowspan="1" colspan="1">35 / 17.5%</td><td align="left" rowspan="1" colspan="1">191 / 95.5%</td></tr><tr><td align="left" rowspan="1" colspan="1">NRA</td><td align="left" rowspan="1" colspan="1">7 / 3.5%</td><td align="left" rowspan="1" colspan="1">134 / 67.0%</td><td align="left" rowspan="1" colspan="1">30 / 15.0%</td><td align="left" rowspan="1" colspan="1">2 / 1.0%</td><td align="left" rowspan="1" colspan="1">173 / 86.5%</td></tr><tr><td align="center" rowspan="3" colspan="1">SocialIQA</td><td align="left" rowspan="1" colspan="1">NQ</td><td align="left" rowspan="1" colspan="1">2 / 1%</td><td align="left" rowspan="1" colspan="1">45 / 22.5%</td><td align="left" rowspan="1" colspan="1">129 / 64.5%</td><td align="left" rowspan="1" colspan="1">18 / 9.0%</td><td align="left" rowspan="1" colspan="1">194 / 97%</td></tr><tr><td align="left" rowspan="1" colspan="1">WQ</td><td align="left" rowspan="1" colspan="1">1 / 0.5%</td><td align="left" rowspan="1" colspan="1">132 / 66%</td><td align="left" rowspan="1" colspan="1">37 / 18.5%</td><td align="left" rowspan="1" colspan="1">3 / 1.5%</td><td align="left" rowspan="1" colspan="1">173 / 86.5%</td></tr><tr><td align="left" rowspan="1" colspan="1">NRA</td><td align="left" rowspan="1" colspan="1">0 / 0%</td><td align="left" rowspan="1" colspan="1">132 / 66%</td><td align="left" rowspan="1" colspan="1">38 / 19.0%</td><td align="left" rowspan="1" colspan="1">3 / 1.5%</td><td align="left" rowspan="1" colspan="1">173 / 86.5%</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t007fn001"><p>Descriptions of confidence shifts are described in the <italic toggle="yes">Metrics</italic> section. NQ, WQ, and NRA stand for the NO-Question, Wrong-Question, and No-Right-Answer perturbation, respectively.</p></fn></table-wrap-foot></table-wrap><p>One particularly noteworthy finding is GPT-3.5-Turbo&#x02019;s ability to abstain from providing responses to certain perturbed instances. For instance, when faced with No-Question perturbed instances in the HellaSwag dataset, the model declined to provide confidence predictions for 54% of the instances. In other scenarios, it opted not to answer 9.6% of the perturbed instances, on average.</p><p>The confidence shift patterns observed in ChatGPT, as depicted in <xref rid="pone.0295925.t007" ref-type="table">Table 7</xref>, exhibit both similarities and distinctions when compared to the RoBERTa-based model. Across both models, <italic toggle="yes">random-like</italic> shifts were rarely observed in both prompt- and choice-based perturbations. The dominance of the <italic toggle="yes">Hybrid</italic> shift persisted in both benchmarks, regardless of the nature of the perturbation applied. However, GPT-3.5-Turbo exhibited a slightly lower proportion of hybrid shifts compared to RoBERTa. A similar trend was also observed for <italic toggle="yes">Conservative</italic> shifts, which emerged as the second most prevalent shift type but with a slightly less pronounced frequency in GPT-3.5-Turbo. These insights suggest that while factors embedded in model architecture, such as training data and fine-tuning, may influence the observed confidence behaviors, the consistent presence of the confidence shifting phenomenon in high-performing models like GPT-3.5-Turbo remains noteworthy.</p></sec></sec><sec sec-type="conclusions" id="sec018"><title>Conclusion</title><p>In this article, we proposed to study changes in the confidence distribution induced in a popular BERT-based question answering model by a set of confusion probes. Our methodology and experiments rely on publicly available benchmarks and models, none of which the authors had any role in developing or disseminating, and that can be downloaded and re-used in further experiments. We found evidence that, when instances are perturbed using the prompt-based functions, the confidence distribution of (the originally) incorrect answers in most perturbed instances is close to random, and is similar to the distribution observed before perturbation. The model will still prefer the originally correct (and post-perturbation, &#x02018;pseudo-correct&#x02019;) answer even though it is now theoretically incorrect. Hence, it is not agnostic to all incorrect answers, despite the fact that the instances in the held-out set were never seen by it during fine-tuning.</p><p>In the case of choice-based perturbations, the model will choose the incorrect choice that, on the surface, seems most closely aligned with the prompt, typically by sharing a greater number of common words, despite its incorrectness. Further analysis, including an analysis of potential &#x02018;irregularities&#x02019; in the benchmarks, suggests that they cannot serve as causal explanations for the observed phenomena. More complex analyses may reveal some correlation between benchmark characteristics and the observations, but a fuller investigation may need detailed linguistic profiling. The results do indicate that the behavior of the model when perturbed is not completely unpredictable. In a real QA-based system, the underlying language model can hypothetically be supplemented with an additional layer or module to discriminate between confidence distributions that arise from clear-cut cases (with one correct answer) and from ambiguous cases (whether intentionally generated or not) where every answer is incorrect, or at best, controversial. Future studies could expand our protocol to consider more probes, benchmarks and models. Such studies may end up providing important insights into the workings and biases of transformer-based models, even as they become larger, more complex and increasingly widespread.</p></sec></body><back><ref-list><title>References</title><ref id="pone.0295925.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Hirschman</surname><given-names>L</given-names></name>, <name><surname>Gaizauskas</surname><given-names>R</given-names></name>. <article-title>Natural language question answering: the view from here</article-title>. <source>natural language engineering</source>. <year>2001</year>;<volume>7</volume>(<issue>4</issue>):<fpage>275</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1017/S1351324901002807</pub-id></mixed-citation></ref><ref id="pone.0295925.ref002"><label>2</label><mixed-citation publication-type="other">Siblini W, Pasqual C, Lavielle A, Cauchois C. Multilingual question answering from formatted text applied to conversational agents. arXiv preprint arXiv:191004659. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref003"><label>3</label><mixed-citation publication-type="other">Devlin J, Chang MW, Lee K, Toutanova K. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:181004805. 2018;.</mixed-citation></ref><ref id="pone.0295925.ref004"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Floridi</surname><given-names>L</given-names></name>, <name><surname>Chiriatti</surname><given-names>M</given-names></name>. <article-title>GPT-3: Its nature, scope, limits, and consequences</article-title>. <source>Minds and Machines</source>. <year>2020</year>;<volume>30</volume>(<issue>4</issue>):<fpage>681</fpage>&#x02013;<lpage>694</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11023-020-09548-1</pub-id></mixed-citation></ref><ref id="pone.0295925.ref005"><label>5</label><mixed-citation publication-type="other">Lee JS, Hsiang J. Patentbert: Patent classification with fine-tuning a pre-trained bert model. arXiv preprint arXiv:190602124. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref006"><label>6</label><mixed-citation publication-type="other">Adhikari A, Ram A, Tang R, Lin J. Docbert: Bert for document classification. arXiv preprint arXiv:190408398. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref007"><label>7</label><mixed-citation publication-type="other">Beltagy I, Lo K, Cohan A. SciBERT: A pretrained language model for scientific text. arXiv preprint arXiv:190310676. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref008"><label>8</label><mixed-citation publication-type="other">Sanh V, Debut L, Chaumond J, Wolf T. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. arXiv preprint arXiv:191001108. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref009"><label>9</label><mixed-citation publication-type="other">Liu W, Zhou P, Zhao Z, Wang Z, Ju Q, Deng H, et al. K-bert: Enabling language representation with knowledge graph. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 34; 2020. p. 2901&#x02013;2908.</mixed-citation></ref><ref id="pone.0295925.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Reddy</surname><given-names>S</given-names></name>, <name><surname>Chen</surname><given-names>D</given-names></name>, <name><surname>Manning</surname><given-names>CD</given-names></name>. <article-title>Coqa: A conversational question answering challenge</article-title>. <source>Transactions of the Association for Computational Linguistics</source>. <year>2019</year>;<volume>7</volume>:<fpage>249</fpage>&#x02013;<lpage>266</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/tacl_a_00266</pub-id></mixed-citation></ref><ref id="pone.0295925.ref011"><label>11</label><mixed-citation publication-type="other">Fan A, Jernite Y, Perez E, Grangier D, Weston J, Auli M. Eli5: Long form question answering. arXiv preprint arXiv:190709190. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref012"><label>12</label><mixed-citation publication-type="other">Lewis P, O&#x0011f;uz B, Rinott R, Riedel S, Schwenk H. Mlqa: Evaluating cross-lingual extractive question answering. arXiv preprint arXiv:191007475. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref013"><label>13</label><mixed-citation publication-type="other">Liu Y, Lapata M. Text summarization with pretrained encoders. arXiv preprint arXiv:190808345. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref014"><label>14</label><mixed-citation publication-type="other">Zhang X, Wei F, Zhou M. HIBERT: Document level pre-training of hierarchical bidirectional transformers for document summarization. arXiv preprint arXiv:190506566. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref015"><label>15</label><mixed-citation publication-type="other">Shin J, Lee Y, Jung K. Effective sentence scoring method using bert for speech recognition. In: Asian Conference on Machine Learning. PMLR; 2019. p. 1081&#x02013;1093.</mixed-citation></ref><ref id="pone.0295925.ref016"><label>16</label><mixed-citation publication-type="other">Lan Z, Chen M, Goodman S, Gimpel K, Sharma P, Soricut R. Albert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:190911942. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref017"><label>17</label><mixed-citation publication-type="other">Zhang Y, Sun S, Galley M, Chen YC, Brockett C, Gao X, et al. Dialogpt: Large-scale generative pre-training for conversational response generation. arXiv preprint arXiv:191100536. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref018"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Rong</surname><given-names>W</given-names></name>, <name><surname>Ouyang</surname><given-names>Y</given-names></name>, <name><surname>Xiong</surname><given-names>Z</given-names></name>. <article-title>Augmenting dialogue response generation with unstructured textual knowledge</article-title>. <source>IEEE Access</source>. <year>2019</year>;<volume>7</volume>:<fpage>34954</fpage>&#x02013;<lpage>34963</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2904603</pub-id></mixed-citation></ref><ref id="pone.0295925.ref019"><label>19</label><mixed-citation publication-type="other">McCoy RT, Pavlick E, Linzen T. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. arXiv preprint arXiv:190201007. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref020"><label>20</label><mixed-citation publication-type="other">Richardson K, Hu H, Moss L, Sabharwal A. Probing natural language inference models through semantic fragments. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 34; 2020. p. 8713&#x02013;8721.</mixed-citation></ref><ref id="pone.0295925.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Gao</surname><given-names>Z</given-names></name>, <name><surname>Feng</surname><given-names>A</given-names></name>, <name><surname>Song</surname><given-names>X</given-names></name>, <name><surname>Wu</surname><given-names>X</given-names></name>. <article-title>Target-dependent sentiment classification with BERT</article-title>. <source>IEEE Access</source>. <year>2019</year>;<volume>7</volume>:<fpage>154290</fpage>&#x02013;<lpage>154299</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2946594</pub-id></mixed-citation></ref><ref id="pone.0295925.ref022"><label>22</label><mixed-citation publication-type="other">Thongtan T, Phienthrakul T. Sentiment classification using document embeddings trained with cosine similarity. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop; 2019. p. 407&#x02013;414.</mixed-citation></ref><ref id="pone.0295925.ref023"><label>23</label><mixed-citation publication-type="book">
<name><surname>Munikar</surname><given-names>M</given-names></name>, <name><surname>Shakya</surname><given-names>S</given-names></name>, <name><surname>Shrestha</surname><given-names>A</given-names></name>. <part-title>Fine-grained sentiment classification using BERT</part-title>. In: <source>2019 Artificial Intelligence for Transforming Business and Society (AITB)</source>. vol. <volume>1</volume>. <publisher-name>IEEE</publisher-name>; <year>2019</year>. p. <fpage>1</fpage>&#x02013;<lpage>5</lpage>.</mixed-citation></ref><ref id="pone.0295925.ref024"><label>24</label><mixed-citation publication-type="journal">
<name><surname>Rogers</surname><given-names>A</given-names></name>, <name><surname>Kovaleva</surname><given-names>O</given-names></name>, <name><surname>Rumshisky</surname><given-names>A</given-names></name>. <article-title>A primer in BERTology: What we know about how BERT works</article-title>. <source>Transactions of the Association for Computational Linguistics</source>. <year>2021</year>;<volume>8</volume>:<fpage>842</fpage>&#x02013;<lpage>866</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/tacl_a_00349</pub-id></mixed-citation></ref><ref id="pone.0295925.ref025"><label>25</label><mixed-citation publication-type="other">Kamsties E, Peach B. Taming ambiguity in natural language requirements. In: Proceedings of the Thirteenth international conference on Software and Systems Engineering and Applications. vol. 1315; 2000.</mixed-citation></ref><ref id="pone.0295925.ref026"><label>26</label><mixed-citation publication-type="other">Lu J, Batra D, Parikh D, Lee S. Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. arXiv preprint arXiv:190802265. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref027"><label>27</label><mixed-citation publication-type="other">Sun C, Myers A, Vondrick C, Murphy K, Schmid C. Videobert: A joint model for video and language representation learning. In: Proceedings of the IEEE/CVF International Conference on Computer Vision; 2019. p. 7464&#x02013;7473.</mixed-citation></ref><ref id="pone.0295925.ref028"><label>28</label><mixed-citation publication-type="other">Lample G, Conneau A. Cross-lingual language model pretraining. arXiv preprint arXiv:190107291. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref029"><label>29</label><mixed-citation publication-type="book">
<name><surname>Chalkidis</surname><given-names>I</given-names></name>, <name><surname>Fergadiotis</surname><given-names>M</given-names></name>, <name><surname>Malakasiotis</surname><given-names>P</given-names></name>, <name><surname>Aletras</surname><given-names>N</given-names></name>, <name><surname>Androutsopoulos</surname><given-names>I</given-names></name>. <part-title>LEGAL-BERT: The Muppets straight out of Law School</part-title>. In: <source>Findings of the Association for Computational Linguistics: EMNLP 2020</source>; <year>2020</year>. p. <fpage>2898</fpage>&#x02013;<lpage>2904</lpage>.</mixed-citation></ref><ref id="pone.0295925.ref030"><label>30</label><mixed-citation publication-type="other">Araci D. Finbert: Financial sentiment analysis with pre-trained language models. arXiv preprint arXiv:190810063. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref031"><label>31</label><mixed-citation publication-type="other">Huang K, Altosaar J, Ranganath R. Clinicalbert: Modeling clinical notes and predicting hospital readmission. arXiv preprint arXiv:190405342. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref032"><label>32</label><mixed-citation publication-type="other">Alsentzer E, Murphy JR, Boag W, Weng WH, Jin D, Naumann T, et al. Publicly available clinical BERT embeddings. arXiv preprint arXiv:190403323. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref033"><label>33</label><mixed-citation publication-type="other">Wang LL, Lo K, Chandrasekhar Y, Reas R, Yang J, Eide D, et al. Cord-19: The covid-19 open research dataset. ArXiv. 2020;.</mixed-citation></ref><ref id="pone.0295925.ref034"><label>34</label><mixed-citation publication-type="journal">
<name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Yoon</surname><given-names>W</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Kim</surname><given-names>D</given-names></name>, <name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>So</surname><given-names>CH</given-names></name>, <etal>et al</etal>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1234</fpage>&#x02013;<lpage>1240</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id>
<pub-id pub-id-type="pmid">31501885</pub-id>
</mixed-citation></ref><ref id="pone.0295925.ref035"><label>35</label><mixed-citation publication-type="journal">
<name><surname>Rogers</surname><given-names>A</given-names></name>, <name><surname>Kovaleva</surname><given-names>O</given-names></name>, <name><surname>Rumshisky</surname><given-names>A</given-names></name>. <article-title>A primer in bertology: What we know about how bert works</article-title>. <source>Transactions of the Association for Computational Linguistics</source>. <year>2020</year>;<volume>8</volume>:<fpage>842</fpage>&#x02013;<lpage>866</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/tacl_a_00349</pub-id></mixed-citation></ref><ref id="pone.0295925.ref036"><label>36</label><mixed-citation publication-type="other">Wu X, Zhang T, Zang L, Han J, Hu S. &#x0201c;Mask and Infill&#x0201d;: Applying Masked Language Model to Sentiment Transfer. arXiv preprint arXiv:190808039. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref037"><label>37</label><mixed-citation publication-type="other">Kobayashi G, Kuribayashi T, Yokoi S, Inui K. Attention module is not only a weight: Analyzing transformers with vector norms. arXiv preprint arXiv:200410102. 2020;.</mixed-citation></ref><ref id="pone.0295925.ref038"><label>38</label><mixed-citation publication-type="journal">
<name><surname>Ettinger</surname><given-names>A</given-names></name>. <article-title>What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models</article-title>. <source>Transactions of the Association for Computational Linguistics</source>. <year>2020</year>;<volume>8</volume>:<fpage>34</fpage>&#x02013;<lpage>48</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/tacl_a_00298</pub-id></mixed-citation></ref><ref id="pone.0295925.ref039"><label>39</label><mixed-citation publication-type="other">Liu NF, Gardner M, Belinkov Y, Peters ME, Smith NA. Linguistic knowledge and transferability of contextual representations. arXiv preprint arXiv:190308855. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref040"><label>40</label><mixed-citation publication-type="other">Warstadt A, Bowman SR. Can neural networks acquire a structural bias from raw linguistic data? arXiv preprint arXiv:200706761. 2020;.</mixed-citation></ref><ref id="pone.0295925.ref041"><label>41</label><mixed-citation publication-type="other">Ribeiro MT, Wu T, Guestrin C, Singh S. Beyond accuracy: Behavioral testing of NLP models with CheckList. arXiv preprint arXiv:200504118. 2020;.</mixed-citation></ref><ref id="pone.0295925.ref042"><label>42</label><mixed-citation publication-type="other">Jawahar G, Sagot B, Seddah D. What does BERT learn about the structure of language? In: ACL 2019-57th Annual Meeting of the Association for Computational Linguistics; 2019.</mixed-citation></ref><ref id="pone.0295925.ref043"><label>43</label><mixed-citation publication-type="other">Wu Z, Chen Y, Kao B, Liu Q. Perturbed masking: Parameter-free probing for analyzing and interpreting bert. arXiv preprint arXiv:200414786. 2020;.</mixed-citation></ref><ref id="pone.0295925.ref044"><label>44</label><mixed-citation publication-type="other">Wallace E, Wang Y, Li S, Singh S, Gardner M. Do nlp models know numbers? probing numeracy in embeddings. arXiv preprint arXiv:190907940. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref045"><label>45</label><mixed-citation publication-type="other">Balasubramanian S, Jain N, Jindal G, Awasthi A, Sarawagi S. What&#x02019;s in a Name? Are BERT Named Entity Representations just as Good for any other Name? arXiv preprint arXiv:200706897. 2020;.</mixed-citation></ref><ref id="pone.0295925.ref046"><label>46</label><mixed-citation publication-type="other">Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, et al. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:190711692. 2019;.</mixed-citation></ref><ref id="pone.0295925.ref047"><label>47</label><mixed-citation publication-type="other">Iyer S, Dandekar N, Csernai K. First quora dataset release: Question pairs; 2016. <ext-link xlink:href="https://https://www.quora.com/share/First-Quora-Dataset-Release-Question-Pairs" ext-link-type="uri">https://https://www.quora.com/share/First-Quora-Dataset-Release-Question-Pairs</ext-link>.</mixed-citation></ref><ref id="pone.0295925.ref048"><label>48</label><mixed-citation publication-type="book">
<name><surname>Dagan</surname><given-names>I</given-names></name>, <name><surname>Glickman</surname><given-names>O</given-names></name>, <name><surname>Magnini</surname><given-names>B</given-names></name>. <part-title>The pascal recognising textual entailment challenge</part-title>. In: <source>Machine Learning Challenges Workshop</source>. <publisher-name>Springer</publisher-name>; <year>2005</year>. p. <fpage>177</fpage>&#x02013;<lpage>190</lpage>.</mixed-citation></ref><ref id="pone.0295925.ref049"><label>49</label><mixed-citation publication-type="book">
<name><surname>Haim</surname><given-names>RB</given-names></name>, <name><surname>Dagan</surname><given-names>I</given-names></name>, <name><surname>Dolan</surname><given-names>B</given-names></name>, <name><surname>Ferro</surname><given-names>L</given-names></name>, <name><surname>Giampiccolo</surname><given-names>D</given-names></name>, <name><surname>Magnini</surname><given-names>B</given-names></name>, <etal>et al</etal>. <part-title>The second pascal recognising textual entailment challenge</part-title>. In: <source>Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual Entailment</source>; <year>2006</year>.</mixed-citation></ref><ref id="pone.0295925.ref050"><label>50</label><mixed-citation publication-type="book">
<name><surname>Giampiccolo</surname><given-names>D</given-names></name>, <name><surname>Magnini</surname><given-names>B</given-names></name>, <name><surname>Dagan</surname><given-names>I</given-names></name>, <name><surname>Dolan</surname><given-names>WB</given-names></name>. <part-title>The third pascal recognizing textual entailment challenge</part-title>. In: <source>Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing</source>; <year>2007</year>. p. <fpage>1</fpage>&#x02013;<lpage>9</lpage>.</mixed-citation></ref><ref id="pone.0295925.ref051"><label>51</label><mixed-citation publication-type="book">
<name><surname>Bentivogli</surname><given-names>L</given-names></name>, <name><surname>Clark</surname><given-names>P</given-names></name>, <name><surname>Dagan</surname><given-names>I</given-names></name>, <name><surname>Giampiccolo</surname><given-names>D</given-names></name>. <part-title>The Fifth PASCAL Recognizing Textual Entailment Challenge</part-title>. In: <source>TAC</source>; <year>2009</year>.</mixed-citation></ref><ref id="pone.0295925.ref052"><label>52</label><mixed-citation publication-type="other">Williams A, Nangia N, Bowman SR. A broad-coverage challenge corpus for sentence understanding through inference. arXiv preprint arXiv:170405426. 2017;.</mixed-citation></ref><ref id="pone.0295925.ref053"><label>53</label><mixed-citation publication-type="other">Rajpurkar P, Zhang J, Lopyrev K, Liang P. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:160605250. 2016;.</mixed-citation></ref><ref id="pone.0295925.ref054"><label>54</label><mixed-citation publication-type="other">Zellers R, Holtzman A, Bisk Y, Farhadi A, Choi Y. HellaSwag; 2019. <ext-link xlink:href="https://storage.googleapis.com/ai2-mosaic/public/hellaswag/hellaswag-train-dev.zip" ext-link-type="uri">https://storage.googleapis.com/ai2-mosaic/public/hellaswag/hellaswag-train-dev.zip</ext-link>.</mixed-citation></ref><ref id="pone.0295925.ref055"><label>55</label><mixed-citation publication-type="other">Zellers R, Holtzman A, Bisk Y, Farhadi A, Choi Y. HellaSwag: Can a Machine Really Finish Your Sentence? In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics; 2019.</mixed-citation></ref><ref id="pone.0295925.ref056"><label>56</label><mixed-citation publication-type="journal">
<name><surname>Lourie</surname><given-names>N</given-names></name>, <name><surname>Bras</surname><given-names>RL</given-names></name>, <name><surname>Bhagavatula</surname><given-names>C</given-names></name>, <name><surname>Choi</surname><given-names>Y</given-names></name>. <article-title>UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark</article-title>. <source>CoRR</source>. <year>2021</year>;abs/2103.13009.</mixed-citation></ref><ref id="pone.0295925.ref057"><label>57</label><mixed-citation publication-type="book">
<name><surname>Sap</surname><given-names>M</given-names></name>, <name><surname>Rashkin</surname><given-names>H</given-names></name>, <name><surname>Chen</surname><given-names>D</given-names></name>, <name><surname>Bras</surname><given-names>RL</given-names></name>, <name><surname>Choi</surname><given-names>Y</given-names></name>. <part-title>Social IQA: Commonsense Reasoning about Social Interactions</part-title>. In: <source>EMNLP 2019</source>; <year>2019</year>.</mixed-citation></ref><ref id="pone.0295925.ref058"><label>58</label><mixed-citation publication-type="other">Sap M, Rashkin H, Chen D, LeBras R, Choi Y. Social IQA; 2019. <ext-link xlink:href="https://storage.googleapis.com/ai2-mosaic/public/socialiqa/socialiqa-train-dev.zip" ext-link-type="uri">https://storage.googleapis.com/ai2-mosaic/public/socialiqa/socialiqa-train-dev.zip</ext-link>.</mixed-citation></ref><ref id="pone.0295925.ref059"><label>59</label><mixed-citation publication-type="other">Minimal Code Base For AI2 Commonsense Leaderboard; 2019. <ext-link xlink:href="https://github.com/isi-nlp/ai2/tree/base" ext-link-type="uri">https://github.com/isi-nlp/ai2/tree/base</ext-link>.</mixed-citation></ref><ref id="pone.0295925.ref060"><label>60</label><mixed-citation publication-type="other">Kaushik D, Lipton ZC. How much reading does reading comprehension require? a critical investigation of popular benchmarks. arXiv preprint arXiv:180804926. 2018;.</mixed-citation></ref><ref id="pone.0295925.ref061"><label>61</label><mixed-citation publication-type="other">Gururangan S, Swayamdipta S, Levy O, Schwartz R, Bowman SR, Smith NA. Annotation artifacts in natural language inference data. arXiv preprint arXiv:180302324. 2018;.</mixed-citation></ref><ref id="pone.0295925.ref062"><label>62</label><mixed-citation publication-type="other">Poliak A, Naradowsky J, Haldar A, Rudinger R, Van Durme B. Hypothesis only baselines in natural language inference. arXiv preprint arXiv:180501042. 2018;.</mixed-citation></ref><ref id="pone.0295925.ref063"><label>63</label><mixed-citation publication-type="other">Confusion probe perturbed commonsense dataset;. Available from: <ext-link xlink:href="https://www.kaggle.com/dsv/5130107" ext-link-type="uri">https://www.kaggle.com/dsv/5130107</ext-link>.</mixed-citation></ref><ref id="pone.0295925.ref064"><label>64</label><mixed-citation publication-type="other">Hendrycks D, Gimpel K. A baseline for detecting misclassified and out-of-distribution examples in neural networks. arXiv preprint arXiv:161002136. 2016;.</mixed-citation></ref><ref id="pone.0295925.ref065"><label>65</label><mixed-citation publication-type="other">Kamath A, Jia R, Liang P. Selective question answering under domain shift. arXiv preprint arXiv:200609462. 2020;.</mixed-citation></ref><ref id="pone.0295925.ref066"><label>66</label><mixed-citation publication-type="other">Zhang S, Gong C, Choi E. Knowing More About Questions Can Help: Improving Calibration in Question Answering. arXiv preprint arXiv:210601494. 2021;.</mixed-citation></ref></ref-list></back><sub-article article-type="aggregated-review-documents" id="pone.0295925.r001" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0295925.r001</article-id><title-group><article-title>Decision Letter 0</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Barros</surname><given-names>Rodrigo Coelho</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2023 Rodrigo Coelho Barros</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Rodrigo Coelho Barros</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0295925" id="rel-obj001" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">13 Sep 2023</named-content>
</p><p><!-- <div> -->PONE-D-23-07266<!-- </div> --><!-- <div> -->Quantifying Confidence Shifts in a BERT-based Question Answering System Evaluated on Perturbed Instances<!-- </div> --><!-- <div> -->PLOS ONE</p><p>Dear Dr. Kejriwal,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#x02019;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>The authors have proposed investigating the performance of RoBERTa in question-answering, specifically with the use of confusion probes to verify the behavior of such systems when dealing with uncertainty. They show that the model&#x02019;s confidence is very different from that of an expected model that has no preferences on the incorrect choices when theoretically dealing with scenarios in which there is no correct answer for a question. This suggests potential research paths that deserve further analysis before robust real-world deployment of such systems.<!-- </div> --><!-- <div> --></p><p>The experimental setup and analysis is sound and the paper is very well-written and detailed. I suggest verifying the minor points raised by the reviewers, in particular addressing the rationale behind the choice of RoBERTa, as well as a discussion on the generality of the findings (e.g., do they stand for LLMs such as Llama, Alpaca, and the GPT family?). Perhaps the inclusion of a small set of experiments in that direction would suffice.</p><p>Please submit your revised manuscript by Oct 28 2023 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#x000a0;<email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list><!-- <div> -->If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols</ext-link>.</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Rodrigo Coelho Barros, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal Requirements:</p><p>When submitting your revision, we need you to address these additional requirements.</p><p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at&#x000a0;</p><p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and&#x000a0;</p><p>
<ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
</p><p>2. Please note that PLOS ONE has specific guidelines on code sharing for submissions in which author-generated code underpins the findings in the manuscript. In these cases, all author-generated code must be made available without restrictions upon publication of the work. Please review our guidelines at <ext-link xlink:href="https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code" ext-link-type="uri">https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code</ext-link> and ensure that your code is shared in a way that follows best practice and facilitates reproducibility and reuse.</p><p>3. Thank you for stating the following in the Acknowledgments Section of your manuscript:&#x000a0;</p><p>"This work was funded as part of MOWGLI, a project in the DARPA Machine Common Sense (MCS) program, supported by the United States Office Of Naval Research under Contract No. N660011924033."</p><p>We note that you have provided funding information that is currently declared in your Funding Statement. However, funding information should not appear in the Acknowledgments section or other areas of your manuscript. We will only publish funding information present in the Funding Statement section of the online submission form.&#x000a0;</p><p>Please remove any funding-related text from the manuscript and let us know how you would like to update your Funding Statement. Currently, your Funding Statement reads as follows:&#x000a0;</p><p>"MK received funding for this work as a principal investigator of MOWGLI, a project in the Defense Advanced Research Projects Agency (DARPA) Machine Common</p><p>Sense program, supported by the United States Office Of Naval Research under</p><p>Contract No. N660011924033. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript."</p><p>Please include your amended statements within your cover letter; we will change the online submission form on your behalf.</p><p>4. Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article&#x02019;s retracted status in the References list and also include a citation and full reference for the retraction notice.</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<!-- <font color="black"> -->
<bold>Comments to the Author</bold>
</p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->5. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p><p>Reviewer #1:&#x000a0;This paper evaluates the confidence shifts in a ROBERTa model on perturbing QA instances.</p><p>#Introduction</p><p>In the introduction, the authors explained BERT-like systems and described their choice of ROBERTa. I suggest a paragraph arguing in favor of ROBERTa instead of a "highly optimized version".</p><p>They argue that they provide a new set of three confusion probes to test linguistic properties. I suggest removing "linguistic properties" and explaining the three probes later, as the authors did.</p><p>The authors provided a significant difference from QA, considering their approach as a prompt, and they presented the Research Questions clearly.</p><p># Related Work</p><p>Concerning their related work, it would be interesting to have a ROBERTa discussion in a BERT-based layer of linguistic approaches, the main differences, for example.</p><p>#Formalism</p><p>The formalism section was interesting in making understanding the probes and correct and incorrect choices clearer.</p><p>#Material and methods</p><p>They described their material and methods and explained their results regarding their research questions.</p><p>#Discussion</p><p>They provided a discussion and two analyses: the benchmarks, irregularities, and automatic detections.</p><p>#Conclusions</p><p>Although they described their conclusion as needing improvement in other experiments' directions, they promoted a substantial analysis concerning the research subject.</p><p>Some typos</p><p>on on -&#x0003e; on</p><p>C(A,P) -&#x0003e; C(&#x000c3;,P)</p><p>Reviewer #2:&#x000a0;This research investigates a BERT-based question-answering model's response to confusion probes, revealing that despite perturbations, the model often maintains a preference for its original correct answer while exhibiting random confidence distributions for incorrect answers, suggesting potential avenues for further analysis and highlighting the need for additional research into transformer-based model behavior and biases.</p><p>I find the research questions about what might happen if no correct answer exists for a given prompt among the provided set of choices quite interesting. Moreover, the manuscript is well-written. Motivation and methodology are sound. Therefore, my overall opinion is positive. I have just some comments to help improve the manuscript:</p><p>- The paper focuses exclusively on BERT. I missed a discussion about whether the results are generalizable to other types of models of the same nature.</p><p>- I do not know if the authors intend to be exhaustive in all the domains in which BERT has application, but some very important ones need to be included, for example, LegalBERT.</p><p>- Very little information is given about the RoBERTa model chosen for the experiments. This brings two additional problems: a) it is necessary to go to the literature to understand the details about the training of such a model, and b) it needs to be clarified why such a configuration has been chosen over many other existing ones.</p><p>- The following comment is closely related to the previous one. Can the authors foresee analogous behavior/results if the model configuration is changed?</p><p>- I do not fully understand the sentence: "incorrect choice that appears superficially closest to the prompt." Does it mean the choice with a smaller semantic distance to the prompt is chosen? How is this defined?</p><p>**********</p><p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#x000a0;<ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#x000a0;<email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0295925.r002"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0295925.r002</article-id><title-group><article-title>Author response to Decision Letter 0</article-title></title-group><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0295925" id="rel-obj002" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">2 Oct 2023</named-content>
</p><p>We thank the editors and all the reviewers for their comments and have attempted to take each concern into account. Among the most significant changes to the revised paper is a more detailed Related Work and Discussion section, and fewer subheadings in other sections. Below, we provide a point-by-point response.</p><p>Thank you for stating the following in the Acknowledgments Section of your manuscript: </p><p>"This work was funded as part of MOWGLI, a project in the DARPA Machine Common Sense (MCS) program, supported by the United States Office Of Naval Research under Contract No. N660011924033."</p><p>We note that you have provided funding information that is currently declared in your Funding Statement. However, funding information should not appear in the Acknowledgments section or other areas of your manuscript. We will only publish funding information present in the Funding Statement section of the online submission form. </p><p>Please remove any funding-related text from the manuscript and let us know how you would like to update your Funding Statement. Currently, your Funding Statement reads as follows: </p><p>"MK received funding for this work as a principal investigator of MOWGLI, a project in the Defense Advanced Research Projects Agency (DARPA) Machine Common</p><p>Sense program, supported by the United States Office Of Naval Research under</p><p>Contract No. N660011924033. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript."</p><p>Please include your amended statements within your cover letter; we will change the online submission form on your behalf.</p><p>Response: </p><p>We have removed the funding information from the manuscript and the current funding statement looks fine to us.</p><p>Reviewer #1: This paper evaluates the confidence shifts in a ROBERTa model on perturbing QA instances.</p><p>#Introduction</p><p>In the introduction, the authors explained BERT-like systems and described their choice of ROBERTa. I suggest a paragraph arguing in favor of ROBERTa instead of a "highly optimized version".</p><p>Response: </p><p>We have revised the introduction and related work section to offer a more comprehensive explanation of the specific advantages of RoBERTa, highlighting how its modified training techniques and superior performance on NLP benchmarks make it a suitable choice for our research.</p><p>They argue that they provide a new set of three confusion probes to test linguistic properties. I suggest removing "linguistic properties" and explaining the three probes later, as the authors did.</p><p>Response: </p><p>We have removed &#x0201c;linguistic properties&#x0201d; and rephrased the original sentence &#x0201c;We design and implement a novel set of three confusion probes to test linguistically relevant properties &#x0201d; to &#x0201c;We design and implement a novel set of three confusion probes to observe how confidence distribution shifts&#x0201d;.</p><p># Related Work</p><p>Concerning their related work, it would be interesting to have a ROBERTa discussion in a BERT-based layer of linguistic approaches, the main differences, for example.</p><p>Response: </p><p>We have rephrased the RoBERTa paragraph in Related Work section to provide a more detailed explanation of the main differences between RoBERTa and BERT. We believe that this addition enhances the manuscript by offering readers a clearer understanding of the nuanced differences between these two influential models.</p><p>Some typos</p><p>on on -&#x0003e; on</p><p>C(A,P) -&#x0003e; C(&#x000c3;,P)</p><p>Response: </p><p>We appreciate your careful review of our manuscript and have corrected the mentioned typos. </p><p>Reviewer #2: This research investigates a BERT-based question-answering model's response to confusion probes, revealing that despite perturbations, the model often maintains a preference for its original correct answer while exhibiting random confidence distributions for incorrect answers, suggesting potential avenues for further analysis and highlighting the need for additional research into transformer-based model behavior and biases.I find the research questions about what might happen if no correct answer exists for a given prompt among the provided set of choices quite interesting. Moreover, the manuscript is well-written. Motivation and methodology are sound. Therefore, my overall opinion is positive. I have just some comments to help improve the manuscript:</p><p>- The paper focuses exclusively on BERT. I missed a discussion about whether the results are generalizable to other types of models of the same nature.</p><p>Response: </p><p>In the revised manuscript, we introduced a new section within the Discussion Section, featuring supplementary experiments employing the GPT-3.5 Turbo model. Given the widespread popularity and exceptional performance of GPT models, we posit that these additional experiments offer robust and representative evidence to support the generalizability of our findings. The results show that while the specific proportions of shifts may exhibit some variance, the general trends in confidence shifts remain remarkably consistent across different models.</p><p>- I do not know if the authors intend to be exhaustive in all the domains in which BERT has application, but some very important ones need to be included, for example, LegalBERT.</p><p>Response: </p><p>Thanks for the valuable suggestion. We have included more domain-specific applications in the related work section of the revised paper. This includes mention of LegalBERT, ClinicalBERT, FinBERT, and PatentBERT, among others. We think the current Related Work section can provide a more comprehensive overview of the significance of the BERT model in various fields.</p><p>- Very little information is given about the RoBERTa model chosen for the experiments. This brings two additional problems: a) it is necessary to go to the literature to understand the details about the training of such a model, and b) it needs to be clarified why such a configuration has been chosen over many other existing ones.</p><p>Response: </p><p>We have expanded upon the pre-training and fine-tuning details of RoBERTa in both the Related Work and Materials and Methods sections in the manuscript, aiming to offer readers a clearer understanding of our model choice and setup.</p><p>Additionally, regarding the selection of specific fine-tuning parameters, our choice was based on optimizing the model's performance on the validation set. We selected the configuration that yielded the best accuracy results during the fine-tuning process. We hope that these clarifications provide more insight into our model selection and fine-tuning decisions.</p><p>- The following comment is closely related to the previous one. Can the authors foresee analogous behavior/results if the model configuration is changed?</p><p>Response: </p><p>We appreciate your comment regarding the potential impact of altering the model configuration on our results. While we did not replicate the experiments by varying the RoBERTa model configuration, we did conduct experiments across different models, including ChatGPT (now presented in the Discussion Section), UnifiedQA, and XLNet. Across these diverse models, we observed a certain degree of consistency in the confidence shift patterns, which suggests that the observed behavior is not solely dependent on the specific architecture but is a characteristic of transformer-based language models in general.</p><p>Given this observation, we believe that even if we were to modify the configuration of the RoBERTa model, it is likely to exhibit similar behavior in terms of confidence shifts when exposed to perturbations. However, further experimentation would be needed to confirm the extent of this similarity and explore the nuances of different configurations.</p><p>- I do not fully understand the sentence: "incorrect choice that appears superficially closest to the prompt." Does it mean the choice with a smaller semantic distance to the prompt is chosen? How is this defined?</p><p>Response: </p><p>The phrase 'superficially closest to' does indeed relate to a smaller semantic distance, but it primarily emphasizes a more 'superficial' characteristic, such as the presence of common words shared between the choice and the prompt. To enhance clarity, we have rephrased the original sentence, and the current version reads:</p><p>'In the case of choice-based perturbation, the model will choose the incorrect choice that, on the surface, seems most closely aligned with the prompt, typically by sharing a greater number of common words, despite its incorrectness.'</p><supplementary-material id="pone.0295925.s001" position="float" content-type="local-data"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">revision-letter.pdf</named-content></p></caption><media xlink:href="pone.0295925.s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0295925.r003" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0295925.r003</article-id><title-group><article-title>Decision Letter 1</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Barros</surname><given-names>Rodrigo Coelho</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2023 Rodrigo Coelho Barros</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Rodrigo Coelho Barros</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0295925" id="rel-obj003" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">4 Dec 2023</named-content>
</p><p>Quantifying Confidence Shifts in a BERT-based Question Answering System Evaluated on Perturbed Instances</p><p>PONE-D-23-07266R1</p><p>Dear Dr. Kejriwal,</p><p>We&#x02019;re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p><p>Within one week, you&#x02019;ll receive an e-mail detailing the required amendments. When these have been addressed, you&#x02019;ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p><p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p><p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they&#x02019;ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p><p>Kind regards,</p><p>Rodrigo Coelho Barros, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<!-- <font color="black"> -->
<bold>Comments to the Author</bold>
</p><p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#x0201c;Comments to the Author&#x0201d; section, enter your conflict of interest statement in the &#x0201c;Confidential to Editor&#x0201d; section, and submit your "Accept" recommendation.<!-- </font> --></p><p>Reviewer #1:&#x000a0;All comments have been addressed</p><p>Reviewer #2:&#x000a0;All comments have been addressed</p><p>**********</p><p><!-- <font color="black"> -->2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->6. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p><p>Reviewer #1:&#x000a0;The authors answered my questions, and they better described their approach. It would be nice to have such a limitation to Roberta in the title instead of a BERT-based but ROBERTA model to delimitate their approach better.</p><p>Reviewer #2:&#x000a0;The authors have successfully dealt with my comments and suggestions. Therefore, I have decided to upgrade my recommendation.</p><p>**********</p><p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p><p>Reviewer #1:&#x000a0;No</p><p>Reviewer #2:&#x000a0;No</p><p>**********</p></body></sub-article><sub-article article-type="editor-report" id="pone.0295925.r004" specific-use="acceptance-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0295925.r004</article-id><title-group><article-title>Acceptance letter</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Barros</surname><given-names>Rodrigo Coelho</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2023 Rodrigo Coelho Barros</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Rodrigo Coelho Barros</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0295925" id="rel-obj004" related-article-type="reviewed-article"/></front-stub><body><p>
<named-content content-type="letter-date">11 Dec 2023</named-content>
</p><p>PONE-D-23-07266R1 </p><p>Quantifying Confidence Shifts in a BERT-based Question Answering System Evaluated on Perturbed Instances </p><p>Dear Dr. Kejriwal:</p><p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p><p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p><p>If we can help with anything else, please email us at <email>customercare@plos.org</email>.</p><p>Thank you for submitting your work to PLOS ONE and supporting open access. </p><p>Kind regards, </p><p>PLOS ONE Editorial Office Staff</p><p>on behalf of</p><p>Dr. Rodrigo Coelho Barros </p><p>Academic Editor</p><p>PLOS ONE</p></body></sub-article></article>
