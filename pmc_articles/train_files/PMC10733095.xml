<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="data-paper" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Data Brief</journal-id><journal-id journal-id-type="iso-abbrev">Data Brief</journal-id><journal-title-group><journal-title>Data in Brief</journal-title></journal-title-group><issn pub-type="epub">2352-3409</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38125373</article-id><article-id pub-id-type="pmc">PMC10733095</article-id><article-id pub-id-type="pii">S2352-3409(23)00986-1</article-id><article-id pub-id-type="doi">10.1016/j.dib.2023.109955</article-id><article-id pub-id-type="publisher-id">109955</article-id><article-categories><subj-group subj-group-type="heading"><subject>Data Article</subject></subj-group></article-categories><title-group><article-title>A novel dataset of potato leaf disease in uncontrolled environment</article-title></title-group><contrib-group><contrib contrib-type="author" id="au0001"><name><surname>Shabrina</surname><given-names>Nabila Husna</given-names></name><email>nabila.husna@umn.ac.id</email><xref rid="aff0001" ref-type="aff">a</xref><xref rid="cor0001" ref-type="corresp">&#x0204e;</xref></contrib><contrib contrib-type="author" id="au0002"><name><surname>Indarti</surname><given-names>Siwi</given-names></name><xref rid="aff0002" ref-type="aff">b</xref></contrib><contrib contrib-type="author" id="au0003"><name><surname>Maharani</surname><given-names>Rina</given-names></name><xref rid="aff0002" ref-type="aff">b</xref></contrib><contrib contrib-type="author" id="au0004"><name><surname>Kristiyanti</surname><given-names>Dinar Ajeng</given-names></name><xref rid="aff0003" ref-type="aff">c</xref></contrib><contrib contrib-type="author" id="au0005"><name><surname>Irmawati</surname></name><xref rid="aff0003" ref-type="aff">c</xref></contrib><contrib contrib-type="author" id="au0006"><name><surname>Prastomo</surname><given-names>Niki</given-names></name><xref rid="aff0004" ref-type="aff">d</xref></contrib><contrib contrib-type="author" id="au0007"><name><surname>Adilah M</surname><given-names>Tika</given-names></name><xref rid="aff0005" ref-type="aff">e</xref></contrib><aff id="aff0001"><label>a</label>Department of Computer Engineering, Universitas Multimedia Nusantara, Tangerang 15111, Banten, Indonesia</aff><aff id="aff0002"><label>b</label>Department of Plant Protection, Universitas Gadjah Mada, Sleman 55281, Yogyakarta, Indonesia</aff><aff id="aff0003"><label>c</label>Department of Information System, Universitas Multimedia Nusantara, Tangerang 15111, Banten, Indonesia</aff><aff id="aff0004"><label>d</label>Department of Physics Engineering, Universitas Multimedia Nusantara, Tangerang 15111, Banten, Indonesia</aff><aff id="aff0005"><label>e</label>Department of Information Technology, Universitas Bina Sarana Informatika, Jakarta Pusat 10450, DKI Jakarta, Indonesia</aff></contrib-group><author-notes><corresp id="cor0001"><label>&#x0204e;</label>Corresponding author. <email>nabila.husna@umn.ac.id</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>12</day><month>12</month><year>2023</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><month>2</month><year>2024</year></pub-date><pub-date pub-type="epub"><day>12</day><month>12</month><year>2023</year></pub-date><volume>52</volume><elocation-id>109955</elocation-id><history><date date-type="received"><day>11</day><month>11</month><year>2023</year></date><date date-type="rev-recd"><day>2</day><month>12</month><year>2023</year></date><date date-type="accepted"><day>6</day><month>12</month><year>2023</year></date></history><permissions><copyright-statement>&#x000a9; 2023 The Author(s)</copyright-statement><copyright-year>2023</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p></license></permissions><abstract id="abs0001"><p>Potatoes are of the utmost importance for both food processing and daily consumption; however, they are also prone to pests and diseases, which can cause significant economic losses. To address this issue, the implementation of image processing and computer vision methods in conjunction with machine learning and deep learning techniques can serve as an alternative approach for quickly identifying diseases in potato leaves. Several studies have demonstrated promising results. However, the current research is limited by the use of a single dataset, the PlantVillage dataset, which may not accurately represent the diverse conditions of potato pests and diseases in real-world settings. Therefore, a new dataset that accurately depicts various types of diseases is crucial. We propose a novel dataset that offers several advantages over previous datasets, including data obtained in an uncontrolled environment that results in a diverse range of variables such as background and image angles. The proposed dataset comprises 3076 images categorized into seven classes, including leaves attacked by viruses, bacteria, fungi, pests, nematodes, phytophthora, and healthy leaves. This dataset aims to provide a more accurate representation of potato leaf diseases and facilitate advancements in the current research on potato leaf disease identification.</p></abstract><kwd-group id="keys0001"><title>Keywords</title><kwd>Dataset</kwd><kwd>Image classification</kwd><kwd>Potato leaf disease</kwd><kwd>Precision agriculture</kwd><kwd>Uncontrolled environment</kwd></kwd-group></article-meta></front><body><p id="para0002">Specifications Table<table-wrap position="float" id="utbl0001"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">Subject</td><td valign="top">Computer Science, Agricultural Science</td></tr><tr><td valign="top">Specific subject area</td><td valign="top">Computer vision, Image classification, Deep Learning, Machine Learning, Precision Agriculture</td></tr><tr><td valign="top">Data format</td><td valign="top">Raw</td></tr><tr><td valign="top">Type of data</td><td valign="top">Image</td></tr><tr><td valign="top">Data collection</td><td valign="top">Dataset were obtained at two distinct periods: August 2, 2023, for potato farms located in Magelang, Central Java, Indonesia and August 15-16, 2023, for potato farms located in Wonosobo, Central Java, Indonesia. Images were captured by several team members using various smartphone cameras. The experts from the Department of Plant Protection were then conducted a thorough evaluation of each image and categorized them into seven distinct classes, including &#x0201c;virus,&#x0201d; &#x0201c;phytophthora,&#x0201d; &#x0201c;nematode,&#x0201d; &#x0201c;fungi,&#x0201d; &#x0201c;bacteria,&#x0201d; &#x0201c;pest,&#x0201d; and &#x0201c;healthy.&#x0201d; All images were then resized to 1500&#x000a0;&#x000d7;&#x000a0;1500 pixels resulting in uniform resolution for all images. Images were saved into .jpg format for compatibility with various image-processing software packages, and ease of accessibility</td></tr><tr><td valign="top">Data source location</td><td valign="top">The dataset was obtained in Central Java, Indonesia, with the detail location as follows.<break/>1.-7.231694, 109.937778 Tieng, Kejajar, Wonosobo<break/>2.-7.231114, 109.937078 Tieng, Kejajar, Wonosobo<break/>3.-7.205085, 109.911120 Dieng, Kejajar, Wonosobo<break/>4.-7.446640, 110.378579 Kragilan, Pakis, Magelang<break/>5.-7.439587, 110.397223 Kenalan, Pakis, Magelang<break/>6.-7.211900, 109.928986 Parikesit, Kejajar, Wonosobo<break/>7.-7.210166, 109.909267 Dieng Kulon, Batur, Banjarnegara<break/>8.-7.210113, 109.909820 Dieng Kulon, Batur, Banjarnegara<break/>9.-7.198797, 109.915172 Dieng, Kejajar, Wonosobo<break/>10.-7.236805, 109.941532 Tieng, Kejajar, Wonosobo<break/>11.-7.441006, 110.371796 Kaponan, Pakis, Magelang<break/>12.-7.407529, 110.381297 Sumberejo, Ngablak, Magelang</td></tr><tr><td valign="top">Data accessibility</td><td valign="top">Repository name: The datasets are publicly and freely available on Mendeley data repository.<break/>Data identification number: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17632/ptz377bwb8.1" id="interref0001a">10.17632/ptz377bwb8.1</ext-link><break/>Direct URL to data: <ext-link ext-link-type="uri" xlink:href="https://data.mendeley.com/datasets/ptz377bwb8/1" id="interref0001b">https://data.mendeley.com/datasets/ptz377bwb8/1</ext-link></td></tr></tbody></table></table-wrap></p><sec id="sec0002"><label>1</label><title>Value of the Data</title><p id="para9003">
<list list-type="simple" id="celist0001"><list-item id="celistitem0001"><label>&#x02022;</label><p id="para0003">This dataset was collected in an uncontrolled environment, resulting in a variety of variables, including the background and the diverse directions and distances of the images.</p></list-item><list-item id="celistitem0002"><label>&#x02022;</label><p id="para0004">This dataset is better at representing the various types of diseases commonly found on potato leaves by categorizing them into seven classes, including leaves symptoms attacked by viruses, bacteria, fungi, pests, nematodes, phytophthora, and healthy leaves.</p></list-item><list-item id="celistitem0003"><label>&#x02022;</label><p id="para0005">This dataset can be used for computer vision and pattern recognition, which are primarily employed in classification tasks.</p></list-item><list-item id="celistitem0004"><label>&#x02022;</label><p id="para0006">The potato leaf dataset has motivated researchers to develop a novel approach for classifying potato leaf diseases in uncontrolled environments.</p></list-item><list-item id="celistitem0005"><label>&#x02022;</label><p id="para0007">This dataset will encourage researchers to classify or build models to identify potato leaf pests and diseases using advanced computer vision techniques under background clutter and occlusion conditions.</p></list-item></list>
</p></sec><sec id="sec0003"><label>2</label><title>Background</title><p id="para0008">The implementation of image processing and computer vision methods can serve as an alternative approach to accelerate the process of identifying diseases in potatoes through the symptoms of leaves. However, the use of a single dataset may impede the ability of Machine Learning (ML) or Deep Learning (DL) to generalize, diversify, and adjust to diverse situations. Furthermore, the existing PlantVillage dataset <xref rid="bib0001" ref-type="bibr">[1]</xref> utilizes a controlled environment for image capture, whereby each image is captured under controlled parameters such as a clean background, controlled angles, and camera directions. This approach was adopted to enable system designers to minimize various sources of variability and achieve high-performance results. In addition, the PlantVillage dataset comprises only three classes: healthy, early blight, and late blight. Among these, late and early blight are caused by fungi. Although previous studies have demonstrated superior performance, the available datasets may not accurately represent the real-world conditions of potato pests and diseases because of the controlled environment in which the images were captured and the lack of information on disease type, which only captures diseases caused by fungi. The creation of a dataset specifically for diversifying images of potato leaf diseases in uncontrolled environments is highly needed because of the scarcity of suitable image datasets for a wider range of diseases. To address this issue, we have recently acquired novel primary data that offer several advantages over previous datasets and will better represent the various types of diseases commonly found on potato leaves.</p></sec><sec id="sec0004"><label>3</label><title>Data Description</title><p id="para0009">The dataset was developed by multidisciplinary teams from the Faculty of Engineering and Informatics, Universitas Multimedia Nusantara, and Faculty of Agriculture, Universitas Gadjah Mada. The dataset was collected from several potato farms in Java Island, Indonesia, primarily in central Java. The dataset was gathered in an unrestricted setting characterized by multiple inconsistencies, such as background and diverse directions and distances. This dataset comprises several categories of potato leaf diseases, including those caused by fungi, viruses, pests, bacteria, phytoplasmas, and nematodes.</p><p id="para0010">The sample images for each category are shown in <xref rid="fig0001" ref-type="fig">Fig.&#x000a0;1</xref>. The total number of images per category in the dataset is listed in <xref rid="tbl0001" ref-type="table">Table&#x000a0;1</xref>. As listed in <xref rid="tbl0001" ref-type="table">Table&#x000a0;1</xref>, the dataset consists of seven classes, with a total of 3076 images. The classes were categorized as &#x0201c;virus,&#x0201d; &#x0201c;phytophthora,&#x0201d; &#x0201c;nematode,&#x0201d; &#x0201c;fungi,&#x0201d; &#x0201c;bacteria,&#x0201d; &#x0201c;pest,&#x0201d; and &#x0201c;healthy&#x0201d;. The images had a resolution of 1500&#x000a0;&#x000d7;&#x000a0;1500 pixels and were saved in. jpg format to ensure ease of access and compatibility with various image-processing software packages.<fig id="fig0001"><label>Fig. 1</label><caption><p>Sample of the seven categories of potato leaf dataset: (a) bacteria; (b) fungi; (c) healthy; (d) nematode; (e) pest; (f) phytophthora; (g) virus.</p></caption><alt-text id="alt0001">Fig 1</alt-text><graphic xlink:href="gr1" id="celink0001"/></fig><table-wrap position="float" id="tbl0001"><label>Table 1</label><caption><p>Distribution of the dataset.</p></caption><alt-text id="alt0002">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Class</th><th valign="top">Number of images</th></tr></thead><tbody><tr><td valign="top">Virus</td><td valign="top">532</td></tr><tr><td valign="top">Phytophthora</td><td valign="top">347</td></tr><tr><td valign="top">Nematode</td><td valign="top">68</td></tr><tr><td valign="top">Fungi</td><td valign="top">748</td></tr><tr><td valign="top">Bacteria</td><td valign="top">569</td></tr><tr><td valign="top">Pest</td><td valign="top">611</td></tr><tr><td valign="top">Healthy</td><td valign="top">201</td></tr><tr><td valign="top"><bold>Total</bold></td><td valign="top"><bold>3076</bold></td></tr></tbody></table></table-wrap></p></sec><sec id="sec0005"><label>4</label><title>Experimental Design, Materials and Methods</title><sec id="sec0006"><label>4.1</label><title>Image capturing</title><p id="para0011">The images used in this study were obtained from multiple angles and distances ranging from approximately 5&#x02013;15 cm. The pictures were acquired under diverse weather conditions, including sunny, cloudy, and partially cloudy. Images were captured between the hours of 8 a.m. and 3:00 p.m This dataset collected symptoms of pathogen and pest attacks on potato leaves of varying ages, approximately 35-80 days after planting. At this stage, the symptoms caused by each pathogen that appeared in the leaves are visible and have no ambiguities with other infections. However, because the dataset was intended for the image classification task, the disease progression stage was not included in the dataset. The disease stage was randomly selected based on the occurrence of diseases observed in the field. The images were obtained at two distinct periods: August 2, 2023, for potato farms located in Magelang, Central Java and August 15&#x02013;16, 2023 for potato farms located in Wonosobo, Central Java. The locations of potato farms are listed in <xref rid="tbl0002" ref-type="table">Table&#x000a0;2</xref>.<table-wrap position="float" id="tbl0002"><label>Table 2</label><caption><p>Location of potato farm.</p></caption><alt-text id="alt0003">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Coordinate</th><th valign="top">Location</th><th valign="top">Meter above the sea (MASL)</th></tr></thead><tbody><tr><td valign="top">&#x02212;7.231694, 109.937778</td><td valign="top">Tieng, Kejajar, Wonosobo</td><td valign="top">&#x000b1;1802</td></tr><tr><td valign="top">&#x02212;7.231114, 109.937078</td><td valign="top">Tieng, Kejajar, Wonosobo</td><td valign="top">&#x000b1;1807</td></tr><tr><td valign="top">&#x02212;7.205085, 109.911120</td><td valign="top">Dieng, Kejajar, Wonosobo</td><td valign="top">&#x000b1;2064</td></tr><tr><td valign="top">&#x02212;7.446640, 110.378579</td><td valign="top">Kragilan, Pakis, Magelang</td><td valign="top">&#x000b1;1208</td></tr><tr><td valign="top">&#x02212;7.439587, 110.397223</td><td valign="top">Kenalan, Pakis, Magelang</td><td valign="top">&#x000b1;1428</td></tr><tr><td valign="top">&#x02212;7.211900, 109.928986</td><td valign="top">Parikesit, Kejajar, Wonosobo</td><td valign="top">&#x000b1;1992</td></tr><tr><td valign="top">&#x02212;7.210166, 109.909267</td><td valign="top">Dieng Kulon, Batur, Banjarnegara</td><td valign="top">&#x000b1;2062</td></tr><tr><td valign="top">&#x02212;7.210113, 109.909820</td><td valign="top">Dieng Kulon, Batur, Banjarnegara</td><td valign="top">&#x000b1;2061</td></tr><tr><td valign="top">&#x02212;7.198797, 109.915172</td><td valign="top">Dieng, Kejajar, Wonosobo</td><td valign="top">&#x000b1;2128</td></tr><tr><td valign="top">&#x02212;7.236805, 109.941532</td><td valign="top">Tieng, Kejajar, Wonosobo</td><td valign="top">&#x000b1;1642</td></tr><tr><td valign="top">&#x02212;7.441006, 110.371796</td><td valign="top">Kaponan, Pakis, Magelang</td><td valign="top">&#x000b1;1155</td></tr><tr><td valign="top">&#x02212;7.407529, 110.381297</td><td valign="top">Sumberejo, Ngablak, Magelang</td><td valign="top">&#x000b1;1281</td></tr></tbody></table></table-wrap></p><p id="para0012">Images were captured by several team members using various smartphone cameras. The detailed specifications of the smartphone camera are listed in <xref rid="tbl0003" ref-type="table">Table&#x000a0;3</xref>. The size format for the captured images had a variety of resolutions ranging from 2448&#x000a0;&#x000d7;&#x000a0;3264 to 3472&#x000a0;&#x000d7;&#x000a0;4624, encompassing both vertical and horizontal forms. This is because of the different specifications of the smartphone cameras used to capture the images. The aspect ratios of the images captured by the smartphone cameras were 4:3 and 16:9. Furthermore, the different positions of the cameras used by the teams resulted in various backgrounds and occlusion of the images. <xref rid="fig0002" ref-type="fig">Fig.&#x000a0;2</xref> shows how the team members gathered the images.<table-wrap position="float" id="tbl0003"><label>Table 3</label><caption><p>Specifications of smartphone cameras used to capture dataset images.</p></caption><alt-text id="alt0004">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Smart phone</th><th valign="top">Camera specifications</th></tr></thead><tbody><tr><td valign="top">iPhone 6</td><td valign="top">8 MP, f/2.2 aperture</td></tr><tr><td valign="top">iPhone 7</td><td valign="top">12 MP, &#x00192;/1.8 aperture</td></tr><tr><td valign="top">iPhone 7+</td><td valign="top">12 MP wide-angle, &#x00192;/1.8 aperture</td></tr><tr><td valign="top">iPhone X</td><td valign="top">12 MP wide-angle, &#x00192;/1.8 aperture</td></tr><tr><td valign="top">iPhone 12 mini</td><td valign="top">12 MP wide angle, &#x00192;/1.6 aperture</td></tr><tr><td valign="top">Samsung galaxy a33</td><td valign="top">48 MP, f/1.8 aperture</td></tr><tr><td valign="top">Samsung SM A14SF</td><td valign="top">50 MP main camera, f/1.8 aperture</td></tr><tr><td valign="top">Samsung M12</td><td valign="top">48 MP main camera, f/2.0 aperture</td></tr><tr><td valign="top">Samsung Galaxy A03s</td><td valign="top">13 MP, f/2.0 aperture</td></tr><tr><td valign="top">Vivo T1</td><td valign="top">50 MP, f/1.8 aperture</td></tr><tr><td valign="top">Redmi Note 7</td><td valign="top">48 MP (wide), f/1.8 aperture</td></tr><tr><td valign="top">Xiaomi Redmi Note 10S</td><td valign="top">48 MP (wide), f/1.79 aperture</td></tr></tbody></table></table-wrap><fig id="fig0002"><label>Fig. 2</label><caption><p>Process of capturing images by team members.</p></caption><alt-text id="alt0005">Fig 2</alt-text><graphic xlink:href="gr2" id="celink0002"/></fig></p></sec><sec id="sec0007"><label>4.2</label><title>Image labelling</title><p id="para0013">The experts from the Department of Plant Protection, Faculty of Agriculture, Universitas Gadjah Mada, who have expertise in plant disease, specifically for potato leave disease, conducted a thorough evaluation of each image and labelled them into seven distinct classes, including &#x0201c;virus,&#x0201d; &#x0201c;phytophthora,&#x0201d; &#x0201c;nematode,&#x0201d; &#x0201c;fungi,&#x0201d; &#x0201c;bacteria,&#x0201d; &#x0201c;pest,&#x0201d; and &#x0201c;healthy.&#x0201d; The labelling process was performed by meticulous observation of the visual characteristics of the captured images, utilizing the core symptoms of each disease. Images exhibiting ambiguous traits such as the concurrent presence of multiple disease features were excluded from the final dataset.</p><p id="para0014">The labelling process utilizes visual observation, performed by experts in plant disease by relying on symptoms for each of the disease categories, such as leaf discoloration, wilting, spots, lesions, or abnormal growth patterns, which can provide clues about the nature of the disease. Reference materials and disease manuals were also used. In addition, plant disease experts labelled the images based on field observations. They considered factors such as weather conditions, plant history, and common diseases in the area. The combination of field observations, experience, and visual inspection of the symptoms appearing in the leaves resulted in the final disease category. A summary of each visual characteristic of the potato leaf dataset is provided in <xref rid="tbl0004" ref-type="table">Table&#x000a0;4</xref>.<table-wrap position="float" id="tbl0004"><label>Table 4</label><caption><p>Summary of visual characteristics of potato leaves.</p></caption><alt-text id="alt0006">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Class</th><th valign="top">Characteristic</th></tr></thead><tbody><tr><td valign="top">Virus</td><td valign="top">reduced leaf size and crinkling, mild mottling or mosaic, necrosis</td></tr><tr><td valign="top">Phytophthora</td><td valign="top">leaves observed as dark brown to black lesions, can cause the lesions to enlarge into circular and necrotic patches</td></tr><tr><td valign="top">Nematode</td><td valign="top">have yellowish leaves with symptoms similar to those of water and nutrient deficiencies</td></tr><tr><td valign="top">Fungi</td><td valign="top">circular patterns manifested along leaf edges and/or slightly sunken leaf spot with yellow borders and concentric ring appearance, and/or yellow leaves with powdery patches</td></tr><tr><td valign="top">Bacteria</td><td valign="top">symptoms on leaves wilt without dead or necrotic leaves; the leaves plant initially does not turn yellow</td></tr><tr><td valign="top">Pest</td><td valign="top">leaf tissue became distorted and/or with holes and/or dotted leaves with silver colour or chlorotic material and/or with mined route on leaves</td></tr><tr><td valign="top">Healthy</td><td valign="top">uniform green colour in all parts of the leaves and perfect leaf shape without imperfections</td></tr></tbody></table></table-wrap></p><p id="para0015"><italic>Phytophthora infestans</italic> symptoms on leaves can be observed as dark brown to black lesions, and if left untreated, they can cause lesions to enlarge into circular and necrotic patches <xref rid="bib0002" ref-type="bibr">[2]</xref>. The symptoms examined in this investigation encompassed dark black lesions that covered the majority of the leaves, ranging from 20% to 90% of the surface area, which eventually dried out, did not sporulate, and exhibited a tan hue. Certain photographs depicted infections in the form of small lesions, ranging in color from bright green to dark green, exhibiting circular to irregular shapes, and displaying wet spots, as described by <xref rid="bib0003" ref-type="bibr">[3]</xref>.</p><p id="para0016">Fungal diseases in potato leaves can show different symptoms, depending on the causative organism. Early blight caused by <italic>Alternaria solani</italic> on leaves can be recognized as circular patterns manifested along leaf edges <xref rid="bib0004" ref-type="bibr">[4]</xref>, slightly sunken leaf spots with yellow borders, and concentric rings. In certain cases, these spots may converge. This characteristic becomes more pronounced as the pathogen infects the underside of the leaf, displaying light-brown spots <xref rid="bib0005" ref-type="bibr">[5]</xref>. However, it should be noted that this development does not lead to leaf drying, as previously described by <xref rid="bib0006" ref-type="bibr">[6]</xref>. Another fungal disease is characterized by yellow leaves that become necrotic with powdery patches <xref rid="bib0002" ref-type="bibr">[2]</xref>.</p><p id="para0017">Bacteria-caused diseases show symptoms on leaves as secondary symptoms because of infection of tubers and stems. Symptoms on leaves wilt without dead or necrotic leaves; wilt is rapid and the plant does not initially turn yellow. When an infected lower stem is placed in water, a prominent milky ooze is observed <xref rid="bib0002" ref-type="bibr">[2]</xref>. This symptom attack may or may not be visible depending on the development of the disease and its relationship with temperature. Wilt symptoms occur when vascular infection occurs, which inhibits nutrition in the stem and leaf petioles <xref rid="bib0007" ref-type="bibr">[7]</xref>. In this study, we did not use leaves with symptoms of primary bacterial attack.</p><p id="para0018">Nematode infections above the ground can be seen as expanding patches with poor growth in the field. The plants are smaller and have yellowish leaves, with symptoms similar to those of water and nutrient deficiency. Plants with damaged roots become wilted, particularly under warmer temperatures during the day, and may remain wilted even with irrigation <xref rid="bib0008" ref-type="bibr">[8]</xref>.</p><p id="para0019">Viral symptoms include reduced leaf size and crinkling, mild mottling or mosaicism, necrosis, and severe infections that can cause dwarfing in plants. In addition to these diseases, crop losses in potatoes worldwide can be caused by pests. Potato pests can be broadly grouped into three categories: sucking pests, tuber- and root-damaging pests, and foliage feeders or defoliating pests <xref rid="bib0009" ref-type="bibr">[9]</xref>. Damage from thrips can be observed in leaf tissues, which become distorted and dotted with silver or chlorotic material. When the leaves are fed continuously, their tips wither, coil up, and eventually die more severely under dry weather conditions. Both nymphs and adults graze on leaves along the midribs and veins. Foliage feeders, caterpillars, leaf beetles, and grasshoppers feed on leaves by scraping and skeletonizing them. Older larval instars are divided into groups that feed heavily on frequently defoliating leaves. If the infection is severe, the crop can simultaneously lose its leaves <xref rid="bib0009" ref-type="bibr">[9]</xref>. Another pest is the leaf miner insect, <italic>Liriomyza spp.</italic>, which causes leaves to be mined by their larvae <xref rid="bib0010" ref-type="bibr">[10]</xref>.</p></sec><sec id="sec0008"><label>4.3</label><title>Image pre-processing</title><p id="para0020">The images were captured at 4:3 or 16:9 ratios in the horizontal direction and 3:4 or 9:16 ratios in the vertical direction. The native resolution of the Convolutional Neural Network (CNN)-based method was 1:1 aspect ratio. Therefore, the gathered images were resized to a 1:1 ratio by using a script in Python with the Pillow Library to match most of the CNN inputs. All images were then resized to 1500&#x000a0;&#x000d7;&#x000a0;1500 pixels using the same script, resulting in uniform resolution for all images. Images were saved into .jpg format for compatibility with various image-processing software packages, and ease of accessibility. The resizing process is illustrated in <xref rid="fig0003" ref-type="fig">Fig.&#x000a0;3</xref>.<fig id="fig0003"><label>Fig. 3</label><caption><p>Preprocessing stage for resizing the original captured image in a 1:1 ratio.</p></caption><alt-text id="alt0007">Fig 3</alt-text><graphic xlink:href="gr3" id="celink0003"/></fig></p></sec><sec id="sec0009"><label>4.4</label><title>Comparison with existing dataset</title><p id="para0021">This section provides a comparison and novelty of the proposed dataset with the existing PlantVillage dataset. <xref rid="tbl0005" ref-type="table">Table&#x000a0;5</xref> provides a comparison between the PlantVillage and proposed datasets.<table-wrap position="float" id="tbl0005"><label>Table 5</label><caption><p>Comparison between PlantVillage datasets and our proposed dataset.</p></caption><alt-text id="alt0008">Table 5</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Comparison</th><th valign="top">PlantVillage dataset</th><th valign="top">Our proposed dataset</th></tr></thead><tbody><tr><td valign="top">Class</td><td valign="top">Three categories: early blight (fungi), late blight (fungi-like), and healthy</td><td valign="top">Seven categories: virus, phytophthora, nematode, fungi, bacteria, pest, and healthy</td></tr><tr><td valign="top">Total images</td><td valign="top">2052 images</td><td valign="top">3076 images</td></tr><tr><td valign="top">Environment</td><td valign="top">Controlled environment:<list list-type="simple" id="celist0002"><list-item id="celistitem0006"><label>&#x02022;</label><p id="para0022">clear and uniform background</p></list-item><list-item id="celistitem0007"><label>&#x02022;</label><p id="para0023">uniform angle of view</p></list-item><list-item id="celistitem0008"><label>&#x02022;</label><p id="para0024">uniform object placement and orientation</p></list-item><list-item id="celistitem0009"><label>&#x02022;</label><p id="para0025">uniform lighting condition</p></list-item></list></td><td valign="top">Uncontrolled environment:<list list-type="simple" id="celist0003"><list-item id="celistitem0010"><label>&#x02022;</label><p id="para0026">varied background and occlusion</p></list-item><list-item id="celistitem0011"><label>&#x02022;</label><p id="para0027">varied angle of view</p></list-item><list-item id="celistitem0012"><label>&#x02022;</label><p id="para0028">diverse object placement and orientation</p></list-item><list-item id="celistitem0013"><label>&#x02022;</label><p id="para0029">varied lighting condition</p></list-item></list></td></tr><tr><td valign="top">Dimension (in pixel)</td><td valign="top">256&#x000d7;256 (low resolution)</td><td valign="top">1500&#x000d7;1500 (high resolution)</td></tr></tbody></table></table-wrap></p><p id="para0030">As presented in <xref rid="tbl0005" ref-type="table">Table&#x000a0;5</xref>, the PlantVillage dataset includes only images of leaf symptoms caused by fungi. In contrast, our dataset included images of leaf symptoms caused by a variety of sources, including viruses, phytophthora, nematodes, fungi, bacteria, and pests. The PlantVillage dataset was collected in a controlled environment with uniform background, angle, orientation, and lighting conditions. Additionally, the images were captured at a low resolution with a pixel size of 256&#x000a0;&#x000d7;&#x000a0;256. The proposed dataset addresses the shortcomings of the PlantVillage dataset by presenting images in a broader range of symptom categories, capturing uncontrolled environments, and boasting a higher resolution. <xref rid="fig0004" ref-type="fig">Fig.&#x000a0;4</xref> shows samples of the images from the PlantVillage dataset and our proposed dataset from the fungi category, and <xref rid="fig0005" ref-type="fig">Fig.&#x000a0;5</xref> shows samples from the healthy class.<fig id="fig0004"><label>Fig. 4</label><caption><p>The sample of potato leaves in fungi category in (a) the PlantVillage dataset, and (b) the proposed dataset.</p></caption><alt-text id="alt0009">Fig 4</alt-text><graphic xlink:href="gr4" id="celink0004"/></fig><fig id="fig0005"><label>Fig. 5</label><caption><p>The sample of potato leaves in the healthy category in (a) the PlantVillage dataset, and (b) the proposed dataset.</p></caption><alt-text id="alt0010">Fig 5</alt-text><graphic xlink:href="gr5" id="celink0005"/></fig></p><p id="para0031">Although the PlantVillage dataset offers benchmark information and training materials for testing and evaluating algorithms for the classification of potato leaf diseases, it may exhibit limitations in encompassing a broader range of potato leaf diseases. Consequently, the model trained on this dataset can encounter constraints when dealing with unfamiliar categories or various real-world situations. This difference signifies that our proposed dataset provides diverse conditions for achieving a robust model performance in real-world settings.</p></sec><sec id="sec0010"><label>4.5</label><title>Preliminary study</title><sec id="sec0011"><label>4.5.1</label><title>Proposed preliminary study</title><p id="para0032">After collecting the dataset, we conducted a preliminary study using several pre-trained CNN: EfficientNetV2B3 <xref rid="bib0011" ref-type="bibr">[11</xref>,<xref rid="bib0012" ref-type="bibr">12]</xref>, MobileNetV3-Large <xref rid="bib0013" ref-type="bibr">[13]</xref>, VGG-16 <xref rid="bib0014" ref-type="bibr">[14]</xref>, ResNet50 <xref rid="bib0015" ref-type="bibr">[15]</xref>, and DenseNet121 <xref rid="bib0016" ref-type="bibr">[16]</xref>. This CNN-based model was selected because of its lightweight size and outstanding performance on the ImageNet dataset. In addition, previous research has shown that these family models perform well for leaf disease classification using the PlantVillage dataset <xref rid="bib0017" ref-type="bibr">[17</xref>,<xref rid="bib0018" ref-type="bibr">18]</xref>.</p><p id="para0033">The dataset was first split into training and test datasets in a ratio of 90:10, consisting of 2765 and 311 images for training and testing, respectively. Before training the CNN modes, the training set was split into 2489 for training and 276 images for validation. All images were then resized to 224&#x000a0;&#x000d7;&#x000a0;224 pixels to match the input specifications of all tested CNN models. The preliminary study was conducted on the Google Colab Free version utilizing the Keras and TensorFlow Library. All CNN models were trained using pre-trained models with pretrained weights on the ImageNet dataset. For consistency, all models were trained using the Adam optimizer with a learning rate of 0.0001, a categorical cross-entropy loss function, and batch sizes of 64 and 50 epochs.</p><p id="para0034">A schematic of the experimental setup is shown in <xref rid="fig0006" ref-type="fig">Fig.&#x000a0;6</xref>. Two scenarios were employed in this study: training without data augmentation, and training with data augmentation. The second scenario was conducted by adding additional preprocessing steps using data augmentation, including brightness, flipping both horizontal and vertical, rotating, zooming, and shifting both horizontal and vertical, which resulting of around 990 up to 1000 images per class. Data augmentation was utilized owing to the imbalance issue in the dataset. Several evaluation metrics were employed in this study, such as the test accuracy, precision, recall, and F1 score. <xref rid="eqn0001" ref-type="disp-formula">Eqs.&#x000a0;(1)</xref>&#x02013;<xref rid="eqn0004" ref-type="disp-formula">(4)</xref> present the formulae for each metric. Most of the evaluation metrics employed TP, FP, TN, and FN, where TP is a True Positive; FP is a False Positive; TN is a True Negative; and FN is a False Negative.<disp-formula id="eqn0001"><label>(1)</label><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:mi>T</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.33em"/><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mspace width="0.33em"/><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0002"><label>(2)</label><mml:math id="M2" altimg="si2.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mspace width="0.33em"/><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0003"><label>(3)</label><mml:math id="M3" altimg="si3.svg"><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mspace width="0.33em"/><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="eqn0004"><label>(4)</label><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mspace width="0.33em"/><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mspace width="0.33em"/><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mspace width="0.33em"/><mml:mi>x</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.33em"/><mml:mi>x</mml:mi><mml:mspace width="0.33em"/><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><fig id="fig0006"><label>Fig. 6</label><caption><p>Experimental study using the proposed dataset.</p></caption><alt-text id="alt0011">Fig 6</alt-text><graphic xlink:href="gr6" id="celink0006"/></fig></p></sec><sec id="sec0012"><label>4.5.2</label><title>Result of the preliminary study</title><p id="para0035"><xref rid="tbl0006" ref-type="table">Tables&#x000a0;6</xref> and <xref rid="tbl0007" ref-type="table">7</xref> list the performance results of the tested model for scenarios without and with augmentation, respectively. In the scenario in which the dataset did not undergo augmentation, as presented in <xref rid="tbl0006" ref-type="table">Table&#x000a0;6</xref>, EfficientNetV2B3 displayed the highest test accuracy of 0.7363, followed by MobileNetV3-Large at 0.7203. In contrast, VGG-16 demonstrated the lowest test accuracy with a value of 0.5981. In the second scenario, in which the dataset was augmented, EfficientNetV2B3 again emerged as the top-performing model, with a test accuracy of 0.723, as shown in <xref rid="tbl0007" ref-type="table">Table&#x000a0;7</xref>. MobileNetV3-Large followed closely, with a test accuracy of 0.7042, whereas VGG-16 continued to exhibit the poorest performance, with a test accuracy of 0.5627. These results indicate that the model performance remained subpar, even after the addition of augmentation to balance the dataset. This is because of the complexity of our proposed dataset, which encompasses a diverse range of backgrounds and image angles, resulting in an augmentation process that does not yield significant improvements.<table-wrap position="float" id="tbl0006"><label>Table 6</label><caption><p>Experimental result from non-augmented dataset.</p></caption><alt-text id="alt0012">Table 6</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Model</th><th valign="top">Test accuracy</th><th valign="top">Precision</th><th valign="top">Recall</th><th valign="top">F1-score</th></tr></thead><tbody><tr><td valign="top">EfficientNetV2B3</td><td valign="top">0.7363</td><td valign="top">0.7428</td><td valign="top">0.7363</td><td valign="top">0.7302</td></tr><tr><td valign="top">MobileNetV3-Large</td><td valign="top">0.7203</td><td valign="top">0.7316</td><td valign="top">0.7203</td><td valign="top">0.7131</td></tr><tr><td valign="top">VGG-16</td><td valign="top">0.5981</td><td valign="top">0.6054</td><td valign="top">0.5981</td><td valign="top">0.5904</td></tr><tr><td valign="top">ResNet50</td><td valign="top">0.6817</td><td valign="top">0.7006</td><td valign="top">0.6817</td><td valign="top">0.6748</td></tr><tr><td valign="top">DenseNet121</td><td valign="top">0.5916</td><td valign="top">0.6058</td><td valign="top">0.5916</td><td valign="top">0.5911</td></tr></tbody></table></table-wrap><table-wrap position="float" id="tbl0007"><label>Table 7</label><caption><p>Experimental result from augmented dataset.</p></caption><alt-text id="alt0013">Table 7</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Model</th><th valign="top">Test accuracy</th><th valign="top">Precision</th><th valign="top">Recall</th><th valign="top">F1-score</th></tr></thead><tbody><tr><td valign="top">EfficientNetV2B3</td><td valign="top">0.7235</td><td valign="top">0.7378</td><td valign="top">0.7235</td><td valign="top">0.7199</td></tr><tr><td valign="top">MobileNetV3-Large</td><td valign="top">0.7042</td><td valign="top">0.7092</td><td valign="top">0.7042</td><td valign="top">0.7037</td></tr><tr><td valign="top">VGG-16</td><td valign="top">0.5627</td><td valign="top">0.5697</td><td valign="top">0.5627</td><td valign="top">0.5607</td></tr><tr><td valign="top">ResNet50</td><td valign="top">0.6624</td><td valign="top">0.6659</td><td valign="top">0.6624</td><td valign="top">0.6607</td></tr><tr><td valign="top">DenseNet121</td><td valign="top">0.5852</td><td valign="top">0.5858</td><td valign="top">0.5852</td><td valign="top">0.5847</td></tr></tbody></table></table-wrap></p><p id="para0036"><xref rid="tbl0008" ref-type="table">Table&#x000a0;8</xref> compares the performance of the best-performing model in this preliminary study, EfficientNetV2B3, when trained on the PlantVillage dataset and our proposed dataset. As shown in <xref rid="tbl0008" ref-type="table">Table&#x000a0;8</xref>, EfficientNetV2B3 achieved a test accuracy of 98.15% when trained on the PlantVillage dataset. However, when trained on the proposed dataset, the accuracy of the model was 73.63%. These results suggest that while the model performed well on the PlantVillage dataset, it struggled when trained on our proposed dataset. Given the exceptional and distinctive characteristics of our proposed dataset, it is understandable that the model struggled to perform optimally. The lack of a controlled environment within the dataset poses a significant challenge for the model to effectively learn.<table-wrap position="float" id="tbl0008"><label>Table 8</label><caption><p>Comparison of results with other datasets.</p></caption><alt-text id="alt0014">Table 8</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Model</th><th valign="top">Dataset</th><th valign="top">Test accuracy</th></tr></thead><tbody><tr><td valign="top">EfficientNetV2B3</td><td valign="top">PlantVillage dataset</td><td valign="top">98.15%</td></tr><tr><td valign="top">EfficientNetV2B3</td><td valign="top"><bold>Our dataset</bold></td><td valign="top"><bold>73.63%</bold></td></tr></tbody></table></table-wrap></p><p id="para0037">The results of the experimental comparison indicate that the EfficientNetV2B3 model, which exhibits exceptional classification performance on the PlantVillage dataset, underperforms when applied to the proposed dataset. Therefore, it is necessary to develop models with improved performance for identifying potato leaf pests and diseases in uncontrolled environments. The real-world scenarios presented in our dataset can aid the algorithm in handling diverse situations, leading to improved recognition accuracy and facilitating optimization and refinement of the algorithm. This will enable researchers to train more advanced algorithms. We hope that the release of this dataset will lead to the development of an automatic potato leaf disease identification system that can be used in real-life scenarios and will contribute to the advancement of precision agriculture.</p></sec></sec></sec><sec id="sec0013"><title>Limitations</title><p id="para0038">Adding potato leaf disease samples from countries outside Indonesia could enhance the diversity of the dataset.</p></sec><sec id="sec0014"><title>Ethics Statement</title><p id="para0039">The dataset presented in this work does not include tests on animals or humans. All images used were obtained by the authors and do not come from any other source.</p></sec><sec id="sec0014a"><title>CRediT authorship contribution statement</title><p id="para0039a"><bold>Nabila Husna Shabrina:</bold> Conceptualization, Methodology, Software, Formal analysis, Investigation, Resources, Data curation, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing, Visualization, Project administration, Funding acquisition. <bold>Siwi Indarti:</bold> Conceptualization, Methodology, Validation, Formal analysis, Investigation, Resources, Data curation, Writing &#x02013; review &#x00026; editing. <bold>Rina Maharani:</bold> Methodology, Validation, Formal analysis, Investigation, Data curation, Writing &#x02013; original draft, Writing &#x02013; review &#x00026; editing. <bold>Dinar Ajeng Kristiyanti:</bold> Investigation, Data curation. <bold>Irmawati:</bold> Investigation, Data curation. <bold>Niki Prastomo:</bold> Writing &#x02013; review &#x00026; editing, Supervision. <bold>Tika Adilah M:</bold> Visualization.</p></sec></body><back><ref-list id="cebibl1"><title>References</title><ref id="bib0001"><label>1</label><mixed-citation publication-type="other" id="sbref0001">D.P. Hughes, M. Salathe, An open access repository of images on plant health to enable the development of mobile disease diagnostics, (2016). <pub-id pub-id-type="doi">10.48550/arXiv.1511.08060</pub-id>.</mixed-citation></ref><ref id="bib0002"><label>2</label><mixed-citation publication-type="other" id="sbref0002">J. Rubb, B. Jacobsen, Bacterial and fungal diseases of potato and their management, Montana State University, 2017. <ext-link ext-link-type="uri" xlink:href="https://www.montana.edu/extension/pspp/documents/BacandFung.pdf" id="interref0004">https://www.montana.edu/extension/pspp/documents/BacandFung.pdf</ext-link> (accessed November 1, 2023).</mixed-citation></ref><ref id="bib0003"><label>3</label><element-citation publication-type="journal" id="sbref0003"><person-group person-group-type="author"><name><surname>Schumann</surname><given-names>G.L.</given-names></name><name><surname>D'Arcy</surname><given-names>C.J.</given-names></name></person-group><article-title>Late blight of potato and tomato</article-title><source>Plant Health Instr.</source><year>2000</year><pub-id pub-id-type="doi">10.1094/PHI-I-2000-0724-01</pub-id></element-citation></ref><ref id="bib0004"><label>4</label><element-citation publication-type="journal" id="sbref0004"><person-group person-group-type="author"><name><surname>Arshad</surname><given-names>F.</given-names></name><name><surname>Mateen</surname><given-names>M.</given-names></name><name><surname>Hayat</surname><given-names>S.</given-names></name><name><surname>Wardah</surname><given-names>M.</given-names></name><name><surname>Al-Huda</surname><given-names>Z.</given-names></name><name><surname>Gu</surname><given-names>Y.H.</given-names></name><name><surname>Al-antari</surname><given-names>M.A.</given-names></name></person-group><article-title>PLDPNet: end-to-end hybrid deep learning framework for potato leaf disease prediction</article-title><source>Alex. Eng. J.</source><volume>78</volume><year>2023</year><fpage>406</fpage><lpage>418</lpage><pub-id pub-id-type="doi">10.1016/j.aej.2023.07.076</pub-id></element-citation></ref><ref id="bib0005"><label>5</label><element-citation publication-type="journal" id="sbref0005"><person-group person-group-type="author"><name><surname>Droby</surname><given-names>S.</given-names></name></person-group><article-title>Pathogenicity of <italic>Alternaria alternata</italic> on potato in Israel</article-title><source>Phytopathology</source><volume>74</volume><year>1984</year><fpage>537</fpage><pub-id pub-id-type="doi">10.1094/Phyto-74-537</pub-id></element-citation></ref><ref id="bib0006"><label>6</label><element-citation publication-type="journal" id="sbref0006"><person-group person-group-type="author"><name><surname>Lagopodi</surname><given-names>A.L.</given-names></name><name><surname>Thanassoulopoulos</surname><given-names>C.C.</given-names></name></person-group><article-title>Effect of a leaf spot disease caused by <italic>Alternaria alternata</italic> on yield of sunflower in Greece</article-title><source>Plant Dis.</source><volume>82</volume><year>1998</year><fpage>41</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1094/PDIS.1998.82.1.41</pub-id><pub-id pub-id-type="pmid">30857067</pub-id>
</element-citation></ref><ref id="bib0007"><label>7</label><element-citation publication-type="book" id="sbref0007"><part-title>The potato crop: its agricultural</part-title><person-group person-group-type="editor"><name><surname>Campos</surname><given-names>H.</given-names></name><name><surname>Ortiz</surname><given-names>O.</given-names></name></person-group><source>Nutritional and Social Contribution to Humankind</source><year>2020</year><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc><pub-id pub-id-type="doi">10.1007/978-3-030-28683-5</pub-id></element-citation></ref><ref id="bib0008"><label>8</label><element-citation publication-type="book" id="sbref0008"><person-group person-group-type="author"><name><surname>Lima</surname><given-names>F.S.O.</given-names></name><name><surname>Mattos</surname><given-names>V.S.</given-names></name><name><surname>Silva</surname><given-names>E.S.</given-names></name><name><surname>Carvalho</surname><given-names>M.A.S.</given-names></name><name><surname>Teixeira</surname><given-names>R.A.</given-names></name><name><surname>Silva</surname><given-names>J.C.</given-names></name><name><surname>Correa</surname><given-names>V.R.</given-names></name></person-group><part-title>Nematodes affecting potato and sustainable practices for their management</part-title><comment>(Ed.)</comment><person-group person-group-type="editor"><name><surname>Yildiz</surname><given-names>M.</given-names></name></person-group><source>Potato - Incas World</source><year>2018</year><publisher-name>InTech</publisher-name><pub-id pub-id-type="doi">10.5772/intechopen.73056</pub-id></element-citation></ref><ref id="bib0009"><label>9</label><element-citation publication-type="book" id="sbref0009"><person-group person-group-type="author"><name><surname>Naga</surname><given-names>K.</given-names></name><name><surname>Tiwari</surname><given-names>R.</given-names></name><name><surname>Shivaramu</surname><given-names>S.</given-names></name><name><surname>Lal</surname><given-names>M.</given-names></name><name><surname>Tetarwal</surname><given-names>A.</given-names></name><name><surname>Kumar</surname><given-names>R.</given-names></name><name><surname>Bhatnagar</surname><given-names>A.</given-names></name></person-group><part-title>Recent advances in root and tuber crops</part-title><source>Recent Adv. Root Tuber Crops</source><year>2021</year><publisher-name>Brillion Publishing</publisher-name><publisher-loc>New Delhi</publisher-loc><fpage>205</fpage><lpage>226</lpage></element-citation></ref><ref id="bib0010"><label>10</label><element-citation publication-type="journal" id="sbref0010"><person-group person-group-type="author"><name><surname>Mugala</surname><given-names>T.</given-names></name><name><surname>Visser</surname><given-names>D.</given-names></name><name><surname>Malan</surname><given-names>A.P.</given-names></name><name><surname>Addison</surname><given-names>P.</given-names></name></person-group><article-title>Occurrence of the potato leaf miner, Liriomyza huidobrensis (Diptera: Agromyzidae), and parasitoids in potato fields and natural vegetation of the Western Cape province, South Africa</article-title><source>Afr. Entomol.</source><year>2023</year><fpage>31</fpage><pub-id pub-id-type="doi">10.17159/2254-8854/2023/a10672</pub-id></element-citation></ref><ref id="bib0011"><label>11</label><element-citation publication-type="book" id="sbref0011"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>M.</given-names></name><name><surname>Le</surname><given-names>Q.V.</given-names></name></person-group><part-title>EfficientNet: rethinking model scaling for convolutional neural networks</part-title><source>Proc. 36th Int. Conf. Mach. Learn</source><volume>97</volume><year>2019</year><fpage>6105</fpage><lpage>6114</lpage><pub-id pub-id-type="doi">10.48550/ARXIV.1905.11946</pub-id></element-citation></ref><ref id="bib0012"><label>12</label><element-citation publication-type="book" id="sbref0012"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>M.</given-names></name><name><surname>Le</surname><given-names>Q.V.</given-names></name></person-group><part-title>EfficientNetV2: smaller models and faster training</part-title><source>Proc. 38 Th Int. Conf. Mach. Learn</source><volume>139</volume><year>2021</year><fpage>10096</fpage><lpage>10106</lpage><pub-id pub-id-type="doi">10.48550/ARXIV.2104.00298</pub-id></element-citation></ref><ref id="bib0013"><label>13</label><element-citation publication-type="book" id="sbref0013"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>A.</given-names></name><name><surname>Sandler</surname><given-names>M.</given-names></name><name><surname>Chen</surname><given-names>B.</given-names></name><name><surname>Wang</surname><given-names>W.</given-names></name><name><surname>Chen</surname><given-names>L.-C.</given-names></name><name><surname>Tan</surname><given-names>M.</given-names></name><name><surname>Chu</surname><given-names>G.</given-names></name><name><surname>Vasudevan</surname><given-names>V.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Pang</surname><given-names>R.</given-names></name><name><surname>Adam</surname><given-names>H.</given-names></name><name><surname>Le</surname><given-names>Q.</given-names></name></person-group><part-title>Searching for MobileNetV3</part-title><source>2019 IEEECVF Int. Conf. Comput. Vis. ICCV, IEEE</source><conf-name>Seoul, Korea (South)</conf-name><year>2019</year><fpage>1314</fpage><lpage>1324</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2019.00140</pub-id></element-citation></ref><ref id="bib0014"><label>14</label><element-citation publication-type="book" id="sbref0014"><person-group person-group-type="author"><name><surname>Simonyan</surname><given-names>K.</given-names></name><name><surname>Zisserman</surname><given-names>A.</given-names></name></person-group><part-title>Very deep convolutional networks for large-scale image recognition</part-title><source>Proceeding 3rd Int. Conf. Learn. Represent. ICLR2015, arXiv</source><conf-name>San Diego, CA, USA</conf-name><year>2015</year><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1409.1556" id="interref0005">http://arxiv.org/abs/1409.1556</ext-link><comment>(accessed November 8, 2023)</comment></element-citation></ref><ref id="bib0015"><label>15</label><element-citation publication-type="book" id="sbref0015"><person-group person-group-type="author"><name><surname>He</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Ren</surname><given-names>S.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group><part-title>Deep residual learning for image recognition</part-title><source>2016 IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, IEEE</source><conf-name>Las Vegas, NV, USA</conf-name><year>2016</year><fpage>770</fpage><lpage>778</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2016.90</pub-id></element-citation></ref><ref id="bib0016"><label>16</label><mixed-citation publication-type="other" id="sbref0016">G. Huang, Z. Liu, L. van der Maaten, K.Q. Weinberger, Densely connected convolutional networks, (2018). <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1608.06993" id="interref0006">http://arxiv.org/abs/1608.06993</ext-link> (accessed November 8, 2023).</mixed-citation></ref><ref id="bib0017"><label>17</label><element-citation publication-type="journal" id="sbref0017"><person-group person-group-type="author"><name><surname>Chakraborty</surname><given-names>K.K.</given-names></name><name><surname>Mukherjee</surname><given-names>R.</given-names></name><name><surname>Chakroborty</surname><given-names>C.</given-names></name><name><surname>Bora</surname><given-names>K.</given-names></name></person-group><article-title>Automated recognition of optical image based potato leaf blight diseases using deep learning</article-title><source>Physiol. Mol. Plant Pathol.</source><volume>117</volume><year>2022</year><object-id pub-id-type="publisher-id">101781</object-id><pub-id pub-id-type="doi">10.1016/j.pmpp.2021.101781</pub-id></element-citation></ref><ref id="bib0018"><label>18</label><element-citation publication-type="journal" id="sbref0018"><person-group person-group-type="author"><name><surname>Too</surname><given-names>E.C.</given-names></name><name><surname>Yujian</surname><given-names>L.</given-names></name><name><surname>Njuki</surname><given-names>S.</given-names></name><name><surname>Yingchun</surname><given-names>L.</given-names></name></person-group><article-title>A comparative study of fine-tuning deep learning models for plant disease identification</article-title><source>Comput. Electron. Agric.</source><volume>161</volume><year>2019</year><fpage>272</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2018.03.032</pub-id></element-citation></ref></ref-list><sec sec-type="data-availability" id="refdata001"><title>Data Availability</title><p id="para9001">
<list list-type="simple" id="dacelist0001"><list-item id="rdlistitem0001"><p id="para9002"><ext-link ext-link-type="uri" xlink:href="https://data.mendeley.com/datasets/ptz377bwb8/1" id="interref0002">Potato Leaf Disease Dataset in Uncontrolled Environment (Original data)</ext-link> (Mendeley Data).</p></list-item></list>
</p></sec><ack id="ack0001"><sec id="sec2013"><title>Declaration of Competing Interest</title><p id="para0041">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></sec><sec id="sec2013s"><title>Acknowledgements</title><p id="para0040">This dataset was part of a research project funded by the <funding-source id="gs0001">Ministry of Research, Technology, and Higher Education of Indonesia in Fundamental Research Schemes</funding-source> (grant number 1423/LL3/AL.04/2023). The authors would also like to thank Universitas Multimedia Nusantara and Universitas Gadjah Mada for their support during this study.</p></sec></ack></back></article>
