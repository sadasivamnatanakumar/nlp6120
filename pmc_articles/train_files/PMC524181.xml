<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Biomed Eng Online</journal-id><journal-title>BioMedical Engineering OnLine</journal-title><issn pub-type="epub">1475-925X</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15461787</article-id><article-id pub-id-type="pmc">PMC524181</article-id><article-id pub-id-type="publisher-id">1475-925X-3-31</article-id><article-id pub-id-type="doi">10.1186/1475-925X-3-31</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>ImageParser: a tool for finite element generation from three-dimensional medical images</article-title></title-group><contrib-group><contrib id="A1" contrib-type="author"><name><surname>Yin</surname><given-names>HM</given-names></name><xref ref-type="aff" rid="I1">1</xref><xref ref-type="aff" rid="I3">3</xref><email>huiming@uiuc.edu</email></contrib><contrib id="A2" corresp="yes" contrib-type="author"><name><surname>Sun</surname><given-names>LZ</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>lizhi-sun@uiowa.edu</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Wang</surname><given-names>G</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>ge-wang@uiowa.edu</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Yamada</surname><given-names>T</given-names></name><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I4">4</xref><email>yamataka@rad.med.tohoku.ac.jp</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I5">5</xref><email>hstjen@yahoo.com.tw</email></contrib><contrib id="A6" contrib-type="author"><name><surname>Vannier</surname><given-names>MW</given-names></name><xref ref-type="aff" rid="I2">2</xref><xref ref-type="aff" rid="I6">6</xref><email>mvannier@radiology.bsd.uchicago.edu</email></contrib></contrib-group><aff id="I1"><label>1</label>Center for Computer-Aided Design, The University of Iowa, Iowa City, IA 52242, USA</aff><aff id="I2"><label>2</label>Department of Radiology, The University of Iowa, Iowa City, IA 52242, USA</aff><aff id="I3"><label>3</label>Department of Civil Engineering, University of Illinois, Urbana, IL 61801, USA</aff><aff id="I4"><label>4</label>Department of Diagnostic Radiology, Tohoku University, Sendai 9808574, JAPAN</aff><aff id="I5"><label>5</label>Department of Radiology, National Taiwan University, Taipei, TAIWAN ROC</aff><aff id="I6"><label>6</label>Department of Radiology, The University of Chicago, Chicago, IL 60637, USA</aff><pub-date pub-type="collection"><year>2004</year></pub-date><pub-date pub-type="epub"><day>1</day><month>10</month><year>2004</year></pub-date><volume>3</volume><fpage>31</fpage><lpage>31</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedical-engineering-online.com/content/3/1/31"/><history><date date-type="received"><day>7</day><month>7</month><year>2004</year></date><date date-type="accepted"><day>1</day><month>10</month><year>2004</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2004 Yin et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2004</copyright-year><copyright-holder>Yin et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Yin
               HM
               
               
               huiming@uiuc.edu
            </dc:author><dc:title>
            ImageParser: a tool for finite element generation from three-dimensional medical images
         </dc:title><dc:date>2004</dc:date><dcterms:bibliographicCitation>BioMedical Engineering OnLine 3(1): 31-. (2004)</dcterms:bibliographicCitation><dc:identifier type="sici">1475-925X(2004)3:1&#x0003c;31&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1475-925X</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>The finite element method (FEM) is a powerful mathematical tool to simulate and visualize the mechanical deformation of tissues and organs during medical examinations or interventions. It is yet a challenge to build up an FEM mesh directly from a volumetric image partially because the regions (or structures) of interest (ROIs) may be irregular and fuzzy.</p></sec><sec sec-type="methods"><title>Methods</title><p>A software package, ImageParser, is developed to generate an FEM mesh from 3-D tomographic medical images. This software uses a semi-automatic method to detect ROIs from the context of image including neighboring tissues and organs, completes segmentation of different tissues, and meshes the organ into elements.</p></sec><sec><title>Results</title><p>The ImageParser is shown to build up an FEM model for simulating the mechanical responses of the breast based on 3-D CT images. The breast is compressed by two plate paddles under an overall displacement as large as 20% of the initial distance between the paddles. The strain and tangential Young's modulus distributions are specified for the biomechanical analysis of breast tissues.</p></sec><sec><title>Conclusion</title><p>The ImageParser can successfully exact the geometry of ROIs from a complex medical image and generate the FEM mesh with customer-defined segmentation information.</p></sec></abstract><kwd-group><kwd>Breast imaging</kwd><kwd>image segmentation</kwd><kwd>biomechanical analysis</kwd><kwd>meshing</kwd><kwd>finite element method (FEM)</kwd></kwd-group></article-meta></front><body><sec><title>Background</title><p>Diagnostic imaging devices such as CT, MRI and PET scanners are able to produce three-dimensional (3-D) descriptions of various features such as tissues and organs. In a computer, these images are some data to describe the intensity at each spatial point of a volume. The interpretation of the dataset requires special training and depends on the experience. Researchers have introduced a variety of algorithms to visualize 3-D medical images, and to extract the geometric information of objects from volumetric image data [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B3">3</xref>].</p><p>In recent years, the finite element method (FEM) has widely been used to simulate the mechanical deformation of tissues and organs during examinations or interventions [<xref ref-type="bibr" rid="B4">4</xref>-<xref ref-type="bibr" rid="B6">6</xref>]. To build up an FEM mesh from a medical image, the contour information of segmented regions of interest (ROIs) need to be first extracted from a volume of data [<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B8">8</xref>]. Then, the volume is meshed into nodes and elements, and material properties are endowed to each element in accordance with the segmentation information [<xref ref-type="bibr" rid="B9">9</xref>]. By further applying the boundary conditions and mechanical loadings on the corresponding nodes or elements, commercial FEM software packages such as ANSYS and ABAQUS may calculate the mechanical stress and strain, and predict the deformation and motion in the field of view.</p><p>The purpose of this work is to establish an FEM model to simulate the deformation of a woman breast based on mammography compression. A patient's breast may include three kinds of tissues: fatty, parenchyma, and cancerous tissues [<xref ref-type="bibr" rid="B6">6</xref>]. During the examination, the breast is squeezed by two flat paddles to obtain an image with a good contrast. The dependence of the relative deformation carries information on the mechanical properties of the tumors and masses. Thus, the FEM is a powerful tool to simulate this kind of deformation. The breast need first be separated from the context of a biomedical image which includes some other organs and the different tissues of the breast are then segmented. As seen in Figure <xref ref-type="fig" rid="F1">1</xref>, parenchyma has a cloud-like shape and three tissues are fully mixed in some regions. While existing modeling techniques [e.g., [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>]] may be applied, a significant amount of 3-D elements have to be introduced because the geometric shapes of the constituent tissues are fairly irregular with fuzzy boundaries. It is not optimal to apply those techniques to our research and clinical studies due to the requirements on the computational efficiency.</p><fig position="float" id="F1"><label>Figure 1</label><caption><p><bold>The Interface of ImageParser When Loading a 3D Image. </bold>The image is automatically shown slice by slice with the slice number shown in the text box, and the interval between two slices can be changed. Clicking the slide bar or text box, we can focus on the current slice; double clicking the window area, we can navigate the image slice by slice again; and dragging the slide bar or inputting the slice number in the text box, we can jump to the desired slice.</p></caption><graphic xlink:href="1475-925X-3-31-1"/></fig><p>In this paper, a software package called the ImageParser is developed to generate an FEM model from 3-D medical images. While aiming at the imaging segmentation, mesh generation, and deformation simulation of heterogeneous breast tissues, the method is applicable to the many biomedical imaging and biomechanical analysis of soft/hard tissues such as mammography and cardiovascular imaging. This software uses a semi-automatic method to detect the objective constituents from the context of an image including neighboring tissues and organs. It segments an image based on customer-defined grayscale ranges, and meshes tissues into elements with a customer-defined size. Inputting the generated FEM mesh into an FEM program, we can calculate the mechanical deformation under specific boundary conditions and mechanical loadings. The ImageParser is written in Microsoft Visual C# .NET (Microsoft Development Environment 2003 Version 7.1), and can be integrated into a high-level image analysis environment with a good extendibility and scalability.</p></sec><sec><title>Description</title><sec><title>Overview</title><p>The ImageParser provides a window style GUI as shown in Figure <xref ref-type="fig" rid="F1">1</xref>. A 3-D image is loaded and shown slice by slice. We can focus on any slice and edit it. While the image can be displayed in the color mode, in graphics analysis, we use 8-bit grayscale to describe a voxel. The RGB color can always be transformed into grayscale according to a desirable equation [<xref ref-type="bibr" rid="B10">10</xref>]. The size of voxel can be user-defined. The image can then be segmented into the real organs. Here we use Figure <xref ref-type="fig" rid="F1">1</xref> as an example to show the procedure for generating an FEM mesh using the ImageParser. In Figure <xref ref-type="fig" rid="F1">1</xref>, the breast is the selected ROI within the axial CT image including the breast, ribs, and organs in the thorax. To obtain its geometric information, we first isolate it from other unwanted regions by selecting a rectangular region as shown in Figure <xref ref-type="fig" rid="F2">2</xref>. It is noted that this selection also works for all other slices so that when we select the ROI, we need work on the most representative slice and reserve enough space not to truncate the wanted region in other slices. Because the shape of the breast is irregular, we can still see the rib and part of the thorax in the ROI as well as some regions with the background color. We need further detect the borderline of the breast in each slice.</p><fig position="float" id="F2"><label>Figure 2</label><caption><p><bold>The Region of Interest in a Slice. </bold>Under the function of selecting ROI, press the left button of the mouse and drag the mouse. When the dashed line rectangle covers ROI, release the button. All the slices will be shown as this selection.</p></caption><graphic xlink:href="1475-925X-3-31-2"/></fig><p>This software provides a semi-automatic interface to detect the borderline of the breast as shown in Figure <xref ref-type="fig" rid="F3">3</xref>. We use the computer mouse to select some key points on the borderline, and then the software will automatically detect the borderline between the key points. Because the borderline changes from one slice to another, the software is designed to automatically detect the borderline of the neighboring slice using the known borderline as a seed. Repeating this procedure, the software can detect the borderlines for all slices. The algorithmic details will be provided in the next section. Based on these borderlines, we can reconstruct the surface of the breast. It is noted that for some special cases that the borderlines are fuzzy or irregular, the software cannot effectively detect the borderlines. However, we can manually select more key points in the first slice, and process other slices similarly. Then, based on our experience we can always manage to obtain the borderlines with a high precision.</p><fig position="float" id="F3"><label>Figure 3</label><caption><p><bold>Selecting and Detecting the Borderline of the Breast in ROI. </bold>Under the function of selecting Outline, click the left button of the mouse on a point close to the borderline. The software will detect the closest point of the borderline and mark it with a yellow cross. After click the next point close to the borderline, the software will automatically detect the closest borderline between the previous point and this one. Repeat this procedure. The borderline is finally detected.</p></caption><graphic xlink:href="1475-925X-3-31-3"/></fig><p>Figure <xref ref-type="fig" rid="F3">3</xref> shows three types of tissues in the breast: the black area representing fatty tissue, the gray area representing parenchyma, and the light area representing the tumor. Because these tissues have different mechanical properties, we need segment them out of the breast as new ROIs. Here we use the grayscale to classify the voxels. From the grayscale histogram in Figure <xref ref-type="fig" rid="F4">4</xref>, we can find the grayscale ranges corresponding to the different tissue types. With the grayscale range for each tissue, the software can map the voxels onto corresponding categories. For example, in this figure we can use the grayscale from 0 to 64 to represent the fatty tissue, 64 to 144 the parenchyma tissue, and 144&#x02013;256 the cancerous tissue.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p><bold>The Grayscale Histogram of ROI. </bold>Horizontal axis denotes a grayscale (<italic>G</italic>), and vertical axis a number of voxels. <italic>G </italic>= 0 is the background color of black; <italic>G </italic>= 255 the color of white. From the grayscale distribution corresponding to the tissues in Figure 3, we can define the grayscale range for fat, parenchyma, and tumor tissues.</p></caption><graphic xlink:href="1475-925X-3-31-4"/></fig><p>While we are able to directly output the segmentation information based on the voxels, it cannot be effectively used by any FEM software since the whole breast includes more than ten million voxels. We therefore mesh the breast into larger elements based on the specific requirements of precision and computation capability. Figure <xref ref-type="fig" rid="F5">5</xref> shows the FEM mesh of one slice with three tissues marked by different colors. Extending this procedure to all slices and considering the slice thickness and element size, we can obtain the 3-D FEM mesh of the breast. While we take cuboidal elements as an example to generate the mesh at this stage, we can also mesh the breast into other elements such as tetrahedrons.</p><fig position="float" id="F5"><label>Figure 5</label><caption><p><bold>The FEM Mesh of the Breast. </bold>The selected region is meshed by cuboidal elements. The color of black denotes fat; gray parenchyma; and white tumor. The green lines are the boundary of elements. Though only one slice is shown here, elements are also generated for some other slices so that the 3D FEM mesh of the Breast is obtained.</p></caption><graphic xlink:href="1475-925X-3-31-5"/></fig><p>After the mesh of the breast is generated, we can implement it into an FEM software package to simulate the mechanical deformation of the breast with given material constants of all the tissues and appropriate boundary conditions.</p></sec><sec><title>Borderline Detection</title><p>A medical image typically includes many kinds of organs and tissues. However, biomedical engineers may only be interested in a small number of regions in a complex medical image. While certain algorithms have been developed to automatically detect the surface of the 3-D image [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B3">3</xref>,<xref ref-type="bibr" rid="B11">11</xref>], the object surface may not be well defined because the ROI is in the context of the complex image, and the boundary is not clear especially for some soft tissues. We have to use our knowledge to isolate ROIs from the image. Therefore, we propose to develop a semi-automatic method as described in the following steps.</p><p>1. We first focus on one slice. When the first point (<italic>x</italic><sub>0</sub>, <italic>y</italic><sub>0</sub>) is selected close to the borderline, a function is then used to search the most possible border point in the square region with the left-top point (<italic>x</italic><sub>0 </sub>- <italic>s</italic>, <italic>y</italic><sub>0 </sub>- <italic>s</italic>) and the right-bottom point (<italic>x</italic><sub>0 </sub>+ <italic>s</italic>, <italic>y</italic><sub>0 </sub>+ <italic>s</italic>). Here <italic>s </italic>is a customer-defined parameter with a default value as 3 pixels. In this region, the gradient of each point &#x00394;(<italic>x</italic>, <italic>y</italic>) is defined by a Laplace operator [<xref ref-type="bibr" rid="B12">12</xref>]</p><p><inline-graphic xlink:href="1475-925X-3-31-i1.gif"/></p><p>so that</p><p><inline-graphic xlink:href="1475-925X-3-31-i2.gif"/></p><p>where <italic>f</italic>(<italic>x</italic>, <italic>y</italic>) denotes the intensity at (<italic>x</italic>, <italic>y</italic>). The detected point is the one with the different color from the background and with the maximum value of &#x00394;(<italic>x</italic>, <italic>y</italic>)/[(<italic>x </italic>- <italic>x</italic><sub>0</sub>)<sup>2 </sup>+ (<italic>y </italic>- <italic>y</italic><sub>0</sub>)<sup>2 </sup>+ <italic>&#x003b5;</italic>] where <italic>&#x003b5; </italic>is a customer-defined parameter with a default value as 0.1 to prevent the singularity on the point (<italic>x</italic><sub>0</sub>, <italic>y</italic><sub>0</sub>). The detected point is denoted as (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>). It is noted that the Laplacian normalized by the distance of the point to the selected seed point is to make the neighboring points have a higher priority to be detected. At certain regions, the borderline may not be clear or two borderlines are close enough, in which cases the program will not get lost.</p><p>2. We start to select the next point of the borderline. After we manually select one point visually close to the borderline following the method of detecting (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>), the software can adjust the location of the point and detect the second point (<italic>x</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>) on the borderline. As seen in Figure <xref ref-type="fig" rid="F6">6</xref>, a function detects the borderline between (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>) and (<italic>x</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>). Two squares with edge length 2<italic>s </italic>are marked by the dark color in a big square having a diagonal line from (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>) to (<italic>x</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>). We find the most possible border point in the two dark squares by using the same method in the first step. If this new border point is in the right-top square, we replace (<italic>x</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>) by this point. Otherwise, we replace (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>) by the new border point. Once (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>) or (<italic>x</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>) is updated, we continue to find the next border point in the same way. Repeat this procedure until the distance between the two points is less than <italic>2s</italic>. Connecting all points in such an orderly way, we obtain the borderline. It is noted that this method is convergent because the distance between two working points becomes smaller and smaller in this procedure.</p><fig position="float" id="F6"><label>Figure 6</label><caption><p><bold>Detecting Borderline between Two Points (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>) and (<italic>x</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>). </bold>First find the most possible border point in two dark regions. Then, treat the new point and the left old one as same as (<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>) and (<italic>x</italic><sub>2</sub>, <italic>y</italic><sub>2</sub>), and find the next border point. Repeat this procedure until the distance between two points is less than <italic>2s</italic>. Connecting all points orderly, we obtain the borderline.</p></caption><graphic xlink:href="1475-925X-3-31-6"/></fig><p>3. We repeat step 2 until the borderline is closed. We thus obtain the whole closed borderline in the slice.</p><p>4. For a 3-D medical image, due to the similarity of neighboring slices, the proposed software can map the selected key border points of the slice onto the neighboring slice and use the method in step 1 to find the corresponding border points in the new slice. After that we adopt step 2 to detect the borderline between the border points. In this way, we are able to detect the borderlines in all the slices. From these borderlines we can finally construct the surface of the selected ROI.</p><p>Because the borderlines of other slices are detected on the basis of the first slice, selection of this slice greatly affects the quality of results. We suggest that this slice need contain the most representative information. If the change of two neighboring slices is large, we can optionally reselect the border point in the new slice instead of detecting the borderline by the computer. It is further noted that because the borderlines detected by the computer may be very irregular, we can use a cubic Bezier curve fitting technique to smooth the borderlines.</p></sec><sec><title>FEM mesh Generation</title><p>Among several methods to automating mesh generation [<xref ref-type="bibr" rid="B9">9</xref>], the mesh with cuboidal elements is the fastest and most stable method to mesh an organ with irregular shape even though it may require more elements at the boundary. We therefore apply the cuboidal-element mesh to make this software applicable for complex cases. For instance, in Figure <xref ref-type="fig" rid="F3">3</xref> the cloud-like parenchyma is dispersed in the fatty tissue. It is almost impossible to extract the exact geometry of parenchyma. In this case, most geometry-based methods are invalid. In the cuboidal mesh, elements are generated layer by layer and are automatically connected through the overlaid nodes. Given an element size, we can calculate how many slices each layer of elements spans. For simplicity, we assume the borderline of the central slice to be the borderline of that layer. Since the borderline consists of many points, we first build up a grid using the element size, move each border point to the closest cross-point of the grid, and remove the repeated points. We thus obtain the borderline denoted by the cross-points of the grid. It is noted the borderline may be entangled somewhere due to the numerical truncation. We need normalize the borderline so that it encloses a single-connected region and the distance between two neighboring point is equal to the size of the elements.</p><p>When we scan the single connected region, there exist two types of points on the borderline: jumping points and inertial points. If the left and right sides of a point are in the different states; i.e. one side is in the inside of the objective region and the other side is in the outside, then the point is called a jumping point. Otherwise, this point is called an inertial point. For instance, in an upstanding rectangle, all points on the left and right sides are jumping points, whereas the rest points on the top and bottom sides are inertial ones. On a closed borderline, each point is connected to two points. For a jumping point, the two neighboring points apparently have different values of <italic>y </italic>coordinate, whereas those for an inertial point do not. From this criterion we can identify the jumping points on the borderline. Once the points of the borderline are given, we can sort the points from top to bottom by <italic>y </italic>coordinate and from left to right by <italic>x </italic>coordinate. Then, for any <italic>y </italic>coordinate we can obtain a list of points with increasing <italic>x </italic>coordinates. During a horizontal scan for a fixed <italic>y </italic>coordinate, the number of jumping points in this list must be even, with which we obtain the pair-wise jumping points and find all the internal points between each pair of jumping points. Scanning the points from top to bottom, we can obtain all the internal points for the connected region. Then we can obtain the cuboidal-element mesh for this layer by mapping one point onto one element.</p><p>Because different elements may have different material properties, we need find the segmentation information for each element. From the grayscale histogram, we have defined the grayscale ranges corresponding to the tissues. Typically, an element may contain many voxels that belong to different tissues, whereas the FEM requires the element to be homogeneous. We count the number of voxels for each tissue in the element and assume the maximum one to be the material of the element. Thus, we can map the elements onto the different tissues as shown in Figure <xref ref-type="fig" rid="F5">5</xref>. We can thus mesh the object layer by layer and finally obtain the total FEM mesh, from which we can further calculate the volume of each tissue.</p><p>The surface information of the object is important for applying boundary conditions and mechanical loadings. This software uses the 2-D rectangular elements to describe the surface. Each 3-D cuboidal element has six rectangular faces. We collect the faces from all cuboidal elements. Thus, for an object containing <italic>N </italic>cuboidal elements, we can obtain 6<italic>N </italic>2-D rectangular elements. Obviously not all the rectangular elements are on the surface of the object. If an element is not on the surface, from the connectivity, another 2-D element containing the same nodes must exist which belongs to the neighboring cuboidal element. Eliminating each pair of these inside elements, we are able to obtain surface elements. We further input the mesh with segmentation information into an FEM program based on the required data format, assign material properties to tissues, and apply boundary conditions on the surface nodes. We can eventually calculate the mechanical deformation, internal stress and strain by the FEM software.</p></sec></sec><sec><title>Results and Discussion</title><sec><title>3-D FEM Mesh and Material Properties</title><p>To illustrate the capability of this software, we construct an FEM model of a woman breast and simulate the mechanical deformation with applied compressive forces. A set of CT image of the prone breast was acquired consisting of 512 &#x000d7; 512 &#x000d7; 243 voxels. The voxel size is 0.46875 &#x000d7; 0.46875 &#x000d7; 0.6 <italic>mm</italic><sup>3</sup>. As an example, the 148<sup>th </sup>slice is shown in Figure <xref ref-type="fig" rid="F1">1</xref>. The breast includes three kinds of tissues: fat, parenchyma, and tumor, which are represented by three grayscales as dark, gray, and light, respectively. Using the ImageParser package, we are able to mesh the breast by cuboidal elements with a size of 2.8125 &#x000d7; 2.8125 &#x000d7; 3 <italic>mm</italic><sup>3</sup>. The breast is meshed into 14,902 elements with 18,486 nodes as shown in Figure <xref ref-type="fig" rid="F7">7</xref>. The tumor, parenchyma, and fatty tissue consist of 154, 5783, and 8965 elements, respectively. The surface of the breast includes 6,900 rectangular 2-D surface elements. The region of breast is defined as follows: 0 &#x0003c;<italic>x </italic>&#x0003c; 84.375 <italic>mm</italic>, 0 &#x0003c;<italic>y </italic>&#x0003c; 87.1875 <italic>mm </italic>and 0 &#x0003c;<italic>z </italic>&#x0003c; 135 <italic>mm</italic>. Here <italic>x </italic>is from left to right in a slice of the image, <italic>y </italic>is from the top to bottom, and <italic>z </italic>is from the first slice to the last slice. Corresponding to the human body, <italic>y </italic>represents the normal direction of the coronal plane, while <italic>z </italic>signifies the normal direction of the axial (transverse) plane (Figure <xref ref-type="fig" rid="F7">7</xref>).</p><fig position="float" id="F7"><label>Figure 7</label><caption><p><bold>3D FEM Mesh of the Breast. </bold>The breast is meshed by cuboidal elements with a size of 2.8125 &#x000d7; 2.8125 &#x000d7; 3 <italic>mm</italic>. 14,902 elements and 18,486 nodes are generated. The breast is in the region as: 0 &#x0003c;<italic>x </italic>&#x0003c; 84.375 <italic>mm</italic>, 0 &#x0003c;<italic>y </italic>&#x0003c; 87.1875 <italic>mm </italic>and 0 &#x0003c;<italic>z </italic>&#x0003c; 135 <italic>mm</italic>.</p></caption><graphic xlink:href="1475-925X-3-31-7"/></fig><p>Based on Krouskop et al. [<xref ref-type="bibr" rid="B13">13</xref>], the initial elastic moduli of three tissues are taken as 20 KPa for fat, 35 KPa for parenchyma, and 100 KPa for tumor. Because these tissues may undergo large (finite) deformation, we apply the Mooney-Rivlin nonlinear elastic (hyperelastic) model to describe the constitutive law for the finite deformation. Using the initial elastic moduli we can calculate the Mooney-Rivlin material constants as: <italic>C</italic><sub>01 </sub>= 1,333 Pa, <italic>C</italic><sub>10 </sub>= 2,000 Pa for fat; <italic>C</italic><sub>01 </sub>= 2333.3 Pa, <italic>C</italic><sub>10 </sub>= 3500 Pa for parenchyma; and <italic>C</italic><sub>01 </sub>= 6,667 Pa, <italic>C</italic><sub>10 </sub>= 10,000 Pa for tumor. It is noted that, due to the nonlinear characteristics, the elastic modulus for each tissue change as a function of deformation.</p></sec><sec><title>FEM Modeling by ANSYS</title><p>ANSYS 7.0 [<xref ref-type="bibr" rid="B14">14</xref>] is the commercial nonlinear FEM software. We input the nodes and elements into ANSYS, and define the material models for three tissues. The applied compression with two flat-paddles is designed to simulate the clinical mammography examination. The ANSYS elastic contact model is adopted for the interaction between the breast tissue and the much more rigid paddle. The paddle's Young's modulus and Poisson's ratio are taken as 210 GPa and 0.3, respectively. During the compression process, the breast deforms. The contact area between the breast surface and the paddle increases automatically. The friction coefficient between the breast and the paddle is assumed to be 0.2. The boundary conditions are assumed that all nodes attached to thorax are constraint as <italic>U</italic><sub><italic>x </italic></sub>= <italic>U</italic><sub><italic>y </italic></sub>= 0, so that they can only move in the <italic>z </italic>direction for computational convenience. The two paddles move toward each other with a quasi-static strain rate. The maximum paddle movement is limited to be 13.5 <italic>mm </italic>(20% deformation) in the <italic>z </italic>direction.</p></sec><sec><title>FEM Results</title><p>To simulate the nonlinearly elastic deformation, we divide this compression process into 20 incremental steps. At each step the displacement, strain, and stress fields can be calculated. Figure <xref ref-type="fig" rid="F8">8</xref> shows the von Mises strain and tangential Young's modulus distributions at the last step. The deformation-dependent tangential Young's modulus is defined as</p><fig position="float" id="F8"><label>Figure 8</label><caption><p><bold>The Strain and Tangent Young's Modulus Distribution. </bold>The von Mises strain (a) and Tangent Young's modulus (b) distribution in the layers at <italic>z </italic>= 69, 78, 87 <italic>mm </italic>are illustrated. Because the tumor is much harder than other tissues, the Tangent Young's modulus is obviously higher and the strain is lower than those at the neighoring region.</p></caption><graphic xlink:href="1475-925X-3-31-8"/></fig><p><inline-graphic xlink:href="1475-925X-3-31-i3.gif"/></p><p>where <italic>&#x003c3;</italic><sub><italic>&#x003b5; </italic></sub>and <italic>&#x003b5;</italic><sub><italic>e </italic></sub>are the von Mises stress and strain, respectively. It is noted that, for linear elastic material, <italic>E </italic>is always a material constant. Because the material properties of skin, normal entity and tumor are all nonlinear, <italic>E </italic>should change during the process of compression. Figure 8(a) shows the von Mises strain for the sections at <italic>z </italic>= 69,78,87 <italic>mm</italic>. The strain around the thorax is quite significant due to the boundary constraint, whereas the strain close to skin is small because of the free boundary condition. In the region of tumor, it is shown that the strain is much smaller than that in the neighboring region because the tumor is much harder than other tissues. Figure 8(b) demonstrates that the tangential Young's modulus is no longer uniform even in the same tissue because its strain field is not uniform.</p></sec></sec><sec><title>Conclusions</title><p>The ImageParser system has been developed to create FEM mesh models from 3-D medical images. A semi-automatic method has been proposed to detect the ROIs from the context of complex image structures. The ROIs can be meshed into cuboidal elements and segmented based on the grayscale of the voxels. It has been demonstrated that, through a 3-D CT image volume of the woman breast, the ImageParser can effectively mesh the breast into cuboidal elements, and simulate the realistic nonlinear deformation responses of the breast tissues upon compression.</p></sec><sec><title>Authors' contributions</title><p>LZS, GW, and MWV conceived and planned this research project. HMY and LZS designed and developed this software. TY prepared the CT image volume of the breast. TY, JW, and GW analyzed the CT images. HMY, LZS, and GW wrote the manuscript.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>This work is sponsored by the University of Iowa's Iowa Informatics Initiative.</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lorensen</surname><given-names>WE</given-names></name><name><surname>Cline</surname><given-names>HE</given-names></name></person-group><article-title>Marching cubes: a high resolution 3D surface construction algorithm</article-title><source>Comput Graph</source><year>1987</year><volume>21</volume><fpage>163</fpage><lpage>169</lpage></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Gueziec</surname><given-names>A</given-names></name><name><surname>Hummel</surname><given-names>R</given-names></name></person-group><article-title>Exploiting triangulated surface extraction using tetrahedral decomposition</article-title><source>IEEE Trans Vis Comput Graph</source><year>1995</year><volume>1</volume><fpage>328</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1109/2945.485620</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Sullivan</surname><given-names>JM</given-names></name></person-group><article-title>Multiple material marching cubes algorithm</article-title><source>Inter J Numer Meth Eng</source><year>2003</year><volume>58</volume><fpage>189</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1002/nme.775</pub-id></citation></ref><ref id="B4"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Maurel</surname><given-names>W</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Magnenat Thalmann</surname><given-names>N</given-names></name><name><surname>Thalmann</surname><given-names>D</given-names></name></person-group><source>Biomechanical Models for Soft Tissue Simulation</source><year>1998</year><publisher-name>Berlin, Springer-Verlag</publisher-name></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Samani</surname><given-names>A</given-names></name><name><surname>Bishop</surname><given-names>J</given-names></name><name><surname>Yaffe</surname><given-names>MJ</given-names></name><name><surname>Plewes</surname><given-names>DB</given-names></name></person-group><article-title>Biomechanical 3-D finite element modelling of the human breast using MRI data</article-title><source>IEEE Trans Med Imaging</source><year>2001</year><volume>20</volume><fpage>877</fpage><lpage>885</lpage><pub-id pub-id-type="pmid">11585205</pub-id><pub-id pub-id-type="doi">10.1109/42.952726</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Azar</surname><given-names>FS</given-names></name><name><surname>Metaxas</surname><given-names>DN</given-names></name><name><surname>Schnall</surname><given-names>MD</given-names></name></person-group><article-title>Methods for modelling predicting mechanical deformations of the breast under external perturbations</article-title><source>Med Image Anal</source><year>2002</year><volume>6</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="pmid">11836132</pub-id><pub-id pub-id-type="doi">10.1016/S1361-8415(01)00053-6</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>Y</given-names></name><name><surname>Engelke</surname><given-names>K</given-names></name><name><surname>Kalender</surname><given-names>WA</given-names></name></person-group><article-title>Interactive 2D editing tools for image segmentation</article-title><source>Med Image Anal</source><year>2004</year><volume>8</volume><fpage>35</fpage><lpage>46</lpage><pub-id pub-id-type="pmid">14644145</pub-id><pub-id pub-id-type="doi">10.1016/j.media.2003.07.002</pub-id></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Viceconti</surname><given-names>M</given-names></name><name><surname>Zannoni</surname><given-names>C</given-names></name><name><surname>Pierotti</surname><given-names>L</given-names></name></person-group><article-title>TRI2SOLID: an application of reverse engineering methods to the creation of CAD models of bone segments</article-title><source>Comput Meth Prog Bio</source><year>1998</year><volume>56</volume><fpage>211</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/S0169-2607(98)00011-X</pub-id></citation></ref><ref id="B9"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Viceconti</surname><given-names>M</given-names></name><name><surname>Bellingeri</surname><given-names>L</given-names></name><name><surname>Cristofolini</surname><given-names>L</given-names></name><name><surname>Toni</surname><given-names>A</given-names></name></person-group><article-title>A comparative study on different methods of automatic mesh generation of human femurs</article-title><source>Med Eng Phys</source><year>1998</year><volume>20</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="pmid">9664280</pub-id><pub-id pub-id-type="doi">10.1016/S1350-4533(97)00049-0</pub-id></citation></ref><ref id="B10"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Ballard</surname><given-names>DH</given-names></name><name><surname>Brown</surname><given-names>CM</given-names></name></person-group><source>Computer Vision</source><year>1982</year><publisher-name>Englewood Cliffs: Prentice-Hall</publisher-name></citation></ref><ref id="B11"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sonka</surname><given-names>M</given-names></name><name><surname>Hlavac</surname><given-names>V</given-names></name><name><surname>Boyle</surname><given-names>R</given-names></name></person-group><source>Image Processing, Analysis and Machine Vision</source><year>1993</year><publisher-name>London: Chapman &#x00026; Hall</publisher-name></citation></ref><ref id="B12"><citation citation-type="book"><person-group person-group-type="author"><name><surname>J&#x000e4;hne</surname><given-names>B</given-names></name></person-group><source>Digital Image Processing</source><year>1991</year><publisher-name>Berlin: Springer-Verlag</publisher-name></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Krouskop</surname><given-names>TA</given-names></name><name><surname>Wheeler</surname><given-names>TM</given-names></name><name><surname>Kallel</surname><given-names>F</given-names></name><name><surname>Garra</surname><given-names>BS</given-names></name><name><surname>Hall</surname><given-names>T</given-names></name></person-group><article-title>Elastic moduli of breast and prostate tissues under compression</article-title><source>Ultrasonic Imaging</source><year>1998</year><volume>20</volume><fpage>260</fpage><lpage>274</lpage><pub-id pub-id-type="pmid">10197347</pub-id></citation></ref><ref id="B14"><citation citation-type="other"><article-title>ANSYS is a commercial FEM software package developed by ANSYS, Inc</article-title></citation></ref></ref-list></back></article>



