<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="data-paper" dtd-version="1.3"><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Data Brief</journal-id><journal-id journal-id-type="iso-abbrev">Data Brief</journal-id><journal-title-group><journal-title>Data in Brief</journal-title></journal-title-group><issn pub-type="epub">2352-3409</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38125368</article-id><article-id pub-id-type="pmc">PMC10733099</article-id><article-id pub-id-type="pii">S2352-3409(23)00968-X</article-id><article-id pub-id-type="doi">10.1016/j.dib.2023.109936</article-id><article-id pub-id-type="publisher-id">109936</article-id><article-categories><subj-group subj-group-type="heading"><subject>Data Article</subject></subj-group></article-categories><title-group><article-title>A comprehensive dragon fruit image dataset for detecting the maturity and quality grading of dragon fruit</article-title></title-group><contrib-group><contrib contrib-type="author" id="au0001"><name><surname>Khatun</surname><given-names>Tania</given-names></name><email>tania.cse@diu.edu.bd</email><xref rid="aff0001" ref-type="aff">a</xref><xref rid="cor0001" ref-type="corresp">&#x0204e;</xref></contrib><contrib contrib-type="author" id="au0002"><name><surname>Nirob</surname><given-names>Md. Asraful Sharker</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0003"><name><surname>Bishshash</surname><given-names>Prayma</given-names></name><xref rid="aff0001" ref-type="aff">a</xref></contrib><contrib contrib-type="author" id="au0004"><name><surname>Akter</surname><given-names>Morium</given-names></name><xref rid="aff0002" ref-type="aff">b</xref></contrib><contrib contrib-type="author" id="au0005"><name><surname>Uddin</surname><given-names>Mohammad Shorif</given-names></name><xref rid="aff0002" ref-type="aff">b</xref></contrib><aff id="aff0001"><label>a</label>Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh</aff><aff id="aff0002"><label>b</label>Department of Computer Science and Engineering, Jahangirnagar University, Dhaka, Bangladesh</aff></contrib-group><author-notes><corresp id="cor0001"><label>&#x0204e;</label>Corresponding author. <email>tania.cse@diu.edu.bd</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>10</day><month>12</month><year>2023</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><month>2</month><year>2024</year></pub-date><pub-date pub-type="epub"><day>10</day><month>12</month><year>2023</year></pub-date><volume>52</volume><elocation-id>109936</elocation-id><history><date date-type="received"><day>10</day><month>11</month><year>2023</year></date><date date-type="rev-recd"><day>27</day><month>11</month><year>2023</year></date><date date-type="accepted"><day>4</day><month>12</month><year>2023</year></date></history><permissions><copyright-statement>&#x000a9; 2023 The Author(s)</copyright-statement><copyright-year>2023</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p></license></permissions><abstract id="abs0001"><p>Dragon fruit, often referred to as pitaya, is a tropical fruit with various types, including both white-fleshed and red-fleshed varieties. Its distinctive appearance is complemented by a range of potential health advantages. These include its abundance of nutrients and antioxidants, which contribute to a robust immune system, aid in blood sugar regulation, and support the well-being of the heart, bones, and skin. Consequently, the global desire for dragon fruit is yielding substantial economic advantages for developing nations like Bangladesh, which in turn underscores the pressing need for an automated system to identify the optimal harvest time and differentiate between fresh and defective fruits to ensure quality. To accomplish this objective, this paper introduces an extensive collection of high-resolution dragon fruits because effective detection by machine learning models necessitates a substantial amount of data. The dataset was painstakingly gathered during a span of four months from three distinct locations in Bangladesh, with the valuable assistance of domain experts. Possible application of the dataset encompasses quality evaluation, robotic harvesting, and packaging systems, ultimately boosting the effectiveness of dragon fruit production procedures. The dataset has the potential to be a valuable resource for researchers interested in dragon fruit cultivation, offering a solid foundation for the application of computer vision and deep learning methods in the agricultural industry.</p></abstract><kwd-group id="keys0001"><title>Keywords</title><kwd>Dragon dataset</kwd><kwd>Image recognition</kwd><kwd>Agriculture</kwd><kwd>Deep learning</kwd><kwd>Computer vision</kwd></kwd-group></article-meta></front><body><p id="para0004a">Specifications Table<table-wrap position="float" id="utbl0001"><table frame="hsides" rules="groups"><tbody><tr><td valign="top">Subject</td><td valign="top">Computer Science</td></tr><tr><td valign="top">Specific subject area</td><td valign="top">Image Categorization, Image Detection, Robotic Harvesting, Maturity Analysis</td></tr><tr><td valign="top">Data format</td><td valign="top">Raw jpg</td></tr><tr><td valign="top">Type of data</td><td valign="top">Image</td></tr><tr><td valign="top">Data collection</td><td valign="top">In collaboration with an expert from Ministry of Agriculture, Bangladesh, a collection of images was taken during the period from May 2023 to August 2023 from the demonstration areas of three different locations in Bangladesh.</td></tr><tr><td valign="top">Data source location</td><td valign="top"><bold>Location:</bold> Bappi Taj Agro Farm demonstration farm in Gazipur, Tipu Sultan Agro Farm in Jhenaidah, and the Daffodil research farm in Gazaria, Munshiganj<break/><bold>Zone:</bold> Gazipur, Jhenaidah, Munshiganj<break/><bold>Country:</bold> Bangladesh</td></tr><tr><td valign="top">Data accessibility</td><td valign="top"><bold>Repository name:</bold> Mendeley Data<break/><bold>Data identification number</bold>: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17632/2jpzbx8tm6.1" id="interref0001d">10.17632/2jpzbx8tm6.1</ext-link><break/><bold>Direct URL to data:</bold><ext-link ext-link-type="uri" xlink:href="https://data.mendeley.com/datasets/2jpzbx8tm6/1" id="interref0003">https://data.mendeley.com/datasets/2jpzbx8tm6/1</ext-link></td></tr></tbody></table></table-wrap></p><sec id="sec0002"><label>1</label><title>Value of the Data</title><p id="para0003">
<list list-type="simple" id="celist0001"><list-item id="celistitem0001"><label>&#x02022;</label><p id="para0004">Inconsistent human harvesting practices lead to the risk of overripe or underripe fruit. Harvesting dragon fruit prematurely leads to decreased sweetness, flavor, and overall quality, potentially dissatisfying customers and reducing demand and sales, resulting in financial losses, increased labor costs, and lower prices for growers. Physical characteristics like the weight, texture, and external color of the peel are commonly employed as non-invasive techniques for assessing the ripeness of dragon fruit <xref rid="bib0001" ref-type="bibr">[1]</xref>. Therefore, utilizing the computer vision approach this dataset has the potential to develop an automated harvesting system that can empower farmers by delivering accurate advice on optimal harvest times by analyzing images of various fruit development stages, consequently lowering labor requirements and minimizing financial losses.</p></list-item><list-item id="celistitem0002"><label>&#x02022;</label><p id="para0005">Detecting the freshness and identifying defects in dragon fruit is essential for upholding product quality, minimizing wastage, avoiding economic repercussions, as well as creating avenues for international exports while promoting the production of top-tier goods to satisfy global market requirements <xref rid="bib0002" ref-type="bibr">[2]</xref>. The dragon fruit image dataset presented in this article can play a pivotal role in this endeavor by serving as an asset for training computer vision and deep learning models. This involvement aids in quality assurance, waste reduction, optimized harvesting practices, and the automation of inspection processes. Ultimately, the dataset's application results in improved product quality, economic advantages for growers and the agricultural sector, and heightened customer contentment, underscoring its significance in fresh and defective dragon fruit detection.</p></list-item><list-item id="celistitem0003"><label>&#x02022;</label><p id="para0006">This dragon fruit dataset is significant for researchers as it serves as a valuable resource for developing and testing computer vision, machine learning, and deep learning technologies. Researchers can create automated systems for fruit recognition, improving harvest efficiency, predicting freshness, and automating packaging and this dataset encourages interdisciplinary collaboration between computer scientists and experts in other fields, particularly agriculture. Moreover, the dataset has the potential to deliver economic benefits by reducing labor costs and enhancing crop quality, underscoring its relevance and importance in the field of computer science.</p></list-item></list>
</p></sec><sec id="sec0003"><label>2</label><title>Background</title><p id="para0007">The compilation of this dataset arose out of the need to address challenges in identifying dragon fruit developmental stages prevalent in agriculture. The creation of the dataset aligns with ongoing efforts in precision agriculture, which aims to improve crop management practices through technological interventions. Motivation also arose from the lack of comprehensive datasets specific to dragon fruit stages and diseases, which hindered the development of accurate detection models. We collect 3780 images displaying different growth stages, and conditions, this dataset serves as a valuable resource for training and validating deep learning algorithms and enables fast and accurate detection of dragon fruit stages and qualities. The dataset article complements a related research publication by providing researchers and practitioners with access to raw data, increasing transparency, reproducibility, and further investigations to optimize agricultural practices.</p></sec><sec id="sec0004"><label>3</label><title>Data Description</title><p id="para0008">The dataset comprises images that depict different phases of dragon fruit development, encompassing healthy young fruits, ripe fruits, and decayed specimens. These images were manually taken during the period spanning from May to August 2023 from the demonstration farm of Bappy Taz Agro Farm in Gazipur, Tipu Sultan Agro Farm in Jhenaidah, and the Daffodil Research Farm in Gazaria, Munshigonj with guidance from a domain expert using the cameras of a Redmi Note 11 Pro Plus and a Samsung S22 smartphone. The resultant images with sizes 800&#x000d7;800 pixels are captured and stored in the JPG format. Each image in the dataset is labeled according to its corresponding stage of maturity and quality, allowing for easy classification and analysis.</p><p id="para0009">While gathering pictures from the dragon fruit orchard, we ran into a few difficulties such as,<list list-type="simple" id="celist0002"><list-item id="celistitem0004"><label>1.</label><p id="para0010">The primary challenge encountered during data collection pertained to capturing images amidst noisy backgrounds and uneven lighting conditions.</p></list-item><list-item id="celistitem0005"><label>2.</label><p id="para0011">The growth of dragon fruits is very time-sensitive. For the dataset to be accurate and relevant, photos had to be collected at growth stages or during particular seasons.</p></list-item></list></p><p id="para0012"><xref rid="fig0001" ref-type="fig">Fig.&#x000a0;1</xref> illustrates the dragon fruit field from where we gathered dataset images.<fig id="fig0001"><label>Fig. 1</label><caption><p>The real dragon fruit field from where we collected the dataset images.</p></caption><alt-text id="alt0001">Fig 1</alt-text><graphic xlink:href="gr1" id="celink0001"/></fig></p><p id="para0013">In this paper we have presented three varieties Bari Dragon Fruit-1, Connie Mayer Dragon Fruit, and Thai Red Dragon Fruit. <xref rid="tbl0001" ref-type="table">Table&#x000a0;1</xref> represents the details of these varieties of dragon fruits.<table-wrap position="float" id="tbl0001"><label>Table 1</label><caption><p>Details about the dragon fruit varieties in the dataset.</p></caption><alt-text id="alt0002">Table 1:</alt-text><table frame="hsides" rules="groups"><thead><tr><th valign="top">Variety Name</th><th valign="top">Description</th><th valign="top">Visualization</th></tr></thead><tbody><tr><td valign="top">Bari Dragon Fruit-1</td><td valign="top">Bari Dragon Fruit-1, a red dragon fruit variant, was invented by BARI (Bangladesh Agricultural Research Institute) and is now successfully cultivated in Dhaka, Chattagram, Northern areas of Bangladesh, and Rangamati Hill. At maturity, the fruit weighs around 350-400 grams and features a light pink exterior, revealing a dark pink, succulent interior boasting a Total Soluble Solids (TSS) content of 13.22%. With an edible portion comprising 81% of the fruit, this variety demonstrates consistent high-yield fruit production. A 3&#x02013;5-year-old tree yields approximately 3.22 kg/year. Notably, it contains 12.06 millimicrograms of beta-carotene and 41.27 milligrams of vitamin C per 100 grams, highlighting its nutritional value <xref rid="bib0003" ref-type="bibr">[3]</xref>.</td><td valign="top"><inline-graphic xlink:href="fx1.gif"><alt-text id="alt1">Image, table 1</alt-text></inline-graphic></td></tr><tr><td valign="top">Connie Mayer Dragon Fruit</td><td valign="top">The Connie Mayer Dragon Fruit, has medium-sized blooms with inner petals shifting from purple to light pink edges, retaining an alluring appearance even during budding. These small, abundant fruits, weighing between 7 and 9 ounces, undergo a striking transformation as their green skin ripens into a transparent pink shade with lemon-lime green fins, enveloping sweet, white flesh. Notably, an extended vine-ripening time of around 45 days in Louisiana, compared to the standard 30 days for similar Hylocereus varieties, augments sweetness <xref rid="bib0004" ref-type="bibr">[4]</xref>.</td><td valign="top"><inline-graphic xlink:href="fx2.gif"><alt-text id="alt2">Image, table 1</alt-text></inline-graphic></td></tr><tr><td valign="top">Thai Red Dragon Fruit</td><td valign="top">Thai dragon fruit also referred to as pitaya, hails from Thailand and is part of the cactus family. It exists in diverse varieties, such as the white-fleshed Hylocereus Undatus and the red-fleshed Hylocereus Costaricensis or Hylocereus Polyrhizus types. Classified by the National Bureau of Agricultural Commodity and Food Standards under the Ministry of Agriculture and Cooperatives of Thailand, this fruit is divided into 3 primary groups based on skin and inner pulp colors <xref rid="bib0005" ref-type="bibr">[5]</xref>. Typically, these fruits are oval or elongated, featuring shiny, spiky skin. Renowned for its gently sweet taste, it's commonly relished in smoothies, akin to kiwi, and often used as an eye-catching garnish in culinary dishes due to its vivid appearance.</td><td valign="top"><inline-graphic xlink:href="fx3.gif"><alt-text id="alt3">Image, table 1</alt-text></inline-graphic></td></tr></tbody></table></table-wrap></p><p id="para0014">In the field of agriculture science, Automation is a game-changer that benefits a nation's agriculture economy in several ways. The raising of quality is one of the main benefits. A final result that is uniform and of high quality is made possible by automation in tasks like fruit and vegetable sorting and grading. This is crucial for satisfying customer demands and those of global markets, which frequently have high standards for quality. While manual fruit and vegetable sorting is still common, it is well known to have a number of disadvantages. As human perception can be subjective and impacted by things like exhaustion or personal judgment, it is prone to mistakes and inconsistencies. Additionally, it takes a lot of time, especially when processing greater amounts of fruit, which can result in inefficiencies and higher labor expenses. Moreover, hand sorting can be expensive because Intelligent fruit grading systems have been created to address these issues. These systems use computer vision algorithms to classify and evaluate products automatically according to a variety of quality criteria. Computer vision makes it possible to precisely measure and analyze traits including color, texture, size, shape, and flaws.</p><p id="para0015">To enable these advancements, this paper introduces two sets of data. The first dataset, referred to as the Dragon Fruit Maturity Detection Dataset, and the second dataset, the Dragon Fruit Quality Grading Dataset, are presented. Each of these dataset folders is further divided into two subfolders: the original dataset, consisting of images directly captured with a camera, and the augmented dataset, containing images generated from the original dataset using data augmentation software. The Dragon Fruit Maturity Detection Dataset takes up 976MB of space, while the Dragon Fruit Quality Grading Dataset occupies 624MB in its folder.</p><p id="para0016">The ripeness and quality of dragon fruits are closely linked to characteristics such as color, skin appearance, texture, flavor, size, and shape <xref rid="bib0001" ref-type="bibr">[1]</xref>. Within the Dragon Fruit Maturity Detection Dataset, both the original and augmented datasets are categorized into two groups: Mature Dragon Fruit and Immature Dragon Fruit. Similarly, within the Dragon Fruit Quality Grading Dataset, both the original and augmented datasets are divided into two groups: Fresh Dragon Fruit and Defect Dragon Fruit. Each of these folders includes relevant images of dragon fruits. The organization of the dataset is presented in <xref rid="fig0002" ref-type="fig">Fig&#x000a0;2</xref>.<fig id="fig0002"><label>Fig 2</label><caption><p>Organization of dragon fruit dataset.</p></caption><alt-text id="alt0003">Fig 2:</alt-text><graphic xlink:href="gr2" id="celink0002"/></fig></p><p id="para0017">The progression of dragon fruit growth differs based on factors such as its variety, cultivation conditions, and climatic influences. Generally, it spans an average duration of 31 to 41 days, roughly equivalent to one and a half months, for the fruit to attain its full mature size <xref rid="bib0001" ref-type="bibr">[1]</xref>. Furthermore, it is important to harvest the fruit at its optimal stage of maturity to ensure the best quality, flavor, and texture <xref rid="bib0011" ref-type="bibr">[11]</xref>. <xref rid="tbl0002" ref-type="table">Table&#x000a0;2</xref> explains each category in both the Dragon Fruit Maturity Detection and Quality Grading Dataset.<table-wrap position="float" id="tbl0002"><label>Table 2</label><caption><p>Concise overview of the dragon fruit maturity detection and quality grading dataset.</p></caption><alt-text id="alt0004">Table 2:</alt-text><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Topic</th><th valign="top">Class Name</th><th valign="top">Description</th><th valign="top">Visualization</th></tr></thead><tbody><tr><td rowspan="2" align="left" valign="top">Dragon Fruit Maturity Detection Dataset</td><td valign="top">Immature Dragon Fruit</td><td valign="top">Premature dragon fruit, in contrast to its ripe counterpart, is smaller in size, typically green, or light pink, has a firmer texture, a milder and less sweet flavor, underdeveloped seeds, and may exhibit a slightly sour taste <xref rid="bib0001" ref-type="bibr">[1]</xref>. Its firmness sets it apart from the softer and sweeter qualities of fully ripe dragon fruit. The exact characteristics can vary depending on the dragon fruit variety and its specific stage of ripeness.</td><td valign="top"><inline-graphic xlink:href="fx4.gif"><alt-text id="alt4">Image, table 2</alt-text></inline-graphic></td></tr><tr><td valign="top">Mature Dragon Fruit</td><td valign="top">A mature dragon fruit has a visually striking appearance. Mature dragon fruit is characterized by its larger size, vibrant red or magenta color based on variety, firm, and spiky skin, sweet and mildly tangy flavor, well-developed seeds, and a sweet tropical aroma when ripe. The skin is usually covered in scales or spikes, giving it a unique and exotic look <xref rid="bib0006" ref-type="bibr">[6]</xref>.</td><td valign="top"><inline-graphic xlink:href="fx5.gif"><alt-text id="alt5">Image, table 2</alt-text></inline-graphic></td></tr><tr><td rowspan="2" align="left" valign="top">Dragon Fruit Quality Grading Dataset</td><td valign="top">Fresh Dragon Fruit</td><td valign="top">Depending on the variety, fresh dragon fruit has a bright exterior skin in tones of pink, red, or yellow. The skin typically has scales or spikes covering it, giving it an unusual and exotic appearance. The flesh can be white or red and is soft, juicy, and slightly crunchy due to small black seeds <xref rid="bib0007" ref-type="bibr">[7]</xref>. A vivid color, a subtle softness to the touch, and a delightful perfume are indications of ripeness.</td><td valign="top"><inline-graphic xlink:href="fx6.gif"><alt-text id="alt6">Image, table 2</alt-text></inline-graphic></td></tr><tr><td valign="top">Defect Dragon Fruit</td><td valign="top">One of the fruit's skin's changing look, becoming loose and wrinkled, is one of the early signs of spoiling. Additionally, these characteristics include physical damage, rot, over-ripeness, internal issues, the possibility of being hollow or empty, physical color changes, and moving from its typical pink hue to a purple one <xref rid="bib0008" ref-type="bibr">[8]</xref>. The interior of spoiled dragon fruit turns a deeper shade of brown.</td><td valign="top"><inline-graphic xlink:href="fx7.gif"><alt-text id="alt7">Image, table 2</alt-text></inline-graphic></td></tr></tbody></table></table-wrap></p><p id="para0018">The dragon fruit dataset holds promise across various applications:</p><p id="para0019"><bold>Developing robotic harvesting systems:</bold> The dragon fruit dataset serves as a pivotal resource in crafting sophisticated robotic harvesting systems capable of selectively picking ripe fruits through image analysis. Leveraging this dataset, machine learning models are trained to precisely locate and discern ripe dragon fruits amidst varying backgrounds. These models enable the development of algorithms that empower robots to make real-time decisions based on color, texture, and shape analysis, selectively harvesting only ripe fruits while leaving others to mature further. Moreover, integrating this dataset-derived intelligence into robotic systems not only streamlines fruit picking but also facilitates continuous learning and adaptation, refining the system's accuracy and efficiency in the dynamic context of fruit harvesting.</p><p id="para0020"><bold>Automating quality control processes:</bold> The dragon fruit image dataset holds immense potential in automating quality control processes within packaging facilities. Through machine learning, this dataset can train models to assess various quality parameters, such as size, shape, color, and defects, enabling automated inspection of dragon fruits as they move through the packaging line. By leveraging the dataset, these systems can accurately identify, and sort fruits based on predetermined quality standards, ensuring consistency and adherence to quality benchmarks. Moreover, the dataset facilitates continuous learning, allowing the system to adapt and improve its accuracy over time, enhancing efficiency and precision in the packaging process while reducing human intervention.</p></sec><sec id="sec0005"><label>4</label><title>Experimental Design, Materials and Methods</title><sec id="sec0006"><label>4.1</label><title>Camera specification</title><p id="para0021">The information was collected by employing the cameras of a Redmi Note 11 Pro Plus and a Samsung S22 smartphone.</p><p id="para0022">The camera of the Redmi Note 11 Pro Plus device is equipped with a 108MP Samsung ISOCELL HM2 sensor, which is a relatively large sensor with a size of 1/1.52 inches. The individual pixels on the sensor have a size of 0.7&#x000b5;m, but they can be combined using a technique called 9-in-1 binning, where 9 pixels are merged to create a larger pixel with a size of 2.1&#x000b5;m.</p><p id="para0023">The Samsung S22 device's camera is furnished with a 50MP Samsung GN5 sensor and Sony IMX766 sensors, featuring a relatively spacious 1/1.57-inch sensor size. The individual pixels on this sensor measure 1.0 &#x000b5;m each, accompanied by an f/1.8 aperture.</p></sec><sec id="sec0007"><label>4.2</label><title>Data augmentation</title><p id="para0024">Data augmentation is essential for deep learning models, particularly for visual object recognition. It is a potent technique for strengthening deep learning models, in particular, supplements the training dataset by creating new images from the ones that already exist, enhancing model generalization, and reducing overfitting. We used a variety of augmentation strategies such as shearing, random rotation, horizontal flipping, width, and height changing, zooming, and brightness modifications. To increase the dataset's diversity and resilience, several procedures were used in accordance with accepted best practices.</p><p id="para0025">The photos may be oriented in a variety of ways according to these specifications, which include a rotation range of 45 degrees. Additionally, we added a 0.2 width and height shift range, allowing for the displacement of the image's content in both directions. The controlled deformation was introduced with a shear range of 0.2. We changed the scale of the photographs by applying a zoom range of 0.2 to provide more diversity. The dataset was expanded with mirrored versions of the photos when horizontal flipping was enabled. We used the 'reflect' fill mode to manage picture modifications without any hiccups. Additionally, to ensure a dynamic range of lighting circumstances, we changed brightness in the range of 0.5 to 1.5. The robust and varied dataset produced by these parameter settings improved the deep learning models' training process.</p><p id="para0026">Within our dataset, a code-driven, automated augmentation procedure was used to create a total of 10010 augmented pictures. These enhanced pictures were carefully designed to increase the variety and depth of our dataset. These improved images are skillfully paired with the appropriate original sample images for each category in <xref rid="tbl0003" ref-type="table">Table&#x000a0;3</xref>. This careful pairing serves to give a clear and instructive representation of the results of the augmentation, successfully demonstrating the effectiveness of the data augmentation process in growing and enhancing our dataset.<table-wrap position="float" id="tbl0003"><label>Table 3</label><caption><p>Statistics of the dragon fruit dataset.</p></caption><alt-text id="alt0006">Table 3:</alt-text><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Topic</th><th valign="top">Name of Class</th><th valign="top">Original Image Number</th><th valign="top">Augmented Image Number</th></tr></thead><tbody><tr><td rowspan="2" align="left" valign="top">Maturity Detection</td><td valign="top">Immature Dragon Fruit</td><td valign="top">1241</td><td valign="top">3000</td></tr><tr><td valign="top">Mature Dragon Fruit</td><td valign="top">887</td><td valign="top">2010</td></tr><tr><td rowspan="2" align="left" valign="top">Quality Grading</td><td valign="top">Fresh Dragon Fruit</td><td valign="top">898</td><td valign="top">2000</td></tr><tr><td valign="top">Defect Dragon Fruit</td><td valign="top">754</td><td valign="top">3000</td></tr><tr><td align="left" valign="top"><bold>Total</bold></td><td valign="top"/><td valign="top"><bold>3779</bold></td><td valign="top"><bold>10010</bold></td></tr></tbody></table></table-wrap></p><p id="para0027">The training dataset is given controlled variance, which makes the model more adaptable to actual-world circumstances. Our main methods include shearing for various viewpoints, horizontal/vertical shifting (up to 20% width/height), and random rotation (0-45 degrees). While horizontal flipping teaches orientation invariance, random zooming (80&#x02013;120%) aids in managing various scales. A fill mode keeps the image's original content while adjusting the brightness (50&#x02013;150%) and contrast (70&#x02013;130%) to account for changes in lighting. Pre-processing adds a random zoom function, increasing the model's versatility. Models are now able to distinguish things in a variety of real-world scenarios thanks to these strategies. <xref rid="fig0003" ref-type="fig">Fig.&#x000a0;3</xref> displays the augmented images of dragon fruit from the dataset, while <xref rid="tbl0003" ref-type="table">Table&#x000a0;3</xref> provides the dataset's statistical information.<fig id="fig0003"><label>Fig. 3</label><caption><p>Augmented images of dragon fruit dataset.</p></caption><alt-text id="alt0005">Fig 3</alt-text><graphic xlink:href="gr3" id="celink0003"/></fig></p></sec><sec id="sec0008"><label>4.3</label><title>Deep learning model validation</title><p id="para0028">We introduced a deep learning model designed to effectively train the dataset, striving for state-of-the-art outcomes. The validation of this deep learning model requires a thorough evaluation of its performance on a dataset. A deep learning model comprises interconnected layers of nodes, where each node signifies a computational unit. The input layer's nodes receive data, while the output layer's nodes generate the ultimate outcome. Situated between these input and output layers are hidden layers, housing the neural network's primary computational capacity <xref rid="bib0009" ref-type="bibr">[9]</xref>. Deep learning models have made substantial strides in analyzing visual data, including tasks such as classifying images or videos, detecting objects, and processing natural language <xref rid="bib0010" ref-type="bibr">[10]</xref>. The deep learning model follows a structured five-step process, encompassing data preprocessing, data segmentation, model training, performance evaluation on a validation set, and ultimately, testing the model on a completely distinct test set. This rigorous approach is crucial to verify the model's reliability in producing accurate results and its capacity to adapt to new data.</p><p id="para0029">Data pre-processing is critical for deep learning because it prepares visual data for model input, enhances data quality, and influences model performance, generalization, and efficiency. It ensures that the images are in a suitable format for the computer vision tasks, addresses issues that can affect model learning and decision-making, and ultimately leads to more accurate and reliable results in various applications. In this research work, image pre-processing involves a range of data transformations, including actions such as data labeling, image resizing, image augmentation, and segmentation.</p><p id="para0030"><bold>Data labeling:</bold> During the first round of data pre-processing, we scrupulously labeled the data, properly assigning each image to its corresponding class or category. Labeled data serves as the foundation for training and refining deep learning models; without precise labels, models are unable to acquire knowledge and make reliable predictions.</p><p id="para0031"><bold>Image resizing:</bold> Because images within the dataset may come in different sizes, we found it necessary to resize them according to our specifications to provide a consistent and understandable dataset. This reduced computational demands and guaranteed compatibility during the training of deep learning models.</p><p id="para0032"><bold>Image segmentation:</bold> As needed, we carried out image cropping to remove undesirable background elements, thereby improving the dataset's overall quality.</p><p id="para0033"><bold>Data augmentation:</bold> The deep learning model requires a huge volume of data as it enhances model performance reduces overfitting and enables complex feature extraction <xref rid="bib0012" ref-type="bibr">[12]</xref>. Hence, we expand the dataset size by employing various augmentation techniques, as comprehensively outlined in <xref rid="sec0007" ref-type="sec">Section&#x000a0;3.2</xref>.</p><p id="para0034"><xref rid="fig0004" ref-type="fig">Fig.&#x000a0;4</xref> represents the pre-processing steps that we have applied to the dataset.<fig id="fig0004"><label>Fig. 4</label><caption><p>The pre-processing steps of proposed deep learning model.</p></caption><alt-text id="alt0007">Fig 4</alt-text><graphic xlink:href="gr4" id="celink0004"/></fig></p><p id="para0035">The dataset underwent a meticulous division into two distinct sets, namely the training dataset and the testing dataset, following a thoughtful separation process. This involved randomly selecting 80% of the photos to compose the training dataset, with the remaining 20% constituting the test dataset. Importantly, there were no repeated images shared between the training and test sets. The testing set played a pivotal role in evaluating the model's performance, serving as a robust benchmark after it had been trained on the training data.</p><p id="para0036">A comprehensive overview of the rigorous validation techniques employed in our deep-learning model, utilizing the dragon fruit image dataset, is thoughtfully presented in <xref rid="fig0005" ref-type="fig">Fig.&#x000a0;5</xref>. These validation procedures encompassed various tasks, including the discrimination of mature and immature dragon fruit, as well as the classification of dragon fruit as fresh or defective. This validation framework ensured the model's effectiveness and reliability in achieving the specific objectives of our study.<fig id="fig0005"><label>Fig. 5</label><caption><p>The working process for assessing dragon fruit ripeness and distinguishing between fresh and defective dragon fruits.</p></caption><alt-text id="alt0008">Fig 5</alt-text><graphic xlink:href="gr5" id="celink0005"/></fig></p><sec id="sec0009"><label>4.3.1</label><title>Model description</title><p id="para0037">In this research, we have applied the ResNet50 framework with the intention of identifying the ripeness and quality of dragon fruits. ResNet50 is a commonly employed deep convolutional neural network (CNN) architecture that is renowned for its effectiveness in image classification and object detection <xref rid="bib0013" ref-type="bibr">[13]</xref>. It is characterized by its depth, consisting of 50 convolutional layers, which enables it to learn intricate features from images. Its deep structure and residual connections contribute to its ability to achieve state-of-the-art results in a variety of computer vision applications.</p><p id="para0038">Within the ResNet-50 architecture, two types of blocks are present: the Identity Block and the Convolutional Block, where "identity block" is a specific type of residual block used within the architecture. Residual blocks are the main advancement in ResNet50, enabling the network to learn complex data representations by integrating shortcut connections and limiting overfitting by bypassing some layers. The result of the residual block is subsequently transferred to the following block. Convolutional blocks facilitate feature extraction and boost network performance with convolutional layers, batch normalization, and ReLU activation functions.</p><p id="para0039">In ResNet50, batch normalization is applied after each convolutional layer and before the activation function (e.g., ReLU), ensuring that the inputs to subsequent layers are well-scaled and centered. ReLU introduces non-linearity into the network by replacing negative values with zeros. In addition, to reduce the spatial resolution, capturing the most important information while reducing computational complexity max pooling layer is used periodically which involves selecting the maximum value in a local region of the feature map.</p><p id="para0040">The architecture concludes with a global average pooling layer, followed by a fully connected layer and softmax layer. ResNet employs global average pooling as an alternative to the conventional fully connected layers, which serves to decrease spatial dimensions and create a feature vector. The classification output is generated through a last fully connected layer, and the quantity of neurons within this layer is determined by the number of categories involved in the classification task. The softmax layer in ResNet-50 serves the purpose of converting the raw output into a probability distribution, particularly for multi-class classification tasks. It ensures that the network's output represents the likelihood of the input belonging to different classes, making it easier to determine the predicted class and calculate the loss during training.</p></sec><sec id="sec0010"><label>4.3.2</label><title>Measurement metrics</title><p id="para0041">In the context of deep learning and classification tasks, an assessment matrix that incorporates metrics like Accuracy, Precision, Recall, and F1-Score is frequently utilized. These indicators are crucial for evaluating the effectiveness of categorization model performance. Here is a quick breakdown of each metric:</p><p id="para0042"><bold>Accuracy:</bold> A classification model's accuracy serves as a gauge of its general correctness. Instances properly predicted as a percentage of all instances in the dataset are calculated. Although accuracy is a valuable indicator, it may not give a whole view of model performance, particularly when working with datasets that are unbalanced.<disp-formula id="eqn0001"><label>(1)</label><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="para0043">Precision: Precision indicates how accurately the model's optimistic predictions came true. It measures the proportion of real positives to all anticipated positives.<disp-formula id="eqn0002"><label>(2)</label><mml:math id="M2" altimg="si2.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="para0044"><bold>Recall:</bold> The model's capacity to recognize all pertinent instances in the dataset is measured by recall, also known as sensitivity or true positive rate. It measures the proportion of real positives to all actual positives.<disp-formula id="eqn0003"><label>(3)</label><mml:math id="M3" altimg="si3.svg"><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.33em"/><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="para0045"><bold>F1-Score:</bold> The harmonic mean of recall and precision is known as the F1-Score. When you need to take into account both false positives and false negatives, it provides a balance between these two measures and is particularly helpful.<disp-formula id="eqn0004"><label>(4)</label><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">&#x02212;</mml:mo><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>2</mml:mn><mml:mo linebreak="goodbreak">&#x000d7;</mml:mo><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.33em"/><mml:mo>&#x000d7;</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.33em"/><mml:mo>&#x000b1;</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p id="para0046"><bold>Confusion matrix:</bold> A crucial tool for assessing the effectiveness of classification models, particularly in situations with several classes, is the confusion matrix. It gives a thorough understanding of how closely the model's predictions match the actual class labels for distinct categories. This matrix is crucial for identifying the model's benefits and drawbacks when categorizing various groups, allowing for a thorough assessment of its effectiveness. The confusion matrix equips data scientists to make well-informed decisions, comprehend class-specific performance, and pinpoint areas for development by classifying forecasts into true positives, true negatives, false positives, and false negatives. The following <xref rid="fig0006" ref-type="fig">Fig.&#x000a0;6</xref> represents the confusion matrix of ResNet50 model for dragon fruit maturity detection and quality grading dataset.<fig id="fig0006"><label>Fig. 6</label><caption><p>Confusion matrix of ResNet50 model.</p></caption><alt-text id="alt0009">Fig 6</alt-text><graphic xlink:href="gr6" id="celink0006"/></fig></p><p id="para0047">This amazing achievement underlines the ResNet50 architecture's potency in precisely determining the maturity and quality grading of dragons. The model has demonstrated strong performance, achieving a 90% accuracy rate in distinguishing between immature and mature dragon fruit and a 98% accuracy rate in identifying fresh or damaged dragon fruit which is clearly depicted in <xref rid="tbl0004" ref-type="table">Table&#x000a0;4</xref>. This outstanding performance highlights the model's strong ability to generalize to new data, demonstrating its utility for real-world applications.<table-wrap position="float" id="tbl0004"><label>Table 4</label><caption><p>Classification report for maturity detection and quality grading.</p></caption><alt-text id="alt0010">Table 4:</alt-text><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Topic</th><th valign="top">Class Name</th><th valign="top">Precision</th><th valign="top">Recall</th><th valign="top">F1-Score</th></tr></thead><tbody><tr><td rowspan="3" align="left" valign="top">Dragon Fruit Maturity Detection Dataset</td><td valign="top">Immature Dragon fruit</td><td valign="top">0.97</td><td valign="top">0.86</td><td valign="top">0.91</td></tr><tr><td valign="top">Mature Dragon fruit</td><td valign="top">0.82</td><td valign="top">0.96</td><td valign="top">0.89</td></tr><tr><td colspan="3" align="left" valign="top">Accuracy</td><td valign="top">0.90</td></tr><tr><td rowspan="3" align="left" valign="top">Dragon Fruit Quality Grading Dataset</td><td valign="top">Defect Fruit</td><td valign="top">0.97</td><td valign="top">0.99</td><td valign="top">0.98</td></tr><tr><td valign="top">Fresh Fruit</td><td valign="top">0.98</td><td valign="top">0.96</td><td valign="top">0.97</td></tr><tr><td colspan="3" align="left" valign="top">Accuracy</td><td valign="top">0.98</td></tr></tbody></table></table-wrap></p><p id="para0048">In the times to come, we will thoroughly investigate advanced deep learning models with the help of this dataset to identify the most effective approach for real-world applications. In the future, by utilizing machine learning algorithms and AI for image processing we will develop a consumer-oriented mobile app aiding in selecting ripe, fresh, and defective dragon fruits.</p></sec></sec></sec><sec id="sec0011"><title>Limitations</title><p id="para0049">The classification of any other fruit would not be possible for this dataset because it solely relates to and is primarily focused on dragon fruit.</p></sec></body><back><ref-list id="cebibl1"><title>References</title><ref id="bib0001"><label>1</label><element-citation publication-type="journal" id="sbref0001"><person-group person-group-type="author"><name><surname>Lata</surname><given-names>Deep</given-names></name><etal/></person-group><article-title>Maturity determination of red and white pulp dragon fruit</article-title><source>J. Horticult. Sci.</source><volume>17</volume><issue>1</issue><year>2022</year><fpage>157</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.24154/jhs.v17i1.1309</pub-id></element-citation></ref><ref id="bib0002"><label>2</label><element-citation publication-type="journal" id="sbref0002"><person-group person-group-type="author"><name><surname>Patil</surname><given-names>Pallavi U.</given-names></name><etal/></person-group><article-title>Grading and sorting technique of dragon fruits using machine learning algorithms</article-title><source>J. Agric. Food Res.</source><volume>4</volume><year>2021</year><object-id pub-id-type="publisher-id">100118</object-id><pub-id pub-id-type="doi">10.1016/j.jafr.2021.100118</pub-id></element-citation></ref><ref id="bib0003"><label>3</label><mixed-citation publication-type="other" id="sbref0003">Modern manufacturing techniques of Bari Dragon Fruit-1 by Bangladesh Agricultural Research Institute. Available at: <ext-link ext-link-type="uri" xlink:href="https://bari.portal.gov.bd/sites/default/files/files/bari.portal.gov.bd/page/dff6cca4_a440_403a_a7e6_b50f4d3ed2f0/Dragon%20Fruit%20%281%29.pdf" id="interref0004">https://bari.portal.gov.bd/sites/default/files/files/bari.portal.gov.bd/page/dff6cca4_a440_403a_a7e6_b50f4d3ed2f0/Dragon%20Fruit%20%281%29.pdf</ext-link>, (Accessed: 24 November 2023).</mixed-citation></ref><ref id="bib0004"><label>4</label><mixed-citation publication-type="other" id="sbref0004">Connie Mayer, Dragon Fruit ROOTED Plants, Healthy Harvesters, Available at: <ext-link ext-link-type="uri" xlink:href="https://hhplantnursery.com/products/4-connie-mayer-dragon-fruit-rooted-plants" id="interref0005">https://hhplantnursery.com/products/4-connie-mayer-dragon-fruit-rooted-plants</ext-link>, (Accessed: 24 November 2023).</mixed-citation></ref><ref id="bib0005"><label>5</label><element-citation publication-type="journal" id="sbref0005"><person-group person-group-type="author"><name><surname>Yusamran</surname><given-names>Naruwan</given-names></name><name><surname>Hiransakolwong</surname><given-names>Nualsawat</given-names></name></person-group><article-title>DIPDEEP: classification for Thai dragon fruit</article-title><source>Eng. Appl. Sci. Res.</source><volume>49</volume><issue>4</issue><year>2022</year><fpage>521</fpage><lpage>530</lpage></element-citation></ref><ref id="bib0006"><label>6</label><element-citation publication-type="journal" id="sbref0006"><person-group person-group-type="author"><name><surname>Kristina</surname></name></person-group><article-title>How to store dragon fruit</article-title><source>Savory Suitcase</source><year>2023</year><ext-link ext-link-type="uri" xlink:href="https://www.savorysuitcase.com/how-to-store-dragon-fruit/" id="interref0006">https://www.savorysuitcase.com/how-to-store-dragon-fruit/</ext-link><comment>(Accessed: 03 November 2023)</comment></element-citation></ref><ref id="bib0007"><label>7</label><element-citation publication-type="journal" id="sbref0007"><person-group person-group-type="author"><name><surname>Spritzler</surname><given-names>F.</given-names></name></person-group><article-title>Dragon fruit: nutrition, benefits, and how to eat it</article-title><source>Healthline</source><year>2023</year></element-citation><note><p>Available at: <ext-link ext-link-type="uri" xlink:href="https://www.healthline.com/nutrition/dragon-fruit" id="interref0007">https://www.healthline.com/nutrition/dragon-fruit</ext-link>&#x000a0;(Accessed: 03 November 2023).</p></note></ref><ref id="bib0008"><label>8</label><mixed-citation publication-type="other" id="sbref0008">Viccie (2022) How to tell if dragon fruit has gone bad? - check your fruit!, Miss Vickie. Available at: <ext-link ext-link-type="uri" xlink:href="https://missvickie.com/how-to-tell-if-dragon-fruit-has-gone-bad/" id="interref0008">https://missvickie.com/how-to-tell-if-dragon-fruit-has-gone-bad/</ext-link> (Accessed: 03 November 2023).</mixed-citation></ref><ref id="bib0009"><label>9</label><element-citation publication-type="journal" id="sbref0009"><person-group person-group-type="author"><name><surname>Abada</surname><given-names>Rofia</given-names></name><name><surname>Musa Abubakar</surname><given-names>Abdulhalim</given-names></name><name><surname>Bilal</surname><given-names>Muhammad Tayyab</given-names></name></person-group><article-title>An overview on deep leaning application of big data</article-title><source>Mesopotamian J. Big Data</source><issue>2022</issue><year>2022</year><fpage>31</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.58496/MJBD/2022/004</pub-id></element-citation></ref><ref id="bib0010"><label>10</label><element-citation publication-type="journal" id="sbref0010"><person-group person-group-type="author"><name><surname>Islam</surname><given-names>Md.Ashiqul</given-names></name><etal/></person-group><article-title>An automated convolutional neural network based approach for paddy leaf disease detection</article-title><source>(IJACSA) Int. J. Adv. Comput. Sci. Appl.</source><volume>12</volume><issue>1</issue><year>2021</year><fpage>280</fpage><lpage>288</lpage></element-citation></ref><ref id="bib0011"><label>11</label><element-citation publication-type="journal" id="sbref0011"><person-group person-group-type="author"><name><surname>Minh Trieu</surname><given-names>N.</given-names></name><name><surname>Thinh</surname><given-names>N.T.</given-names></name></person-group><article-title>Quality classification of dragon fruits based on external performance using a convolutional neural network</article-title><source>Appl. Sci.</source><volume>11</volume><issue>22</issue><year>2021</year><fpage>10558</fpage><pub-id pub-id-type="doi">10.3390/app112210558</pub-id></element-citation></ref><ref id="bib0012"><label>12</label><element-citation publication-type="journal" id="sbref0012"><person-group person-group-type="author"><name><surname>Khatun</surname><given-names>Tania</given-names></name><etal/></person-group><article-title>An extensive real-world in field tomato image dataset involving maturity classification and recognition of fresh and defect tomatoes</article-title><source>Data Brief</source><volume>51</volume><year>2023</year><object-id pub-id-type="publisher-id">109688</object-id><pub-id pub-id-type="doi">10.1016/j.dib.2023.109688</pub-id></element-citation></ref><ref id="bib0013"><label>13</label><element-citation publication-type="book" id="sbref0013"><person-group person-group-type="author"><name><surname>He</surname><given-names>Kaiming</given-names></name><etal/></person-group><part-title>Deep residual learning for image recognition</part-title><source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source><conf-name>Las Vegas, NV, USA, 27&#x02013;30 June</conf-name><year>2016</year><fpage>770</fpage><lpage>778</lpage></element-citation></ref></ref-list><sec sec-type="data-availability" id="refdata001"><title>Data availability</title><p id="para9001">
<list list-type="simple" id="dacelist0001"><list-item id="rdlistitem0001"><p id="para9002"><ext-link ext-link-type="uri" xlink:href="https://data.mendeley.com/datasets/2jpzbx8tm6/1" id="interref0002">Dragon Fruit Maturity Detection and Quality Grading Dataset (Original data)</ext-link> (Mendeley Data)</p></list-item></list>
</p></sec><ack id="ack0001"><sec id="sec0012"><title>Ethics Statement</title><p id="para0050">None of the authors of this article have conducted any research using humans or animals as subjects. The datasets consulted for this article are accessible to everyone but following the correct citation guidelines is essential.</p></sec><sec id="sec0013"><title>CRediT Author Statement</title><p id="para0051"><bold>Tania Khatun:</bold> Conceptualization, Data curation, Methodology, Visualization, Validation, Writing; <bold>Md. Asraful Sharker Nirob:</bold> Methodology, Data curation; <bold>Prayma Bishshash:</bold> Writing, Data curation; <bold>Morium Akter:</bold> Writing &#x02013; review, <bold>Mohammad Shorif Uddin:</bold> Supervision, Writing &#x02013; review &#x00026; editing.</p></sec><sec id="sec0014"><title>Acknowledgements</title><p id="para0052">We are very grateful to the domain expert Mohammad Enayet-e-Rabbi, Deputy Director of Quality Control, Seed Certification Agency, Ministry of Agriculture, Bangladesh for the valuable feedback and cooperation to accomplish the task.</p></sec><sec id="sec001"><title>Declaration of Competing Interest</title><p id="para0053">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></sec></ack></back></article>
