<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN" "archivearticle.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Biomed Eng Online</journal-id><journal-title>BioMedical Engineering OnLine</journal-title><issn pub-type="epub">1475-925X</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">15494072</article-id><article-id pub-id-type="pmc">PMC529274</article-id><article-id pub-id-type="publisher-id">1475-925X-3-35</article-id><article-id pub-id-type="doi">10.1186/1475-925X-3-35</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Image fusion for dynamic contrast enhanced magnetic resonance imaging</article-title></title-group><contrib-group><contrib id="A1" corresp="yes" contrib-type="author"><name><surname>Twellmann</surname><given-names>Thorsten</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>ttwellma@TechFak.Uni-Bielefeld.de</email></contrib><contrib id="A2" contrib-type="author"><name><surname>Saalbach</surname><given-names>Axel</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>asaalbac@TechFak.Uni-Bielefeld.de</email></contrib><contrib id="A3" contrib-type="author"><name><surname>Gerstung</surname><given-names>Olaf</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>ogerstun@TechFak.Uni-Bielefeld.de</email></contrib><contrib id="A4" contrib-type="author"><name><surname>Leach</surname><given-names>Martin O</given-names></name><xref ref-type="aff" rid="I2">2</xref><email>martin.leach@icr.ac.uk</email></contrib><contrib id="A5" contrib-type="author"><name><surname>Nattkemper</surname><given-names>Tim W</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>tnattkem@TechFak.Uni-Bielefeld.de</email></contrib></contrib-group><aff id="I1"><label>1</label>Applied Neuroinformatics Group, Faculty of Technology, University of Bielefeld, Germany</aff><aff id="I2"><label>2</label>Cancer Research UK Clinical MR Research Group, Section of Magnetic Resonance, Institute of Cancer Research, Royal Marsden Hospital, Sutton, Surrey, UK</aff><pub-date pub-type="collection"><year>2004</year></pub-date><pub-date pub-type="epub"><day>19</day><month>10</month><year>2004</year></pub-date><volume>3</volume><fpage>35</fpage><lpage>35</lpage><ext-link ext-link-type="uri" xlink:href="http://www.biomedical-engineering-online.com/content/3/1/35"/><history><date date-type="received"><day>4</day><month>6</month><year>2004</year></date><date date-type="accepted"><day>19</day><month>10</month><year>2004</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2004 Twellmann et al; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2004</copyright-year><copyright-holder>Twellmann et al; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p><!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Twellmann
               Thorsten
               
               ttwellma@TechFak.Uni-Bielefeld.de
            </dc:author><dc:title>
            Image fusion for dynamic contrast enhanced magnetic resonance imaging
         </dc:title><dc:date>2004</dc:date><dcterms:bibliographicCitation>BioMedical Engineering OnLine 3(1): 35-. (2004)</dcterms:bibliographicCitation><dc:identifier type="sici">1475-925X(2004)3:1&#x0003c;35&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1475-925X</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>--></license></permissions><abstract><sec><title>Background</title><p>Multivariate imaging techniques such as dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) have been shown to provide valuable information for medical diagnosis. Even though these techniques provide new information, integrating and evaluating the much wider range of information is a challenging task for the human observer. This task may be assisted with the use of image fusion algorithms.</p></sec><sec sec-type="methods"><title>Methods</title><p>In this paper, image fusion based on <italic>Kernel Principal Component Analysis </italic>(KPCA) is proposed for the first time. It is demonstrated that a priori knowledge about the data domain can be easily incorporated into the parametrisation of the KPCA, leading to task-oriented visualisations of the multivariate data. The results of the fusion process are compared with those of the well-known and established standard linear <italic>Principal Component Analysis </italic>(PCA) by means of temporal sequences of 3D MRI volumes from six patients who took part in a breast cancer screening study.</p></sec><sec><title>Results</title><p>The PCA and KPCA algorithms are able to integrate information from a sequence of MRI volumes into informative gray value or colour images. By incorporating a priori knowledge, the fusion process can be automated and optimised in order to visualise suspicious lesions with high contrast to normal tissue.</p></sec><sec><title>Conclusion</title><p>Our machine learning based image fusion approach maps the full signal space of a temporal DCE-MRI sequence to a single meaningful visualisation with good tissue/lesion contrast and thus supports the radiologist during manual image evaluation.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>In recent years, multivariate imaging techniques have become an important source of information to aid diagnosis in many medical fields. One example is the <italic>dynamic contrast-enhanced magnetic resonance imaging </italic>(DCE-MRI) technique [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B2">2</xref>]. After the administration of a gadolinium-based contrast agent, a sequence of <italic>d </italic>3D MRI volumes is recorded from a certain part of the body (see Fig. <xref ref-type="fig" rid="F1">1</xref>). Thus, each spatial coordinate <bold>p </bold>= (<italic>x</italic>, <italic>y</italic>, <italic>z</italic>) in the volume can be associated with a temporal kinetic pattern vector <inline-graphic xlink:href="1475-925X-3-35-i1.gif"/> which is regarded as a point in a signal space <inline-graphic xlink:href="1475-925X-3-35-i2.gif"/> (see Fig. <xref ref-type="fig" rid="F2">2</xref>). The examination of these temporal kinetic patterns at different spatial coordinates in the volume allows the observer to infer information about local tissue types and states (see Fig. <xref ref-type="fig" rid="F3">3</xref>) [<xref ref-type="bibr" rid="B3">3</xref>].</p><fig position="float" id="F1"><label>Figure 1</label><caption><p>Visualisation of contrast agent concentration as gray value images of the same volume slice at different points of time (Left to right: first precontrast, first postcontrast and fifth postcontrast image). The lesion is located near the centre of the right breast.</p></caption><graphic xlink:href="1475-925X-3-35-1"/></fig><fig position="float" id="F2"><label>Figure 2</label><caption><p>Alternative view on a temporal sequence of <italic>d </italic>3D MRI volumes: Each spatial coordinate <bold>p </bold>in a 3D volume can be associated with a <italic>d</italic>-dimensional temporal kinetic vector <bold>x</bold><sub><bold>p </bold></sub>consisting of measurements of the local intensity at <italic>d </italic>points of time.</p></caption><graphic xlink:href="1475-925X-3-35-2"/></fig><fig position="float" id="F3"><label>Figure 3</label><caption><p>Illustration of temporal kinetic patterns of contrast uptake for normal, benign and malignant tissue (left to right) measured during DCE-MRI with two precontrast and five postcontrast recordings. Especially the strong signal uptake between the two precontrast measurements and the first postcontrast measurement indicates suspicious tissue.</p></caption><graphic xlink:href="1475-925X-3-35-3"/></fig><p>Today, much effort is spent on enhancing the capabilities of the imaging techniques e.g. increasing the spatial and temporal resolution. In contrast to these improvements in image acquisition, much less effort has been spent on effective visualisation methods. Even though several approaches for detection and classification of suspicious lesions in DCE-MRI data of the breast have been proposed (e.g. [<xref ref-type="bibr" rid="B4">4</xref>-<xref ref-type="bibr" rid="B8">8</xref>]), it is still common practice for the huge amount of data to be analysed manually using simple operations such as <italic>subtraction images </italic>of two volumes.</p><p>Obviously, these images can only comprise a small fraction of the information which is commonly spread over all volumes of the sequences. As a consequence, analysing multivariate images in radiology remains a time consuming and challenging task which potentially can be alleviated by the application of <italic>image fusion </italic>techniques.</p><sec><title>Image fusion</title><p>Image fusion methods have been an area of research for several decades. According to Genderen &#x00026; Pohl [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B10">10</xref>], image fusion '<italic>is the combination of two or more different images to form a new image by using a certain algorithm' </italic>e.g. integration of a large number of multivariate images from a remote sensing process into one image. Because Genderen &#x00026; Pohl already stated PCA as a standard technique for image fusion in remote sensing, we adopt the more general definition of the term <italic>image fusion </italic>from the remote sensing community. Whereas in the medical imaging community the meaning of the term <italic>image fusion </italic>is commonly restricted to fusion of multimodal images, the definition of this term used in this article also includes multivariate images such as multispectral or multitemporal images.</p><p>Pattern recognition methods such as <italic>artificial neural networks </italic>(ANN) have gained much attention from the remote sensing community [<xref ref-type="bibr" rid="B11">11</xref>-<xref ref-type="bibr" rid="B15">15</xref>]. From the point of view of pattern recognition, the problem of image fusion is strongly related to the task of <italic>dimension reduction</italic>: Ignoring the spatial order of the patterns <bold>x</bold>, the image data is an unordered set of patterns that forms a data distribution in the data space <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/> and image fusion or dimension reduction corresponds to a mapping</p><p><inline-graphic xlink:href="1475-925X-3-35-i4.gif"/></p><p>to a new low dimensional space <inline-graphic xlink:href="1475-925X-3-35-i5.gif"/> which retains certain properties of the original data distribution. Subsequently, the mapped patterns <inline-graphic xlink:href="1475-925X-3-35-i6.gif"/> can be spatially ordered according to the locations <bold>p </bold>of the corresponding sources, leading to the final fused images.</p><p>Well-known algorithms such as <italic>Principal Component Analysis </italic>(PCA) [<xref ref-type="bibr" rid="B16">16</xref>] or <italic>Self Organising Maps </italic>[<xref ref-type="bibr" rid="B17">17</xref>] have been successfully applied for various tasks of multispectral or multitemporal image fusion [<xref ref-type="bibr" rid="B11">11</xref>-<xref ref-type="bibr" rid="B15">15</xref>]. It is important to note that these methods are not bounded with limitations on the dimensionality of <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/>. Hence, they are especially suited if <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/> is high dimensional.</p><p>In this work, we investigate the application of machine learning algorithms to medical image fusion. We compare the results of the standard linear PCA with it's nonlinear extension, the so called <italic>Kernel PCA </italic>(KPCA) which was proposed by Sch&#x000f6;lkopf et al. in 1998 [<xref ref-type="bibr" rid="B18">18</xref>]. Our empirical observations are presented and discussed by means of DCE-MRI data sets from a breast cancer screening study [<xref ref-type="bibr" rid="B19">19</xref>]. Image material presented in this paper is also provided online in original size (PNG format) [<xref ref-type="bibr" rid="B20">20</xref>].</p></sec></sec><sec sec-type="methods"><title>Methods</title><p>In the following, we briefly describe the theoretical background of the linear PCA and nonlinear KPCA algorithms and their application to the task of image fusion. Both methods determine a set of projection directions, referred to as <italic>principal directions </italic>(PDs), by optimising a certain criterion. The mapping <italic>M </italic>is defined by a subset of all possible PDs. Projecting each pattern <bold>x</bold><sub><bold>p </bold></sub>on to one of these PDs associates each spatial position <bold>p </bold>with a new scalar value <inline-graphic xlink:href="1475-925X-3-35-i7.gif"/> (the <italic>principal component</italic>) of which integrates information from the different components <inline-graphic xlink:href="1475-925X-3-35-i8.gif"/> of <bold>x</bold><sub><bold>p</bold></sub>, respectively. The resulting 3D image can be visualised as a gray value image or using perceptually optimised colour scales [<xref ref-type="bibr" rid="B21">21</xref>,<xref ref-type="bibr" rid="B22">22</xref>]. Alternatively, the low dimensional representation <inline-graphic xlink:href="1475-925X-3-35-i9.gif"/> of the patterns can be displayed as RGB composite images, if <italic>M </italic>is defined by a set of three PDs.</p><sec><title>Principal component analysis</title><p>Principal Component Analysis is one of the most frequently used dimension reduction method. Suppose the data are given by the set &#x00393; = {<bold>x</bold><sub><italic>i</italic></sub>}, <bold>x</bold><sub><italic>i </italic></sub>&#x02208; <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/>, 0 &#x02264; <italic>i </italic>&#x02264; <italic>N</italic>, PCA is a transformation in a new coordinate system of uncorrelated and orthogonal principal axes <bold><italic>&#x003be; </italic></bold>&#x02208; <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/>, |<bold><italic>&#x003be;</italic></bold>| = 1 which can be derived from the eigenvectors of the covariance matrix</p><p><inline-graphic xlink:href="1475-925X-3-35-i10.gif"/></p><p>by solving the eigenvalue equation</p><p><italic>&#x003bb;</italic><bold><italic>&#x003be; </italic></bold>= <italic>C</italic><bold><italic>&#x003be; </italic></bold>&#x000a0;&#x000a0;&#x000a0; (2)</p><p>for <italic>&#x003bb; </italic>&#x02265; 0 and <bold><italic>&#x003be; </italic></bold>&#x02208; <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/> \ {0}. The first eigenvector <bold><italic>&#x003be;</italic></bold><sub>1 </sub>(the one with the largest eigenvalue <italic>&#x003bb;</italic><sub>1</sub>) maximises the variance <inline-graphic xlink:href="1475-925X-3-35-i11.gif"/>. Therefore, the set of the first <italic>n </italic>&#x02264; <italic>d </italic>eigenvectors or PDs carry more variance than any other <italic>n </italic>orthogonal projections.</p></sec><sec><title>Kernel principal component analysis</title><p>In recent years, kernel based methods have been the object of much research effort within the machine learning community. The concept of a subset of kernel methods is based on the combination of well-known linear algorithms such as <italic>Principal Component Analysis </italic>or <italic>Fisher Discriminant Analysis </italic>with nonlinear kernel functions [<xref ref-type="bibr" rid="B23">23</xref>,<xref ref-type="bibr" rid="B24">24</xref>]. While the application of these functions allows more powerful nonlinear solutions, the kernelised algorithms retain most properties of their linear versions.</p><p>Consider a nonlinear function</p><p><inline-graphic xlink:href="1475-925X-3-35-i12.gif"/></p><p>which maps the examples <bold>x </bold>&#x02208; &#x00393; to some feature space <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/>[<xref ref-type="bibr" rid="B25">25</xref>]. Furthermore, assume that the mapped data are centred in <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/>. In order to perform the PCA in <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/>, one has to find the eigenvectors <bold><italic>&#x003be; </italic></bold>of the covariance matrix</p><p><inline-graphic xlink:href="1475-925X-3-35-i14.gif"/></p><p>i.e. those vectors that satisfy <inline-graphic xlink:href="1475-925X-3-35-i15.gif"/> with <bold><italic>&#x003be; </italic></bold>&#x02208; <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/> \ {0} and <italic>&#x003bb; </italic>&#x02265; 0. Substituting (3), it is easy to see that the eigenvectors <bold><italic>&#x003be; </italic></bold>lie in the span of &#x003a6;(<bold>x</bold><sub>1</sub>),...,&#x003a6;(<bold>x</bold><sub><italic>N</italic></sub>). Therefore, Sch&#x000f6;lkopf et al. [<xref ref-type="bibr" rid="B26">26</xref>] define the equivalent eigenvalue problem</p><p><italic>N&#x003bb;</italic><bold><italic>&#x003b1; </italic></bold>= <italic>K</italic><bold><italic>&#x003b1;</italic></bold>&#x000a0;&#x000a0;&#x000a0; (4)</p><p>where <bold>&#x003b1; </bold>denotes the column vector of coefficients <italic>&#x003b1;</italic><sup>(1)</sup>,...,<italic>&#x003b1;</italic><sup>(<italic>N</italic>) </sup>describing the dual form of the eigenvector by</p><p><inline-graphic xlink:href="1475-925X-3-35-i16.gif"/></p><p>and <italic>K </italic>is the symmetric <italic>Gram matrix </italic>with elements</p><p><italic>K</italic><sub><italic>ij </italic></sub>= <italic>K</italic>(<bold>x</bold><sub><italic>i</italic></sub>, <bold>x</bold><sub><italic>j</italic></sub>) = <inline-graphic xlink:href="1475-925X-3-35-i25.gif"/>&#x003a6;(<bold>x</bold><sub><italic>i</italic></sub>), &#x003a6;(<bold>x</bold><sub><italic>j</italic></sub>)<inline-graphic xlink:href="1475-925X-3-35-i26.gif"/>. &#x000a0;&#x000a0;&#x000a0;(6)</p><p>Normalising <bold><italic>&#x003b1;</italic></bold><sub><italic>k </italic></sub>corresponding to the k-th eigenvalue <italic>&#x003bb;</italic><sub><italic>k </italic></sub>of <italic>K </italic>ensures <italic>&#x003bb;</italic><sub><italic>k</italic></sub><inline-graphic xlink:href="1475-925X-3-35-i25.gif"/><bold><italic>&#x003b1;</italic></bold><sub><italic>k</italic></sub>, <bold><italic>&#x003b1;</italic></bold><sub><italic>k</italic></sub><inline-graphic xlink:href="1475-925X-3-35-i26.gif"/> = 1. Now, principal components can be extracted in <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/> by projecting an example <bold>x </bold>on <bold><italic>&#x003be;</italic></bold><sub><italic>k </italic></sub>using</p><p><inline-graphic xlink:href="1475-925X-3-35-i17.gif"/></p><p>It is crucial to note that for extracting principal components using (4) and (7) the inner product <inline-graphic xlink:href="1475-925X-3-35-i25.gif"/>&#x003a6;(<bold>x</bold><sub><italic>i</italic></sub>), &#x003a6;(<bold>x</bold><sub><italic>j</italic></sub>)<inline-graphic xlink:href="1475-925X-3-35-i26.gif"/> is needed rather than the explicit images &#x003a6;(<bold>x</bold><sub><italic>i</italic></sub>), &#x003a6;(<bold>x</bold><sub><italic>j</italic></sub>) alone. Instead, one can use <italic>kernel functions </italic>fulfilling <italic>Mercer's Theorem </italic>such as the <italic>Gaussian Kernel</italic></p><p><inline-graphic xlink:href="1475-925X-3-35-i18.gif"/></p><p>with bandwidth parameter <italic>&#x003c3; </italic>or the <italic>Polynomial Kernel of degree d</italic></p><p><italic>K</italic>(<bold>x</bold><sub><italic>i</italic></sub>, <bold>x</bold><sub><italic>j</italic></sub>) = <inline-graphic xlink:href="1475-925X-3-35-i25.gif"/><bold>x</bold><sub><italic>i</italic></sub>, <bold>x</bold><sub><italic>j</italic></sub><inline-graphic xlink:href="1475-925X-3-35-i26.gif"/><sup><italic>d </italic></sup>&#x000a0;&#x000a0;&#x000a0; (9)</p><p>which allow the PCA in the corresponding <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/> to be performed implicitly with reasonable computational costs. For the Polynomial Kernel we have a clear interpretation of KPCA. In this case, <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/> is the space of all monomials of degree <italic>d </italic>of the pattern components. Thus, KPCA is a linear PCA of the corresponding high order statistical features. The KPCA algorithm can be summarised as follows:</p><p>1. Calculate the Gram matrix <italic>K </italic>of &#x00393; using a suitable parameterised kernel function.</p><p>2. Transform <italic>K </italic>according</p><p><inline-graphic xlink:href="1475-925X-3-35-i19.gif"/></p><p>with <inline-graphic xlink:href="1475-925X-3-35-i20.gif"/>. This transformation implicitly moves the centre of mass of the mapped data {&#x003a6;(<bold>x</bold><sub><italic>i</italic></sub>)}, <bold>x</bold><sub><italic>i </italic></sub>&#x02208; &#x00393; to the origin of <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/>, i.e. centres the data in <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/>.</p><p>3. Calculate the eigenvector expansion coefficients <bold><italic>&#x003b1;</italic></bold><sub><italic>k</italic></sub>, i.e. the eigenvectors of <inline-graphic xlink:href="1475-925X-3-35-i21.gif"/> and normalise them.</p><p>4. Extract principal components using (7).</p></sec><sec><title>Compression vs. discrimination</title><p>Application of both image fusion techniques leads to a set of up to <italic>d </italic>PDs in case of PCA and up to <italic>N </italic>PDs in case of KPCA. In general, a compact visualisation of the complete data as a single image is desired. In this case, inspection of the fused image based on the PD corresponding to the first (largest) eigenvalue is optimal in terms of a general compression scheme: The projection on this PD retains most of the total data variance and leads to a reconstruction with least mean square error. Nevertheless, image fusion is commonly employed with a well defined intention e.g. in order to detect a specific phenomenon such as bushfires in multitemporal satellite images [<xref ref-type="bibr" rid="B11">11</xref>] or (as in this work) tumour lesions in DCE-MRI data. In addition to the general compression characteristics, the fused image has to show task-specific discriminative properties which do not necessarily reflect the total data variance. In this case, using a PD corresponding to one of the following eigenvalues may lead to more discriminative visualisations. If the image data are fused by KPCA, an additional degree of freedom can be exploited. In addition to the index of the selected PD, the type and parameterisation of the kernel <italic>K </italic>can be varied leading to alternative mappings to the feature space, changing the characteristic of the fusion image.</p></sec><sec><title>Experiments</title><p>In the following, the fusion results of both methods are discussed and illustrated with DCE-MRI sequences from six cases (referred to as <italic>S</italic><sub>1</sub>,...,<italic>S</italic><sub>6</sub>) which were taken during the the <italic>MARIBS </italic>breast screening study [<xref ref-type="bibr" rid="B19">19</xref>]. Each sequence consists of seven 3D MRI volumes of the female breast, recorded with a separation of 90 sec using a standardised protocol (A fast spoiled gradient echo sequence (FLASH) with TR = 12 ms, TE = 5 ms, ip angle = 35&#x000b0;, FOV = 340 mm and coronal slice orientation). Before recording the third volume, a gadolinium-based contrast agent was administered with a bolus injection. Therefore, each spatial position <bold>p </bold>in the 256 &#x000d7; 128 &#x000d7; 64 (1.33 mm &#x000d7; 1.33 mm &#x000d7; 2.5 mm) sized volume is associated with a pattern <inline-graphic xlink:href="1475-925X-3-35-i22.gif"/>, <italic>d </italic>= 7 describing the temporal signal kinetic of the local tissue.</p><p>The images were manually evaluated by an expert who marked voxels of tumour with a cursor on an evaluation device. Below, the kinetic signals of the marked tumour voxels are labelled '+'. Signals corresponding to voxels of the complement of the marked region are labelled '-'.</p><p>For this kind of data, experiments of Lucht et al. [<xref ref-type="bibr" rid="B5">5</xref>] suggest recording a much longer temporal sequence of 28 images which makes the need for efficient fusion techniques evident.</p><sec><title>Evaluation criteria</title><p>In order to provide an objective discussion of the value and drawbacks of both algorithms, we focus on the following requirements:</p><p>1. The marked region should be visualised with high contrast compared to unmarked regions in order to facilitate detection of kinetic signals which are similar to the marked signals.</p><p>2. The fusion image should follow the first criteria without time consuming manual manipulation by the observer (e.g. tuning of transfer functions such as windowing).</p><p>Following the first criteria, the purpose of the visualisation is specified implicitly by the voxel labels. In the present work, the expert marked regions of tumour tissues. Thus, optimal fusion images of an image sequence display locations of cancerous kinetic signals with high contrast to normal signals.</p><p>Next to the visualisation of the fusion images as gray value and RGB images, both methods are evaluated by means of a <italic>receiver-operating-characteristic </italic>(ROC) analysis [<xref ref-type="bibr" rid="B27">27</xref>,<xref ref-type="bibr" rid="B28">28</xref>]. To this end, pixel intensities of the fusion images are interpreted as confidence values for the existence of suspicious signals and are compared with the expert label as ground truth. The ROC analysis objectively measures the applicability of the fusion images for the task of lesion detection.</p><p>However, no conclusion can be drawn about how well other tissue types are distinguishable in the fusion images, i.e. how well the information of the entire signal space is represented.</p></sec><sec><title>Preprocessing</title><p>For numerical reasons, the voxel value range of each volume sequence is individually normalised to [0; 1]. In order to preserve the signal kinetics, the individual minimal and maximal intensity value is determined simultaneously on all <italic>d </italic>image volumes of each sequence. To ensure this normalisation is robust with respect to single outlier values, the values are calculated based on an application of a 3 &#x000d7; 3 &#x000d7; 3 median filter.</p><p>Since about 66% of each volume is covered by background, all images sequences are preprocessed with a full automatic tissue/background separation method. The histogram of the <italic>sum of local intensity differences </italic>(sod) feature</p><p><inline-graphic xlink:href="1475-925X-3-35-i23.gif"/></p><p>individually calculated for each sequence, has a bimodal shape and shows a clear separable maximum for the background voxels. The optimal threshold separating background from tissue can be computed automatically [<xref ref-type="bibr" rid="B29">29</xref>]. The resulting binary masks are postprocessed with a morphological <italic>closing operator </italic>[<xref ref-type="bibr" rid="B30">30</xref>] to ensure closed masks for the regions of tissue.</p></sec><sec><title>Adaptation</title><p>In order to automate and optimise the fusion process, a priori knowledge about the phenomenon to be visualised, given by the expert label, is used to find a suitable parameterisation of the algorithms as described in detail in the following section. In practice, these labels are not available for new image sequences. Thus, the algorithms have to be adapted on a small number of image sequences, e.g. from a subgroup of cases of a screening study, which were manually evaluated by a human expert and can be subsequently applied to the data of an arbitrary number of unseen cases.</p><p>To assure the experimental setup reflects the circumstances of a practical application, the data sets &#x00393; used for adaptation consist of marked tissue signals from only five of the six image sequences and the sixth unseen image sequence is used for the evaluation of the algorithm's capabilities. This setup is repeated six times, each time using a different image sequence for evaluation. In case of KPCA, using all kinetic signals from the five image sequences is prohibitive due to the computational and memory complexity. Therefore, the KPCA is adapted with a reduced data set &#x00393; consisting of all signals of the marked tumour regions and an equal number of signals randomly selected from non-tumour regions.</p></sec><sec><title>Parameter selection</title><p>An essential part of kernel methods is the mapping from the data space <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/> to the feature space <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/> by the kernel function. In this paper, we focus on the frequently used <italic>Gaussian Kernel </italic>(8) which is parameterised by the bandwidth parameter <italic>&#x003c3;</italic>. Selection of this parameter is crucial for the fusion process. For the experiments, <italic>s </italic>is chosen by scanning the range [0.05,...,2.0] using a step size of 0.05. Because manual evaluation by visual examination of the fusion images of each parameterisation is time consuming, we apply an automatic selection heuristic for the bandwidth based on the component specific <italic>Fisher score</italic></p><p><inline-graphic xlink:href="1475-925X-3-35-i24.gif"/></p><p>with class specific mean <italic>&#x003bc;</italic><sup>&#x000b1; </sup>and variance <italic>v</italic><sup>&#x000b1;</sup>. The Fisher score is commonly used for ranking components <italic>x</italic><sup>(<italic>k</italic>) </sup>of a set {(<bold>x</bold>, <italic>y</italic>)} of binary labelled (<italic>y </italic>= &#x000b1;) examples according to their discriminative power. In a similar manner, the score can be evaluated for different PDs on a random subset of the training set &#x00393; utilising the corresponding principal component values with their associated expert label and thus can be interpreted as a measure for the first evaluation criteria. Furthermore, the sign of the PCA/KPCA based PDs can be adjusted in order to obtain a high value for the average intensity of tumour voxels causing tumour lesions to appear as bright regions.</p><p>Thereby, the a priori knowledge of which region of the five image sequences used for adaptation should be visualised with high contrast can be utilised for selecting proper parameterisations which lead to discriminative visualisations tailored to the given task.</p></sec></sec><sec><title>Fusion</title><p>For each method and image sequence, the first three PDs are used for calculating fused images, referred to as <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2 </sub>and <italic>I</italic><sub>3</sub>. For the purpose of visualisation, the range of the voxel values is normalised to [0; 255]. Additionally, <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2 </sub>and <italic>I</italic><sub>3 </sub>are composed in to an RGB image <italic>I</italic><sub><italic>RGB</italic></sub>. For fusion images based on KPCA, the bandwidth for each <italic>I</italic><sub><italic>k </italic></sub>is chosen according to the individual maximum of the Fisher criterion as illustrated in Fig. <xref ref-type="fig" rid="F10">10</xref>.</p><fig position="float" id="F10"><label>Figure 10</label><caption><p>Plot of Fisher score values for PD<sub>1 </sub>of the KPCA algorithm with varying bandwidth. The score indicates a varying magnitude of separation between the class of suspicious tissue signals and the class of normal tissue signals. Below, the fusion image <italic>I</italic><sub>1 </sub>for <italic>S</italic><sub>1 </sub>based KPCA with four different bandwidth values A, B, C and D is shown. Variation of the bandwidth leads to fusion images with varying imaging properties. The bandwidth B leads to a fusion image that displays the tumour with the highest contrast to the surrounding tissue and the Fisher score shows a peak at the corresponding position. For bandwidth values A, C and D, the Fisher score and the contrast in the fusion images decreases.</p></caption><graphic xlink:href="1475-925X-3-35-10"/></fig></sec></sec><sec><title>Results</title><p>Fusion results for the sequences <italic>S</italic><sub>1</sub>,...,<italic>S</italic><sub>6 </sub>based on the PCA algorithm are shown in the lower 2 &#x000d7; 2 block of Fig. <xref ref-type="fig" rid="F4">4</xref>, Fig. <xref ref-type="fig" rid="F5">5</xref>, Fig. <xref ref-type="fig" rid="F6">6</xref>, Fig. <xref ref-type="fig" rid="F7">7</xref>, Fig. <xref ref-type="fig" rid="F8">8</xref> and Fig. <xref ref-type="fig" rid="F9">9</xref>. For all six sequences, the fusion image <italic>I</italic><sub>1 </sub>based on the PD with the leading eigenvalue does not lead to discriminative visualisations. The tumour lesions appear with the same intensity as fatty tissue, while glandula tissue is displayed as dark areas (<italic>S</italic><sub>3</sub>, <italic>S</italic><sub>4</sub>). In contrast to <italic>I</italic><sub>1</sub>, the discriminative power of <italic>I</italic><sub>2 </sub>is obviously much greater for all six image sequences. The display of the tumour lesions (high intensity values) differs significantly from areas of glandular tissues, blood vessels (medium intensity values) and fatty tissue (low intensity values). The contrast between tumour lesion and the surrounding tissue decreases in <italic>I</italic><sub>3 </sub>of <italic>S</italic><sub>2</sub>, <italic>S</italic><sub>3 </sub>and <italic>S</italic><sub>5</sub>. Additionally, the surrounding tissue is displayed less detailed (<italic>S</italic><sub>1</sub>, <italic>S</italic><sub>2</sub>, <italic>S</italic><sub>4</sub>, <italic>S</italic><sub>5</sub>). According to the weak discriminative characteristic of <italic>I</italic><sub>1 </sub>and <italic>I</italic><sub>3</sub>, the tumour lesions are coloured with shadings of green or cyan in the corresponding <italic>I</italic><sub><italic>RGB</italic></sub>.</p><fig position="float" id="F4"><label>Figure 4</label><caption><p>Fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2</sub>, <italic>I</italic><sub>3 </sub>and corresponding colour composite image <italic>I</italic><sub><italic>RGB </italic></sub>for sequence <italic>S</italic><sub>1 </sub>based on KPCA (upper 2 &#x000d7; 2 block) and PCA (lower 2 &#x000d7; 2 block). The lesion is located near the centre of the left breast.</p></caption><graphic xlink:href="1475-925X-3-35-4"/></fig><fig position="float" id="F5"><label>Figure 5</label><caption><p>Fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2</sub>, <italic>I</italic><sub>3 </sub>and corresponding colour composite image <italic>I</italic><sub><italic>RGB </italic></sub>for sequence <italic>S</italic><sub>2 </sub>based on KPCA (upper 2 &#x000d7; 2 block) and PCA (lower 2 &#x000d7; 2 block). The lesion is located in the lower left part of the left breast.</p></caption><graphic xlink:href="1475-925X-3-35-5"/></fig><fig position="float" id="F6"><label>Figure 6</label><caption><p>Fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2</sub>, <italic>I</italic><sub>3 </sub>and corresponding colour composite image <italic>I</italic><sub><italic>RGB </italic></sub>for sequence <italic>S</italic><sub>3 </sub>based on KPCA (upper 2 &#x000d7; 2 block) and PCA (lower 2 &#x000d7; 2 block). The lesion is located near the centre of the left breast.</p></caption><graphic xlink:href="1475-925X-3-35-6"/></fig><fig position="float" id="F7"><label>Figure 7</label><caption><p>Fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2</sub>, <italic>I</italic><sub>3 </sub>and corresponding colour composite image <italic>I</italic><sub><italic>RGB </italic></sub>for sequence <italic>S</italic><sub>4 </sub>based on KPCA (upper 2 &#x000d7; 2 block) and PCA (lower 2 &#x000d7; 2 block). The lesion is located near the centre of the right breast.</p></caption><graphic xlink:href="1475-925X-3-35-7"/></fig><fig position="float" id="F8"><label>Figure 8</label><caption><p>Fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2</sub>, <italic>I</italic><sub>3 </sub>and corresponding colour composite image <italic>I</italic><sub><italic>RGB </italic></sub>for sequence <italic>S</italic><sub>5 </sub>based on KPCA (upper 2 &#x000d7; 2 block) and PCA (lower 2 &#x000d7; 2 block). The lesion is located near the implant in the right breast.</p></caption><graphic xlink:href="1475-925X-3-35-8"/></fig><fig position="float" id="F9"><label>Figure 9</label><caption><p>Fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2</sub>, <italic>I</italic><sub>3 </sub>and corresponding colour composite image <italic>I</italic><sub><italic>RGB </italic></sub>for sequence <italic>S</italic><sub>6 </sub>based on KPCA (upper 2 &#x000d7; 2 block) and PCA (lower 2 &#x000d7; 2 block). The lesion is located near the centre of the left breast and is surrounded by glandular tissue.</p></caption><graphic xlink:href="1475-925X-3-35-9"/></fig><p>Fusion images based on KPCA are shown in the upper 2 &#x000d7; 2 block of Fig. <xref ref-type="fig" rid="F4">4</xref>, Fig. <xref ref-type="fig" rid="F5">5</xref>, Fig. <xref ref-type="fig" rid="F6">6</xref>, Fig. <xref ref-type="fig" rid="F7">7</xref>, Fig. <xref ref-type="fig" rid="F8">8</xref> and Fig. <xref ref-type="fig" rid="F9">9</xref>. For <italic>S</italic><sub>1</sub>, <italic>S</italic><sub>2</sub>, <italic>S</italic><sub>3 </sub>and <italic>S</italic><sub>4</sub>, image <italic>I</italic><sub>1 </sub>displays the tumour lesion with high contrast to the surrounding tissues. Adipose tissue appears in <italic>I</italic><sub>1 </sub>and <italic>I</italic><sub>2 </sub>with mediumin tensity. In <italic>I</italic><sub>2 </sub>of <italic>S</italic><sub>4 </sub>and <italic>S</italic><sub>3</sub>, glandular tissue can be observed in addition to the tumour. These areas appear dark in <italic>I</italic><sub>1</sub>. The fraction of glandular tissue regions in <italic>I</italic><sub>2 </sub>of <italic>S</italic><sub>1 </sub>and <italic>S</italic><sub>2 </sub>is much smaller, since the tumour is located near the chest muscle where the breast mostly consists of fatty tissue and blood vessels.</p><p>An interesting detail can be observed in <italic>I</italic><sub>3 </sub>of <italic>S</italic><sub>4</sub>. The image clearly shows a ring structure as part of or around the tumour lesion. At positions inside the ring which are displayed with high intensity values in <italic>I</italic><sub>1 </sub>and <italic>I</italic><sub>2</sub>, the temporal kinetic patterns show a fast uptake with a following constant or slightly decreasing concentration of the contrast agent. In contrast to the signals inside the ring, all signals corresponding to the ring structure in <italic>I</italic><sub>3 </sub>show as teadily increasing concentration. In all composite images <italic>I</italic><sub><italic>RGB </italic></sub>except for <italic>S</italic><sub>5</sub>, the tumour lesions are coloured white and can be easily discriminated from fatty tissue (shadings of blue to purple) and glandular tissue (shadings of blue to green). For image <italic>S</italic><sub>5</sub>, only <italic>I</italic><sub>1 </sub>shows a discriminative characteristic. The tumour is displayed as a small cluster of high intensity values in the lower right area of the right breast, next to the implant.</p><p>According to common practice, the curves obtained from the ROC analysis of the fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2 </sub>and <italic>I</italic><sub>3 </sub>are compared by measuring the <italic>area</italic>-<italic>under</italic>-<italic>the</italic>-<italic>curve</italic>(AUC) values. The corresponding AUC values are listed in Tab. <xref ref-type="table" rid="T1">1</xref>. The fusion image yielding the highest AUC value is printed bold for each sequence. For five of six sequences, a fusion image based on PCA yields the highest AUC value (column <italic>PCA </italic>in Tab. <xref ref-type="table" rid="T1">1</xref>). The fusion image <italic>I</italic><sub>2 </sub>based on the second PD of the PCA algorithm significantly outperforms the corresponding PCA based fusion images <italic>I</italic><sub>1 </sub>and <italic>I</italic><sub>3</sub>. A similar predominance of <italic>I</italic><sub>2 </sub>can be observed for the KPCA based AUC values (column <italic>KPCA </italic>in Tab. <xref ref-type="table" rid="T1">1</xref>). Here, <italic>I</italic><sub>2 </sub>outperforms <italic>I</italic><sub>1 </sub>and <italic>I</italic><sub>3 </sub>in four of six cases (<italic>S</italic><sub>1</sub>, <italic>S</italic><sub>2</sub>, <italic>S</italic><sub>3 </sub>and <italic>S</italic><sub>5</sub>). Only for <italic>S</italic><sub>4 </sub>and <italic>S</italic><sub>6 </sub>the fusion image <italic>I</italic><sub>1 </sub>yields the largest AUC value. Nevertheless for KPCA, the difference to the corresponding fusion images <italic>I</italic><sub>1 </sub>and <italic>I</italic><sub>3 </sub>is much less distinct. In particular <italic>I</italic><sub>1 </sub>yields AUC values which are close to those of the corresponding fusion image <italic>I</italic><sub>2</sub>. The predominance of the second component also decreases, if the PCA algorithm is trained with the reduced data set used for adaptation of the KPCA (column <italic>PCA (reduced) </italic>in Tab. <xref ref-type="table" rid="T1">1</xref>). In comparison with the results of the PCA adapted with the entire data set, the AUC values of <italic>I</italic><sub>2 </sub>decrease and increase for the fusion images <italic>I</italic><sub>1 </sub>and <italic>I</italic><sub>3</sub>.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>Area under ROC curve values for fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2 </sub>and <italic>I</italic><sub>3 </sub>for series <italic>S</italic><sub>1</sub>,...,<italic>S</italic><sub>6 </sub>based on KPCA, PCA and PCA trained with the same reduced training set as KPCA. For each AUC value, the pixel intensities of the fusion images are interpreted as confidence values indicating the existence of suspicious signals at the corresponding positions. The largest AUC value for each case is printed bold.</p></caption><table frame="hsides" rules="groups"><thead><tr><td></td><td align="center" colspan="9"><bold>Area-Under-ROC-Curve</bold></td></tr></thead><tbody><tr><td></td><td align="center" colspan="3">KPCA</td><td align="center" colspan="3">PCA</td><td align="center" colspan="3">PCA (reduced set)</td></tr><tr><td colspan="10"><hr></hr></td></tr><tr><td align="center">Sequence</td><td align="center"><italic>I</italic><sub>1</sub></td><td align="center"><italic>I</italic><sub>2</sub></td><td align="center"><italic>I</italic><sub>3</sub></td><td align="center"><italic>I</italic><sub>1</sub></td><td align="center"><italic>I</italic><sub>2</sub></td><td align="center"><italic>I</italic><sub>3</sub></td><td align="center"><italic>I</italic><sub>1</sub></td><td align="center"><italic>I</italic><sub>2</sub></td><td align="center"><italic>I</italic><sub>3</sub></td></tr><tr><td colspan="10"><hr></hr></td></tr><tr><td align="center"><italic>S</italic><sub>1</sub></td><td align="center">0.950</td><td align="center">0.972</td><td align="center">0.879</td><td align="center">0.539</td><td align="center"><bold>0.993</bold></td><td align="center">0.633</td><td align="center">0.772</td><td align="center">0.972</td><td align="center">0.692</td></tr><tr><td align="center"><italic>S</italic><sub>2</sub></td><td align="center">0.918</td><td align="center">0.945</td><td align="center">0.728</td><td align="center">0.727</td><td align="center"><bold>0.993</bold></td><td align="center">0.712</td><td align="center">0.852</td><td align="center">0.948</td><td align="center">0.547</td></tr><tr><td align="center"><italic>S</italic><sub>3</sub></td><td align="center">0.995</td><td align="center"><bold>0.998</bold></td><td align="center">0.710</td><td align="center">0.520</td><td align="center">0.997</td><td align="center">0.926</td><td align="center">0.799</td><td align="center">0.997</td><td align="center">0.747</td></tr><tr><td align="center"><italic>S</italic><sub>4</sub></td><td align="center">0.996</td><td align="center">0.985</td><td align="center">0.259</td><td align="center">0.926</td><td align="center"><bold>0.999</bold></td><td align="center">0.919</td><td align="center">0.992</td><td align="center">0.985</td><td align="center">0.963</td></tr><tr><td align="center"><italic>S</italic><sub>5</sub></td><td align="center">0.959</td><td align="center">0.966</td><td align="center">0.904</td><td align="center">0.693</td><td align="center"><bold>0.997</bold></td><td align="center">0.925</td><td align="center">0.814</td><td align="center">0.964</td><td align="center">0.344</td></tr><tr><td align="center"><italic>S</italic><sub>6</sub></td><td align="center">0.994</td><td align="center">0.986</td><td align="center">0.706</td><td align="center">0.926</td><td align="center"><bold>0.999</bold></td><td align="center">0.919</td><td align="center">0.785</td><td align="center">0.986</td><td align="center">0.802</td></tr></tbody></table></table-wrap><p>The influence of the bandwidth <italic>&#x003c3; </italic>on the fusion characteristic is illustrated in Fig. <xref ref-type="fig" rid="F10">10</xref>. For small values of the bandwidth <italic>&#x003c3; </italic>only a small fraction of the tumour lesion appears with high intensities. If the bandwidth is chosen according to the maximum of the Fisher score, the lesion is visualised with high contrast to the surrounding tissue. In the shown example, the Fisher criterion decreases along with the contrast of the visualisation for further increasing bandwidth values.</p></sec><sec><title>Discussion</title><p>The results shown in the preceding section indicate that fusion of DCE-MRI data by PCA or KPCA leads to compact and meaningful visualisations. Lesions are correctly displayed as bright regions or with specific colouring and can be easily discriminated from surrounding tissue. Once a small subgroup of cases is evaluated, the obtained secondary information in the form of labelled tumour areas is utilised for automation of the data processing and presentation: (<italic>i</italic>) The sign of the PD is selected in a way that tumour lesions always appear with high intensities. (<italic>ii</italic>) The parametrisation of the kernel function of the KPCA is optimised in such a way that the fusion images show the desired discriminative characteristics. Thus, both evaluation criteria stated in the section <italic>Evaluation criteria </italic>are accomplished.</p><p>Although both methods are applicable for the task of image fusion, several properties should be discussed in more detail. According to the ROC analysis and visual appraisal, the fusion image <italic>I</italic><sub>2 </sub>based on PCA shows for nearly all cases a discriminative characteristic which is superior to all other fusion images based on PCA or KPCA. While <italic>I</italic><sub>1 </sub>based on PCA captures the slightly increasing elucidation of the major part of the breast, caused by minor accumulation of contrast agent in tissues such as fat, the fusion image <italic>I</italic><sub>2 </sub>corresponding to the second PD of PCA shows the lesions with high contrast to the surrounding tissue. This can also be observed by means of the PDs itself. Figure <xref ref-type="fig" rid="F13">13</xref> shows a plot of the components of the three PCA based PDs. The plot of PD<sub>1 </sub>shows anearly constant or slightly increasing curve, whereas the plot of the components of PD<sub>2 </sub>is similar to a typical temporal course of contrast agent concentration insuspicious tissue (see Fig. <xref ref-type="fig" rid="F3">3</xref>). The plot of PD<sub>3 </sub>shows increasing values for the components corresponding to the postcontrast measurements. From this follows that the major part of the signal variance is caused by voxels which exhibit signals at different intensity levels with only minor changes of intensity in the course of time. This fraction of data variance is captured by PD<sub>1 </sub>of PCA. The next major source of variance is the signal uptake between the precontrast and the first postcontrast measurement insuspicious tissue which is captured by PD<sub>2 </sub>and leads to the superior discriminative characteristics of the fusion image <italic>I</italic><sub>2</sub>. PD<sub>3 </sub>is sensitive to signals which show a continuously increasing intensity for the postcontrast measurements. Hence, <italic>I</italic><sub>3 </sub>is more discriminative than <italic>I</italic><sub>1</sub>, but less discriminative than <italic>I</italic><sub>2</sub>.</p><fig position="float" id="F13"><label>Figure 13</label><caption><p>Plot of the components of the vectors PD<sub>1 </sub>(solid), PD<sub>2 </sub>(dashed) and <italic>PD</italic><sub>3 </sub>(solid with crosses) based on the PCA algorithm. The plot of <italic>PD</italic><sub>2 </sub>shows a typical signal of suspicious tissue (see Fig. 3) and therefore leads to discriminative fusion images with high intensity values at positions of tissue that exhibits a significant signal uptake after injection of the contrast agent.</p></caption><graphic xlink:href="1475-925X-3-35-13"/></fig><p>The ROC analysis of the KPCA based fusion images indicates that the fusion images <italic>I</italic><sub>2 </sub>show superior discriminative characteristics for four of six cases (<italic>S</italic><sub>1</sub>, <italic>S</italic><sub>2</sub>, <italic>S</italic><sub>3 </sub>and <italic>S</italic><sub>5</sub>). However, selection of a suitable kernel parametrisation leads to comparable AUC values for <italic>I</italic><sub>1</sub>. For fusion images corresponding to PDs with smaller eigenvalues, KPCA based images still show more details than those based on PCA, if the bandwidth value is chosen according to the maximum of the Fisher score. Figure <xref ref-type="fig" rid="F11">11</xref> shows the KPCA based (left column) and the PCA based (right column) fusion images <italic>I</italic><sub>4</sub>, <italic>I</italic><sub>5 </sub>and <italic>I</italic><sub>6 </sub>for sequence <italic>S</italic><sub>4</sub>. While KPCA distributes the total data variance on <italic>N </italic>PDs, the PCA method uses only <italic>d </italic>PDs. Therefore, the PCA based fusion images <italic>I</italic><sub>4</sub>, <italic>I</italic><sub>5 </sub>and <italic>I</italic><sub>6 </sub>typically contain a large fraction of high frequent noise. It is important to note that the fusion images based on KPCA are not necessarily uncorrelated, if each image is calculated using PDs with different bandwidth values, and therefore may display redundant information. In five of six cases, RGB visualisations based on KPCA show the tumour lesion as white regions which are easy to discriminate from other tissue types. In contrast to subtraction images which also allow detection of lesions with high sensitivity (see e.g. [<xref ref-type="bibr" rid="B4">4</xref>]), the fusion images <italic>I</italic><sub><italic>RGB </italic></sub>provide a more comprehensive display of the data. A single subtraction image displays only the information of a two dimensional subspace of the signal space <inline-graphic xlink:href="1475-925X-3-35-i3.gif"/>, i.e. the information of two manually selected components of the signal vector. Without further manipulation of the transfer function and after selection of two suitable components, a subtraction image commonly shows the lesion as a cluster of high intensity values and other types of tissue are not displayed or indistinguishable. The fusion images are low dimensional representations of the entire signal space. Thus, the RGB composite images <italic>I</italic><sub><italic>RGB </italic></sub>based on PCA or KPCA clearly display the lesion in combination with glandular or fatty tissue and major blood vessels.</p><fig position="float" id="F11"><label>Figure 11</label><caption><p>Fusion images <italic>I</italic><sub>4</sub>, <italic>I</italic><sub>5 </sub>and <italic>I</italic><sub>6 </sub>for <italic>S</italic><sub>3 </sub>based on the PDs with the fourth, fifth and sixth largest eigenvalue. The left column shows the fusion images based on KPCA. Each fusion image was calculated with a bandwidth that was individually optimised according to the Fisher score. The right column shows the same images fused with PCA. In contrast to the KPCA based fusion images, these images show a significant fraction of high frequent noise and less details.</p></caption><graphic xlink:href="1475-925X-3-35-11"/></fig><p>One drawback of KPCA is the increased computational and memory complexity in contrast to PCA. In case of KPCA, the complexity scales with the size <italic>N </italic>of the training set &#x00393;. During the adaptation of KPCA, an <italic>N </italic>&#x000d7; <italic>N </italic>sized kernel matrix has to be stored and manipulated, whereas the covariance matrix for PCA is only of size <italic>d </italic>&#x000d7; <italic>d</italic>. Thus for KPCA, the computation time (LINUX system / 1.8 GHz Pentium IV / 2 GB RAM) for the adaptation, i.e. calculation of the kernel matrix and extraction of 3 PDs, increases significantly with the size of the training set &#x00393; and takes 73 seconds for &#x00393; consisting of 2700 training items which is comparable to the computation time of the PCA for the given setup (see Fig. <xref ref-type="fig" rid="F14">14</xref>). While even for large matrices, a subset of eigenvectors can be extracted in a reasonable time using efficient numerical software packages like LAPACK [<xref ref-type="bibr" rid="B31">31</xref>], the memory complexity obviously limits the size of &#x00393;. One way to address this problem is to subsample the data. Instead of using a random sample of the whole data set, the chosen scheme assures the presence of tumour voxels in the training set. In the former case, the presence of a larger number tumour voxels is unlikely because of the unbalanced ratio between number of tumour voxels and the number of non-tumour voxels. Nevertheless, the reduction of the training data causes a degradation of the detection performance and changing fusion characteristics (see Fig. <xref ref-type="fig" rid="F12">12</xref>).</p><fig position="float" id="F14"><label>Figure 14</label><caption><p>Computation time for adaptation of KPCA (solid line). The measured time includes calculation of the kernel matrix and the extraction of the first three PDs. Additionally, the time for adaptation of the PCA using the complete training data is shown (dashed line).</p></caption><graphic xlink:href="1475-925X-3-35-14"/></fig><fig position="float" id="F12"><label>Figure 12</label><caption><p>Image <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2</sub>, <italic>I</italic><sub>3 </sub>and <italic>I</italic><sub><italic>RGB </italic></sub>of <italic>S</italic><sub>3</sub>(top block) and <italic>S</italic><sub>4</sub>(bottom block) fused by the PCA algorithm which was adapted on the same reduced data set as KPCA.</p></caption><graphic xlink:href="1475-925X-3-35-12"/></fig><p>More important for practical applications of both methods is the computational expense for calculation of the fusion images. Using PCA, the value of a fusion image voxel is equivalent to the inner product of two <italic>d</italic>-dimensional vectors and the calculation of the three fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2 </sub>and <italic>I</italic><sub>3 </sub>of one volume slice takes approximately 1 second. In case of KPCA, the inner product has to be calculated in the feature space and the PD in <inline-graphic xlink:href="1475-925X-3-35-i13.gif"/> is only implicitly given as an expansion of <italic>N </italic>kernel functions. Thus, computation of <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2 </sub>and <italic>I</italic><sub>3 </sub>of one volume slice takes approximately 23 seconds for training sets &#x00393; consisting of 1000 examples and increases linearly with the size of &#x00393; (Fig. <xref ref-type="fig" rid="F15">15</xref>).</p><fig position="float" id="F15"><label>Figure 15</label><caption><p>Computation time for the three fusion images <italic>I</italic><sub>1</sub>, <italic>I</italic><sub>2 </sub>and <italic>I</italic><sub>3 </sub>of one slice using PCA (dashed line) and KPCA (solid line). The computation time of principal component values with KPCA increases linearly with the size of the training set. For PCA, the computation time depends only on the dimension of the signal pattern and is constant for the given setup.</p></caption><graphic xlink:href="1475-925X-3-35-15"/></fig><p>In consideration of the fact that both methods are able to fuse the multitemporal DCE-MRI to single meaningful images which do not only show the lesion with high intensities, but also other types of tissue such as fatty or glandular tissue, the standard linear PCA seems to be most suitable for the given signal domain because of it's low computation time and superior detection performance. Only for PCA, the three fusion images can be calculated for a complete volume in a reasonable time and without delaying the diagnostic process. According to the ROC analysis, the introduction of nonlinearity by the kernel function did not improve the discriminative properties of the fusion images, but visual appraisal of the RGB composite images based on KPCA suggest a more comprehensive display of the different types of tissue. It is an open question whether fusion images of other data domains with more complex or higher dimensional signals might benefit more obviously from the nonlinearity of KPCA.</p></sec><sec><title>Conclusion</title><p>In this paper, we have demonstrated the integration of distributed information from DCE-MRI image sequences to meaningful visualisations by means of PCA and KPCA. Both methods were able to accentuate the regions marked by the expert as important in image sequences blinded to automatic analyses. By the employment of task-specific information, the parametrisation of the KPCA algorithm was optimised in order to accentuate the relevant characteristics of the visualisation.</p></sec><sec><title>List of abbreviations</title><p><bold>PCA </bold>Principal Component Analysis</p><p><bold>KPCA </bold>Kernel Principal Component Analysis</p><p><bold>PD </bold>Principal Direction</p><p><bold>DCE-MRI </bold>Dynamic Contrast Enhanced Magnetic Resonance Imaging</p></sec><sec><title>Authors' contributions</title><p>T. Twellmann, A. Saalbach and T. W. Nattkemper conceived the experimental setup. Implementation and realisation was done by O. Gerstung. Image acquisition was done under supervision of M. O. Leach.</p></sec></body><back><ack><sec><title>Acknowledgements</title><p>The authors would like to thank the advisory staff, radiologists, geneticists and surgeons of the <italic>MARIBS Breast Screening Study</italic>:</p><p><italic>Principal Investigator</italic>: M.O. Leach. <italic>Manchester</italic>: C. Boggis, S. Reaney, M. Wilson, J. Hawnaur*, J. Adams, D.G.R. Evans, A. Shenton. <italic>Sutton </italic>&#x00026;<italic>St George's</italic>: P. Kessar*, G. Brown, J. Murfitt, R. Eeles*, R.S. Houlston, A. Arden-Jones, K. Bishop, S. Gray, F. Lennard, S. Shanley, N. Rahman, R. Houlston. <italic>Newcastle</italic>: J. Potterton, A. Coulthard, L. McLean, M. McElroy, W. Wotherspoon, F. Douglas. <italic>Cambridge</italic>: R. Warren, A.K. Dixon, P. Britton, R. Sinnatamby, A. Freeman, J. Mackay, J. Rankin. <italic>Edinburgh</italic>: J. Walsh, B.B. Muir, A. Murray, C.M. Steel, E. Anderson, J.M. Dixon. <italic>Leeds/Sheffield/Hull</italic>: L.W. Turnbull, G. Hall, P. Kneeshaw, A. Hubbard, G. Liney, C. Chu, O. Quarrell, J. Kumar. <italic>Guy's </italic>&#x00026;<italic>St Thomas, London</italic>: S. Rankin, S. McWilliams, J. Pemberton, A. Jones, E. Sanderson, S.V. Hodgson. <italic>Aberdeen</italic>: F.J. Gilbert, G. Needham, H. Deans, K. Duncan, L. Gomersall, G. Iyengar, N. Haites, H. Gregory. <italic>Southampton</italic>: C. Rubin, M. Briley, S. Hegarty, G. Michaels, M. Reddy, D.M. Eccles. <italic>Dundee</italic>: D.G. Sheppard, J. Rehman, A. Cook, C. Walker, D. Goudie. <italic>Bristol</italic>: N. Slack, I. Lyburn, A. Jones, E. Kutt, J. Basten, M. Shere, S. Cawthorn, Z. Rayter. <italic>Birmingham</italic>: C.P. Walker, S. Bradley, M. Wallis, T. Cole, C. McKeown, J. Morton <italic>Glasgow</italic>: L. Wilkinson, J. Litherland, C. Cordiner, R. Davidson <italic>Liverpool</italic>: G. Whitehouse, D. Ritchie, F. White, I. Ellis <italic>Belfast</italic>: G. Crothers, McAllister, P. Morrison <italic>Northwick Park</italic>: W. Teh, B Shah, J. Paterson <italic>Portsmouth</italic>: P. Gordon, P. Buxton, J. Domsan <italic>UCH London</italic>: M. Hall-Craggs <italic>Barnet</italic>: G. Kaplan. <italic>Mount Vernon</italic>: A.R. Padhani, K. Raza. <italic>Study staff: </italic>L. Pointon, R. Hoff, D. Thompson, K. Chan, M. Khazen, C. Hayes, R. Fowler, M. Sydenham, E. Moore, J. Anderson, C. Levesley. <italic>Advisory Group members (not mentioned elsewhere): </italic>J. Brown (<italic>Bristol, MRC HSRC</italic>), D. Easton (<italic>Cambridge</italic>), L. Walker (Hull), S. Moss (<italic>Sutton</italic>).</p></sec></ack><ref-list><ref id="B1"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Orel</surname><given-names>S</given-names></name><name><surname>Schnall</surname><given-names>M</given-names></name></person-group><article-title>MR Imaging of the Breast for the Detection, Diagnosis, and Staging of Breast Cancer</article-title><source>Radiology</source><year>2001</year><volume>220</volume><fpage>13</fpage><lpage>30</lpage><pub-id pub-id-type="pmid">11425968</pub-id></citation></ref><ref id="B2"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kinkel</surname><given-names>K</given-names></name><name><surname>Hylton</surname><given-names>N</given-names></name></person-group><article-title>Challenges to Interpretation of Breast MRI</article-title><source>Journal of Magnetic Resonance Imaging</source><year>2001</year><volume>13</volume><fpage>821</fpage><lpage>829</lpage><pub-id pub-id-type="pmid">11382939</pub-id><pub-id pub-id-type="doi">10.1002/jmri.1117</pub-id></citation></ref><ref id="B3"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kuhl</surname><given-names>C K</given-names></name><name><surname>Mielcareck</surname><given-names>P</given-names></name><name><surname>Klaschik</surname><given-names>S</given-names></name><name><surname>Leutner</surname><given-names>C</given-names></name><name><surname>Wardelmann</surname><given-names>E</given-names></name><name><surname>Gieseke</surname><given-names>J</given-names></name><name><surname>Schild</surname><given-names>H H</given-names></name></person-group><article-title>Dynamic breast MR imaging: Are signal intensity time course data useful for differential diagnosis of enhancing lesions?</article-title><source>Radiology</source><year>1999</year><volume>211</volume><fpage>101</fpage><lpage>10</lpage><pub-id pub-id-type="pmid">10189459</pub-id></citation></ref><ref id="B4"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Twellmann</surname><given-names>T</given-names></name><name><surname>Saalbach</surname><given-names>A</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>C</given-names></name><name><surname>Nattkemper</surname><given-names>T</given-names></name><name><surname>Wism&#x000fc;ller</surname><given-names>A</given-names></name></person-group><article-title>Detection of Suspicious Lesions in Dynamic Contrast-Enhanced MRI Data</article-title><source>In Proc of EMBC 2004, 26th Annual Int Conf of the IEEE Engineering in Medicine and Biology Society</source><year>2004</year></citation></ref><ref id="B5"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Lucht</surname><given-names>R</given-names></name><name><surname>Knopp</surname><given-names>M</given-names></name><name><surname>Brix</surname><given-names>G</given-names></name></person-group><article-title>Classification of signal-time curves from dynamic MR mammography by neural networks</article-title><source>Magnetic Resonance Imaging</source><year>2001</year><volume>19</volume><fpage>51</fpage><lpage>57</lpage><pub-id pub-id-type="pmid">11295347</pub-id><pub-id pub-id-type="doi">10.1016/S0730-725X(01)00222-3</pub-id></citation></ref><ref id="B6"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>M</given-names></name><name><surname>Barker</surname><given-names>P</given-names></name><name><surname>Bluemke</surname><given-names>D</given-names></name><name><surname>Maranto</surname><given-names>C</given-names></name><name><surname>Arnold</surname><given-names>C</given-names></name><name><surname>Herskovites</surname><given-names>E</given-names></name><name><surname>Bhujwalla</surname><given-names>Z</given-names></name></person-group><article-title>Benign and Malignant Breast Lesions: Diagnosis with Multiparametric MR Imaging</article-title><source>Radiology</source><year>2003</year><volume>229</volume><fpage>225</fpage><lpage>232</lpage><pub-id pub-id-type="pmid">14519877</pub-id></citation></ref><ref id="B7"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Kelcz</surname><given-names>F</given-names></name><name><surname>Furman-Haran</surname><given-names>E</given-names></name><name><surname>Grobgeld</surname><given-names>D</given-names></name><name><surname>Degani</surname><given-names>H</given-names></name></person-group><article-title>Clinical Testing of High-Spatial-Resolution Parametric Contrast-Enhanced MR Imaging of the Breast</article-title><source>A J R oentgenol</source><year>2002</year><volume>179</volume><fpage>1485</fpage><lpage>92</lpage></citation></ref><ref id="B8"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Tofts</surname><given-names>P</given-names></name></person-group><article-title>Modeling Tracer Kinetics in Dynamic Gd-DTPA MR Imaging</article-title><source>Journal of Magnetic Resonance Imaging</source><year>1997</year><volume>7</volume><fpage>91</fpage><lpage>101</lpage><pub-id pub-id-type="pmid">9039598</pub-id></citation></ref><ref id="B9"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Pohl</surname><given-names>C</given-names></name><name><surname>van Genderen</surname><given-names>J</given-names></name></person-group><person-group person-group-type="editor"><name><surname>van Gendern J, Cappellini V</surname></name></person-group><article-title>Image fusion: Issues, techniques and applications</article-title><source>In Proceedings EARSeL Workshop</source><year>1994</year></citation></ref><ref id="B10"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Pohl</surname><given-names>C</given-names></name><name><surname>van Genderen</surname><given-names>J</given-names></name></person-group><article-title>Multisensor image fusion in remote sensing: concepts, methods and applications</article-title><source>Int Journal of Remote Sensing</source><year>1998</year><volume>19</volume><fpage>823</fpage><lpage>854</lpage><pub-id pub-id-type="doi">10.1080/014311698215748</pub-id></citation></ref><ref id="B11"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Richards</surname><given-names>J</given-names></name><name><surname>Milne</surname><given-names>A</given-names></name></person-group><article-title>Mapping Fire Burns and Veetation Regeneration Using Principal Component Analysis</article-title><source>In Proceedings Int Geoscience and Remote Sensing Symposium</source><year>1983</year></citation></ref><ref id="B12"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Manduca</surname><given-names>A</given-names></name></person-group><article-title>Multi-spectral medical image visualization with self-organizing maps</article-title><source>In Proceedings ICIP-94 (Cat No 94CH35708)</source><year>1994</year><volume>1</volume><publisher-name>Los Alamitos, CA, USA: IEEE Comput Soc Press</publisher-name><fpage>633</fpage><lpage>7</lpage></citation></ref><ref id="B13"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Villmann</surname><given-names>T</given-names></name><name><surname>Merenyi</surname><given-names>E</given-names></name><name><surname>Hammer</surname><given-names>B</given-names></name></person-group><article-title>Neural Maps in remote sensing image anlysis</article-title><source>Neural Networks</source><year>2003</year><volume>16</volume><fpage>389</fpage><lpage>403</lpage><pub-id pub-id-type="pmid">12672434</pub-id><pub-id pub-id-type="doi">10.1016/S0893-6080(03)00021-2</pub-id></citation></ref><ref id="B14"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Merenyi</surname><given-names>E</given-names></name></person-group><article-title>The challenges in spectral image analysis: An introduction and review of ANN approaches</article-title><source>In Proceedings of the European Symposium on Artificial Neural Networks (ESANN) 1999</source><year>1999</year></citation></ref><ref id="B15"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Richards</surname><given-names>J</given-names></name></person-group><source>Remote Sensing Digital Image Analysis &#x02013; An introduction</source><year>1993</year><publisher-name>Springer</publisher-name></citation></ref><ref id="B16"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Jolliffe</surname><given-names>I</given-names></name></person-group><source>Principal Component Analysis</source><year>1986</year><publisher-name>Springer</publisher-name></citation></ref><ref id="B17"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Ritter</surname><given-names>H</given-names></name><name><surname>Martinetz</surname><given-names>T</given-names></name><name><surname>Schulten</surname><given-names>K</given-names></name></person-group><source>Neural Computation and Self-Organizing Maps</source><year>1992</year><publisher-name>Addison-Wesley</publisher-name></citation></ref><ref id="B18"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>Smola</surname><given-names>A</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K</given-names></name></person-group><article-title>Nonlinear Component Analysis as a Kernel Eigenvalue Problem</article-title><source>Neural Computation</source><year>1998</year><volume>10</volume><fpage>1299</fpage><lpage>1319</lpage><pub-id pub-id-type="doi">10.1162/089976698300017467</pub-id></citation></ref><ref id="B19"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>J</given-names></name><name><surname>Buckley</surname><given-names>D</given-names></name><name><surname>Coulthard</surname><given-names>A</given-names></name><name><surname>Dixon</surname><given-names>A</given-names></name><name><surname>Dixon</surname><given-names>J</given-names></name><name><surname>Easton</surname><given-names>D</given-names></name><name><surname>Eeles</surname><given-names>R</given-names></name><name><surname>Evans</surname><given-names>D</given-names></name><name><surname>Gilbert</surname><given-names>F</given-names></name><name><surname>Graves</surname><given-names>M</given-names></name><name><surname>Hayes</surname><given-names>C</given-names></name><name><surname>Jenkins</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>A</given-names></name><name><surname>Keevil</surname><given-names>S</given-names></name><name><surname>Leach</surname><given-names>M</given-names></name><name><surname>Liney</surname><given-names>G</given-names></name><name><surname>Moss</surname><given-names>S</given-names></name><name><surname>Padhani</surname><given-names>A</given-names></name><name><surname>Parker</surname><given-names>G</given-names></name><name><surname>LJ</surname><given-names>P</given-names></name><name><surname>Ponder</surname><given-names>B</given-names></name><name><surname>Redpath</surname><given-names>T</given-names></name><name><surname>Sloane</surname><given-names>J</given-names></name><name><surname>Turnbull</surname><given-names>L</given-names></name><name><surname>Walker</surname><given-names>L</given-names></name><name><surname>Warren</surname><given-names>R</given-names></name></person-group><article-title>Magnetic resonance imaging screening in women at genetic risk of breast cancer: imaging and analysis protocol for the UK multicentre study. UK MRI Breast Screening Study Advisory Group</article-title><source>Magn Reson Imaging</source><year>2000</year><volume>18</volume><fpage>765</fpage><lpage>76</lpage><pub-id pub-id-type="pmid">11027869</pub-id><pub-id pub-id-type="doi">10.1016/S0730-725X(00)00167-3</pub-id></citation></ref><ref id="B20"><citation citation-type="other"><article-title>Image Fusion for Dynamic Contrast Enhanced Magnet Resoncance Imaging &#x02013; Auxiliary Material</article-title><ext-link ext-link-type="uri" xlink:href="http://www.techfak.uni-bielefeld.de/ags/ani/projects/ImageFusionForDCEMRI"/></citation></ref><ref id="B21"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Ware</surname><given-names>C</given-names></name></person-group><article-title>Color Sequences for Univariate Maps: Theory, Experiments and Principles</article-title><source>IEEE Computer Graphics &#x00026; Applications</source><year>1988</year><volume>8</volume><fpage>41</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1109/38.7760</pub-id></citation></ref><ref id="B22"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Ware</surname><given-names>C</given-names></name></person-group><source>Information Visualization: Perception for Design</source><year>2000</year><publisher-name>Morgan Kaufmann</publisher-name></citation></ref><ref id="B23"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mika</surname><given-names>S</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>Smola</surname><given-names>A</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K</given-names></name><name><surname>Scholz</surname><given-names>M</given-names></name><name><surname>R&#x000e4;tsch</surname><given-names>G</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Kearns M, Solla SA, Cohn D</surname></name></person-group><article-title>Kernel PCA and De-Noising in Feature Spaces</article-title><source>In Advances in Neural Information Processing Systems 11</source><year>1999</year><publisher-name>MIT Press</publisher-name></citation></ref><ref id="B24"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Mika</surname><given-names>S</given-names></name><name><surname>R&#x000e4;tsch</surname><given-names>G</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Hu Y, Larsen J, Wilson E, Douglas S</surname></name></person-group><article-title>Fisher Discriminant Analysis with Kernels</article-title><source>In Neural Networks for Signal Processing IX</source><year>1999</year><publisher-name>IEEE</publisher-name><fpage>41</fpage><lpage>48</lpage></citation></ref><ref id="B25"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>Mika</surname><given-names>S</given-names></name><name><surname>Burges</surname><given-names>C</given-names></name><name><surname>Knirsch</surname><given-names/></name><name><surname>M&#x000fc;ller</surname><given-names>K</given-names></name><name><surname>R&#x000e4;tsch</surname><given-names>G</given-names></name><name><surname>Smola</surname><given-names>AJ</given-names></name></person-group><article-title>Input space vs. feature space in kernel-based methods</article-title><source>IEEE Trans on Neural Networks</source><year>1999</year><volume>10</volume><fpage>1000</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1109/72.788641</pub-id></citation></ref><ref id="B26"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>Smola</surname><given-names>A</given-names></name><name><surname>M&#x000fc;ller</surname><given-names>K</given-names></name></person-group><source>Advances in Kernel Methods &#x02013; Support Vector Learning</source><year>1999</year><publisher-name>MIT Press</publisher-name></citation></ref><ref id="B27"><citation citation-type="other"><person-group person-group-type="author"><name><surname>Fawcett</surname><given-names>T</given-names></name></person-group><article-title>ROC Graphs: Notes and Practical Considerations for Researchers</article-title><source>Tech rep HP Labs</source><year>2003</year></citation></ref><ref id="B28"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Hanley</surname><given-names>JA</given-names></name></person-group><article-title>Receiver operating characteristic methodology: the state of the art</article-title><source>CRC critical reviews in diagnostic imaging</source><year>1989</year><volume>29</volume><fpage>307</fpage><lpage>335</lpage><pub-id pub-id-type="pmid">2667567</pub-id></citation></ref><ref id="B29"><citation citation-type="journal"><person-group person-group-type="author"><name><surname>Otsu</surname><given-names>N</given-names></name></person-group><article-title>A threshold selection method from gray level histograms</article-title><source>IEEE Trans Systems Man and Cybernetics</source><year>1979</year><volume>9</volume><fpage>62</fpage><lpage>66</lpage></citation></ref><ref id="B30"><citation citation-type="book"><person-group person-group-type="author"><name><surname>Sonka</surname><given-names>M</given-names></name><name><surname>Hlavac</surname><given-names>V</given-names></name><name><surname>Boyle</surname><given-names>R</given-names></name></person-group><source>Image Processing, Analysis, and Machine Vision</source><year>1998</year><publisher-name>Brooks/Cole</publisher-name></citation></ref><ref id="B31"><citation citation-type="other"><article-title>LAPACK &#x02013; Linear Algebra PACKage</article-title><ext-link ext-link-type="uri" xlink:href="http://www.netlib.org/lapack/"/></citation></ref></ref-list></back></article>



